{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtmxhzYiaCkyfistGackNW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameerfayiz/ML-notebooks/blob/main/finetune_GPT2_working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/ai-innovation/beginners-guide-to-retrain-gpt-2-117m-to-generate-custom-text-content-8bb5363d8b7f"
      ],
      "metadata": {
        "id": "idVrXs2TqAOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C9xQJFHaRaI",
        "outputId": "9ce915be-8c12-4ac0-f4a9-53dfb431cb59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 429, done.\u001b[K\n",
            "remote: Counting objects: 100% (138/138), done.\u001b[K\n",
            "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
            "remote: Total 429 (delta 20), reused 77 (delta 11), pack-reused 291\u001b[K\n",
            "Receiving objects: 100% (429/429), 4.47 MiB | 5.69 MiB/s, done.\n",
            "Resolving deltas: 100% (216/216), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nshepperd/gpt-2.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fire>=0.1.3\n",
        "!pip install regex==2017.4.5\n",
        "!pip install requests==2.21.0\n",
        "!pip install tqdm==4.31.1\n",
        "!pip install toposort==1.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3qmMtJzcVGs",
        "outputId": "f3fc2f9a-928d-4312-d42c-34fab659458a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.8/dist-packages (2017.4.5)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.8/dist-packages (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests==2.21.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests==2.21.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests==2.21.0) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests==2.21.0) (2.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm==4.31.1 in /usr/local/lib/python3.8/dist-packages (4.31.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: toposort==1.5 in /usr/local/lib/python3.8/dist-packages (1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd gpt-2 && pip install -r  requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RdDo-dnbqNW",
        "outputId": "20bb29c2-e494-49da-8aa4-6ed7c5aa720b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 1)) (0.5.0)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (2017.4.5)\n",
            "Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Requirement already satisfied: tqdm==4.31.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (4.31.1)\n",
            "Requirement already satisfied: toposort==1.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (1.5)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2022.12.7)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (2.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base = \"355M\""
      ],
      "metadata": {
        "id": "b_LYdYlqUk-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python gpt-2/download_model.py $base"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9PCvWVJctPm",
        "outputId": "59e48f32-1228-4202-d3ef-6ec06e18cfce"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 860kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:01, 555kit/s]                                                    \n",
            "Fetching hparams.json: 1.00kit [00:00, 976kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [04:44, 4.99Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 9.33Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:01, 490kit/s]                                                  \n",
            "Fetching vocab.bpe: 457kit [00:01, 368kit/s]                                                        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import re\n",
        "\n",
        "\n",
        "filepath = 'sentence_to_chunks.csv'\n",
        "mlist = []\n",
        "end_of_text_token = \"<|endoftext|>\"\n",
        "\n",
        "with open(filepath) as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    x = 0\n",
        "    for row in csv_reader:\n",
        "        _str = \"\"\"Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \n",
        "        \n",
        "        INPUT :\\n{text}\n",
        "        OUTPUT :\\n{out}\"\"\".replace(\"{text}\",re.sub('\\s+',' ',row[0])).replace(\"{out}\",re.sub('\\s+',' ',row[1]))\n",
        "        mlist.append(re.sub('\\s+',' ',_str))"
      ],
      "metadata": {
        "id": "_DzwIFwIeAMp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in mlist:\n",
        "  with open(\"data.txt\", 'a') as f:\n",
        "    f.write(\"\\n\\n\\n\" + item.replace(\"INPUT :\",\"\\n\\nINPUT :\").replace(\"OUTPUT : \",\"\\nOUTPUT :\\n\").replace('\", \"','\",\\n\"') + \"\\n<|endoftext|>\")\n",
        "     "
      ],
      "metadata": {
        "id": "I6fQitDbeXzf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python gpt-2/src/encode.py data.txt data.npz --model_name $base\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkwECGrGemKJ",
        "outputId": "828eff31-33ea-47af-8dca-e54df8f40a19"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading files\n",
            "\r  0% 0/1 [00:00<?, ?it/s]\r100% 1/1 [00:00<00:00, 4760.84it/s]\n",
            "Writing data.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r checkpoint/run1"
      ],
      "metadata": {
        "id": "rovek2_4EiLQ"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python gpt-2/src/train.py --dataset data.npz --batch_size 2 --model_name $base --learning_rate 0.00002 --sample_every 50 --sample_num 3 --sample_length 1023 --save_every 100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBBOub6tlTLT",
        "outputId": "6189fb6c-6cb4-40f9-bfe1-38186c03273b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-10 12:40:16.116954: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "Using Adam optimizer\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "Loading dataset...\n",
            "100% 1/1 [00:00<00:00, 542.18it/s]\n",
            "dataset has 11489 tokens\n",
            "Training...\n",
            "[1 | 2.02] loss=1.82 avg=1.82\n",
            "[2 | 2.85] loss=1.31 avg=1.56\n",
            "[3 | 3.69] loss=1.26 avg=1.46\n",
            "[4 | 4.52] loss=1.33 avg=1.43\n",
            "[5 | 5.35] loss=1.42 avg=1.43\n",
            "[6 | 6.19] loss=1.37 avg=1.42\n",
            "[7 | 7.02] loss=1.28 avg=1.40\n",
            "[8 | 7.86] loss=1.32 avg=1.39\n",
            "[9 | 8.70] loss=1.28 avg=1.37\n",
            "[10 | 9.54] loss=1.24 avg=1.36\n",
            "[11 | 10.39] loss=1.27 avg=1.35\n",
            "[12 | 11.23] loss=1.15 avg=1.33\n",
            "[13 | 12.07] loss=1.24 avg=1.33\n",
            "[14 | 12.91] loss=1.16 avg=1.31\n",
            "[15 | 13.76] loss=1.14 avg=1.30\n",
            "[16 | 14.60] loss=1.25 avg=1.30\n",
            "[17 | 15.44] loss=1.16 avg=1.29\n",
            "[18 | 16.29] loss=1.02 avg=1.27\n",
            "[19 | 17.13] loss=1.02 avg=1.26\n",
            "[20 | 17.98] loss=1.07 avg=1.25\n",
            "[21 | 18.83] loss=1.13 avg=1.24\n",
            "[22 | 19.68] loss=1.01 avg=1.23\n",
            "[23 | 20.52] loss=0.97 avg=1.22\n",
            "[24 | 21.37] loss=1.00 avg=1.21\n",
            "[25 | 22.23] loss=1.01 avg=1.20\n",
            "[26 | 23.08] loss=1.02 avg=1.19\n",
            "[27 | 23.93] loss=0.91 avg=1.18\n",
            "[28 | 24.79] loss=1.06 avg=1.17\n",
            "[29 | 25.64] loss=0.98 avg=1.17\n",
            "[30 | 26.49] loss=0.96 avg=1.16\n",
            "[31 | 27.34] loss=0.73 avg=1.14\n",
            "[32 | 28.19] loss=0.88 avg=1.13\n",
            "[33 | 29.05] loss=0.86 avg=1.12\n",
            "[34 | 29.90] loss=0.90 avg=1.12\n",
            "[35 | 30.75] loss=0.79 avg=1.10\n",
            "[36 | 31.60] loss=0.77 avg=1.09\n",
            "[37 | 32.46] loss=0.78 avg=1.08\n",
            "[38 | 33.32] loss=0.79 avg=1.07\n",
            "[39 | 34.18] loss=0.81 avg=1.07\n",
            "[40 | 35.04] loss=0.74 avg=1.06\n",
            "[41 | 35.90] loss=0.72 avg=1.05\n",
            "[42 | 36.76] loss=0.72 avg=1.04\n",
            "[43 | 37.63] loss=0.72 avg=1.03\n",
            "[44 | 38.49] loss=0.63 avg=1.02\n",
            "[45 | 39.36] loss=0.76 avg=1.01\n",
            "[46 | 40.22] loss=0.67 avg=1.00\n",
            "[47 | 41.08] loss=0.77 avg=0.99\n",
            "[48 | 41.95] loss=0.76 avg=0.99\n",
            "[49 | 42.82] loss=0.73 avg=0.98\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            " grilled with a hot sauce, tomato sauce, fresh parsley, and lime juice at The Mound. $2.99 a plate.\n",
            "\n",
            "\n",
            "Mountain Dew\n",
            "\n",
            "$6.99 in stock order\n",
            "\n",
            "One of the most delicious juices available in the Mountain Dew menu, Mountain Dew has a rich and creamy texture with a subtle flavor that blends well with your favorite beverage. The base of the Mountain Dew is rich with an earthy, earthy taste that complements the rich flavors of both fresh and old. The base of the Mountain Dew is rich with minerals and antioxidants and has a rich, rich flavor profile with a balanced sweetness. The base of the Mountain Dew is rich with flavors such as peach and grapefruit, and has a subtle lemon flavor that complements the rich flavors of both fresh and old. The base of the Mountain Dew is rich with flavors such as chocolate, chocolate pudding, and caramel pudding. The base of the Mountain Dew is rich with flavors such as cream, peanut butter, candied coconut, and coconut dressing. $6.99\n",
            "\n",
            "\n",
            "Wild Turkey\n",
            "\n",
            "$4.99 in stock order\n",
            "\n",
            "Wild Turkey is a creamy, savory and tart flavor with a fruity and tangy flavor that is sure to add a great balance of citrus fruit and savory notes. Wild Turkey has a rich, citrusy taste and is a wonderful addition to any meal. The flavor profile of Wild Turkey is bright, tart, and citrusy. The aroma of Wild Turkey is rich and earthy with a strong woody flavor. Wild Turkey has a medium to heavy sweetness that is complemented by a spicy kick to the mouth that delivers a refreshing finish. $4.99\n",
            "\n",
            "\n",
            "Oatmeal\n",
            "\n",
            "$6.99 in stock order\n",
            "\n",
            "Oatmeal is a sweet, savory and bitter flavor with a rich, complex flavor that is sweet and savory with a mild punch to the mouth. Oatmeal has a light sweetness to it that allows it to last for hours and is rich in vitamin C and protein. Oatmeal has a rich, complex flavor with a rich nutty flavor to it that is rich in a rich mix of fruit, fiber, and healthy fats. Oatmeal has a light body odor that is well balanced and allows it to last for hours. Oatmeal is rich in vitamins A, C, C- and E. $6.99\n",
            "\n",
            "\n",
            "Strawberry\n",
            "\n",
            "$16.99 in stock order\n",
            "\n",
            "A refreshing and rich strawberry is created in a traditional way that is rich with flavor and texture. Strawberry is a delicate, delicate, and easy to grow fruit with no added sugar. All of the strawberries in the Wild Turkey and Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkish Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild Turkey Wild\n",
            "\n",
            "[50 | 76.91] loss=0.80 avg=0.98\n",
            "[51 | 77.80] loss=0.53 avg=0.97\n",
            "[52 | 78.69] loss=0.60 avg=0.96\n",
            "[53 | 79.58] loss=0.75 avg=0.95\n",
            "[54 | 80.48] loss=0.54 avg=0.94\n",
            "[55 | 81.37] loss=0.51 avg=0.93\n",
            "[56 | 82.26] loss=0.48 avg=0.92\n",
            "[57 | 83.15] loss=0.56 avg=0.91\n",
            "[58 | 84.05] loss=0.55 avg=0.90\n",
            "[59 | 84.94] loss=0.39 avg=0.89\n",
            "[60 | 85.84] loss=0.61 avg=0.89\n",
            "[61 | 86.73] loss=0.59 avg=0.88\n",
            "[62 | 87.63] loss=0.55 avg=0.87\n",
            "[63 | 88.52] loss=0.68 avg=0.87\n",
            "[64 | 89.42] loss=0.54 avg=0.86\n",
            "[65 | 90.32] loss=0.40 avg=0.85\n",
            "[66 | 91.22] loss=0.57 avg=0.85\n",
            "[67 | 92.11] loss=0.54 avg=0.84\n",
            "[68 | 93.02] loss=0.53 avg=0.83\n",
            "[69 | 93.92] loss=0.62 avg=0.83\n",
            "[70 | 94.82] loss=0.72 avg=0.83\n",
            "[71 | 95.72] loss=0.50 avg=0.82\n",
            "[72 | 96.62] loss=0.49 avg=0.82\n",
            "[73 | 97.52] loss=0.47 avg=0.81\n",
            "[74 | 98.43] loss=0.57 avg=0.80\n",
            "[75 | 99.33] loss=0.54 avg=0.80\n",
            "[76 | 100.24] loss=0.37 avg=0.79\n",
            "[77 | 101.14] loss=0.39 avg=0.78\n",
            "[78 | 102.05] loss=0.42 avg=0.78\n",
            "[79 | 102.95] loss=0.55 avg=0.77\n",
            "[80 | 103.86] loss=0.33 avg=0.76\n",
            "[81 | 104.77] loss=0.34 avg=0.76\n",
            "[82 | 105.68] loss=0.41 avg=0.75\n",
            "[83 | 106.59] loss=0.59 avg=0.75\n",
            "[84 | 107.50] loss=0.58 avg=0.74\n",
            "[85 | 108.41] loss=0.47 avg=0.74\n",
            "[86 | 109.31] loss=0.40 avg=0.73\n",
            "[87 | 110.22] loss=0.46 avg=0.73\n",
            "[88 | 111.13] loss=0.42 avg=0.72\n",
            "[89 | 112.03] loss=0.30 avg=0.72\n",
            "[90 | 112.94] loss=0.43 avg=0.71\n",
            "[91 | 113.84] loss=0.32 avg=0.71\n",
            "[92 | 114.75] loss=0.27 avg=0.70\n",
            "[93 | 115.66] loss=0.43 avg=0.69\n",
            "[94 | 116.56] loss=0.41 avg=0.69\n",
            "[95 | 117.47] loss=0.32 avg=0.68\n",
            "[96 | 118.38] loss=0.35 avg=0.68\n",
            "[97 | 119.29] loss=0.48 avg=0.67\n",
            "[98 | 120.20] loss=0.29 avg=0.67\n",
            "[99 | 121.10] loss=0.30 avg=0.66\n",
            "Saving checkpoint/run1/model-100\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            " quiz at the bar, I go back to my desk and read my work, and then I go back to the study in between reading and watching television. I try my best to remember each sentence and keep track of it with a short book review.\n",
            "\n",
            "I have learned a lot from my daily practice and try my best to be as productive and productive in the future as I am in the past. I look forward to a rewarding and productive future.\n",
            "\n",
            "Related Reading:\n",
            "\n",
            "\"How to Live Your Life Without Pills of Tea\" by Dr. Mary E. Dickey\n",
            "\n",
            "\"Doing Healthy Weight Loss\" by Dr. Maria R. Mazzaro\n",
            "\n",
            "\"Dieting Is Great for Good Mental Health\" by Dr. Ronda T. Tillery\n",
            "\n",
            "\"Living a Healthy and Healthy Dream\" by Dr. David R. Puckett\n",
            "\n",
            "\"Practicing Non-Stop Nonstop\" by Dr. Susan M. Van Sheijden\n",
            "\n",
            "\"Losing Weight Is the Most Common Disaster I've Seen\" by Dr. Ann N. Van Sheijden\n",
            "\n",
            "\"I'm Ready to Take on More Health Challenges\" by Dr. Karen E. Mazzaro\n",
            "\n",
            "\"I'm Trying Hard to Balance Sport and Exercise\" by Dr. Sarah K. Van Heesen\n",
            "\n",
            "\"I'm Winning 5 Hardest and Cheaper Trials of Physical Fitness\" by Dr. Jennifer K. Van Heesen\n",
            "\n",
            "\"I'm Building Better Relationships with My Friends\" by Dr. Sarah K. Van Heesen\n",
            "\n",
            "\"I Love to Watch The Sun Shine on Me\" by Dr. Sharon E. Strom\n",
            "\n",
            "\"Being a Successful Organiser is Easy\" by Dr. Rachel A. Thickelsma\n",
            "\n",
            "\"I'm Able to Take a Break from Stress\" by Dr. Jennifer M. Van Heesen\n",
            "\n",
            "\"I Learn how to Break the Habit of Eating Right\" by Dr. Jennifer K. Van Heesen\n",
            "\n",
            "\"I Love to Explore the World\" by Dr. Anne Puckett\n",
            "\n",
            "\"I Have a Good Heart and Mind\" by Dr. Mary E. Dickey\n",
            "\n",
            "\"I've Been Working Out for Less Than a Day\" by Dr. Mandy H. Dickey\n",
            "\n",
            "\"I Have the Most Positive and Fun Years of My Life\" by Dr. Mary E. Dickey\n",
            "\n",
            "\"I Have the Energy to Beat a Hard Day of Training\" by Dr. Mandy H. Dickey\n",
            "\n",
            "\"I Have a Happy End to My Year\" by Dr. Mary E. Dickey\n",
            "\n",
            "\"I Have a Happy New Year\" by Dr. Maria R. Mazzaro\n",
            "\n",
            "\"I Have a Healthy and Positive Mind\" by Dr. Maria R. Mazzaro\n",
            "\n",
            "\"I Love to Change the Mood\" by Dr. Mandy H. Dickey\n",
            "\n",
            "\"I Have the Power to Change My Life\" by Dr. Mary E. Dickey\n",
            "\n",
            "\"I Have the Power to Make a Difference\" by Dr. Mary E. Dickey\n",
            "\n",
            "\"I Have the Courage to Set New Standards\" by Dr. Mandy H. Dickey\n",
            "\n",
            "\"I Have the Spirit of Change to Self-Help\" by Dr. Mandy H. Dickey\n",
            "\n",
            "\"I Have the Intuition to Take Action\" by Dr. Mandy H. Dickey\n",
            "\n",
            "\"I Have the Love to Make a Difference\" by Dr. Mandy H. Dickey\n",
            "\n",
            "\"I Have the Speed to Make a Difference\" by Dr. Mandy H. Dickey\n",
            "\n",
            "I am looking forward to continuing my journey of success and discovering the unspoken meaning of success in everyday life. I have some very positive experiences to share with you, and I look forward to sharing my own with you soon!<|endoftext|>NEW YORK -- It's been a long day for the NFL's biggest star.\n",
            "\n",
            "The New York Giants have been without quarterback Eli Manning for six of the past seven weeks due to an Achilles injury, cornerback Vernon Davis suffered an Achilles tendon tear and defensive end Jason Pierre-Paul has a strained hamstring.\n",
            "\n",
            "Giants coach Tom Coughlin said players are continuing recovery work after the all-but-certain defeat to the New Orleans Saints early in the second quarter on Sunday. He said his team is ready for a matchup Sunday against the NFC West champion New York Jets at Lambeau Field.\n",
            "\n",
            "\"We're working on the health side of things,\" Coughlin said. \"We're taking a beating. In the meantime, this game is over.\"\n",
            "\n",
            "The Giants (2-2) held Giants quarterback Eli Manning to a season high 10 quarterback hits in Sunday's 41-14 rout of the Lions. He had six hits in all but one game remaining for the Giants (3-1) who had been up 15-0 with no sacks over the previous two games.\n",
            "\n",
            "\"We all got through it in a short period of time\n",
            "\n",
            "[100 | 156.65] loss=0.38 avg=0.66\n",
            "[101 | 157.55] loss=0.23 avg=0.65\n",
            "[102 | 158.45] loss=0.26 avg=0.65\n",
            "[103 | 159.34] loss=0.31 avg=0.64\n",
            "[104 | 160.24] loss=0.25 avg=0.63\n",
            "[105 | 161.14] loss=0.32 avg=0.63\n",
            "[106 | 162.03] loss=0.24 avg=0.62\n",
            "[107 | 162.93] loss=0.46 avg=0.62\n",
            "[108 | 163.83] loss=0.35 avg=0.62\n",
            "[109 | 164.73] loss=0.25 avg=0.61\n",
            "[110 | 165.63] loss=0.21 avg=0.61\n",
            "[111 | 166.53] loss=0.26 avg=0.60\n",
            "[112 | 167.42] loss=0.35 avg=0.60\n",
            "[113 | 168.32] loss=0.25 avg=0.59\n",
            "[114 | 169.22] loss=0.26 avg=0.59\n",
            "[115 | 170.12] loss=0.26 avg=0.58\n",
            "[116 | 171.02] loss=0.28 avg=0.58\n",
            "[117 | 171.92] loss=0.28 avg=0.57\n",
            "[118 | 172.82] loss=0.28 avg=0.57\n",
            "[119 | 173.71] loss=0.19 avg=0.56\n",
            "[120 | 174.61] loss=0.23 avg=0.56\n",
            "[121 | 175.51] loss=0.26 avg=0.55\n",
            "[122 | 176.41] loss=0.16 avg=0.55\n",
            "[123 | 177.31] loss=0.17 avg=0.54\n",
            "[124 | 178.21] loss=0.16 avg=0.54\n",
            "[125 | 179.11] loss=0.15 avg=0.53\n",
            "[126 | 180.00] loss=0.20 avg=0.53\n",
            "[127 | 180.90] loss=0.17 avg=0.52\n",
            "[128 | 181.81] loss=0.12 avg=0.52\n",
            "[129 | 182.71] loss=0.19 avg=0.51\n",
            "[130 | 183.61] loss=0.21 avg=0.51\n",
            "[131 | 184.51] loss=0.15 avg=0.50\n",
            "[132 | 185.41] loss=0.26 avg=0.50\n",
            "[133 | 186.31] loss=0.20 avg=0.50\n",
            "[134 | 187.21] loss=0.29 avg=0.49\n",
            "[135 | 188.11] loss=0.19 avg=0.49\n",
            "[136 | 189.01] loss=0.18 avg=0.49\n",
            "[137 | 189.91] loss=0.24 avg=0.48\n",
            "[138 | 190.81] loss=0.14 avg=0.48\n",
            "[139 | 191.71] loss=0.22 avg=0.47\n",
            "[140 | 192.61] loss=0.09 avg=0.47\n",
            "[141 | 193.51] loss=0.18 avg=0.47\n",
            "[142 | 194.41] loss=0.14 avg=0.46\n",
            "[143 | 195.32] loss=0.14 avg=0.46\n",
            "[144 | 196.22] loss=0.11 avg=0.45\n",
            "[145 | 197.12] loss=0.09 avg=0.45\n",
            "[146 | 198.02] loss=0.15 avg=0.44\n",
            "[147 | 198.93] loss=0.15 avg=0.44\n",
            "[148 | 199.83] loss=0.18 avg=0.44\n",
            "[149 | 200.73] loss=0.14 avg=0.43\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            " a \"sick man\" who lived in the house with his family for a few months. He was homeless and had diabetes. In the hallway he sat on his bed wearing only his underwear and had no energy. In the bathroom he had no running water and had to use the toilet all day. He told me about the time he came to visit his grandmother on the morning of the picnic and how she had given him a delicious breakfast and was making sure the rest of the family had sufficient food for dinner. He told me about the time he got dressed up for his job as an energy consultant and went to a nearby park to play basketball. He told me about the time he visited his aunt in the hospital after being hit by a car while playing basketball with her brother, who also played basketball, and was only lightly injured. He told me about his visit to the rehabilitation center and the treatment center for the mentally ill, where he learned about their challenges and received a positive treatment plan. He told me about the treatment center for the substance abuse disorder and its treatment, and was given a copy of their report and a recording of its contents. He told me about his trip to the beach with his friends and saw them having a great time catching the rays of the nearby beach. He told me about the trip to the beach with their friends and seeing them having a fantastic time catching the rays of the nearby beach. He told me about the trip to the beach with their friends and seeing them having a great time catching the rays of the nearby beach. He told me about the trip to the beach with their friends and seeing them having a great time catching the rays of the nearby beach. He told me about the trip to the beach with their friends and seeing them having a great time catching the rays of the nearby beach. he told me about the trip to the beach with their friends and seeing them having a great time catching the rays of the nearby beach\n",
            "\n",
            "26 1/2 years ago\n",
            "\n",
            "<johny>Hi johny,\n",
            "\n",
            "\n",
            "I always loved going to the beach and it was always a big time experience. I loved going to the beach with my friends and taking a tour of the ocean. We enjoyed the view and the views led me here are some of my favorite memories from visiting the beach:\n",
            "\n",
            "\n",
            "I always loved going to the beach with my friends and visiting the ocean with us. We enjoyed the opportunity to spend time with our favorite friends and take a few pictures with them. We also learned a valuable lesson from our time together: don't let people take it up too far.\n",
            "\n",
            "27 1/4 years ago\n",
            "<johny>I recently graduated from college and am working full-time as a web developer. I have been freelancing since high school and have been doing some exciting projects for my future employer. I plan to expand my career and make a significant investment in the future.<br />I recently graduated from college and am studying for my doctorate in management studies. I have been practicing management consulting for a living for about a year and a half now and have begun work on a major project management project management plan management email\n",
            "<p>Thanks for visiting my new blog<br />My blog is a collection of short stories that I have been sharing over the past few months.<br /p><br /div><div class=\"separator\"></div>\n",
            "<p>Thanks for visiting my new favorite blog<br />My favorite blog is a collection of short stories I have been sharing over the past few months<br /><br/><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>><br><br><br><br><br><br><br><\n",
            "\n",
            "[150 | 235.79] loss=0.10 avg=0.43\n",
            "[151 | 236.69] loss=0.14 avg=0.42\n",
            "[152 | 237.59] loss=0.13 avg=0.42\n",
            "[153 | 238.48] loss=0.12 avg=0.42\n",
            "[154 | 239.38] loss=0.10 avg=0.41\n",
            "[155 | 240.28] loss=0.08 avg=0.41\n",
            "[156 | 241.18] loss=0.13 avg=0.41\n",
            "[157 | 242.08] loss=0.10 avg=0.40\n",
            "[158 | 242.98] loss=0.10 avg=0.40\n",
            "[159 | 243.88] loss=0.11 avg=0.39\n",
            "[160 | 244.78] loss=0.11 avg=0.39\n",
            "[161 | 245.68] loss=0.12 avg=0.39\n",
            "[162 | 246.58] loss=0.09 avg=0.38\n",
            "[163 | 247.49] loss=0.12 avg=0.38\n",
            "[164 | 248.39] loss=0.09 avg=0.38\n",
            "[165 | 249.29] loss=0.07 avg=0.37\n",
            "[166 | 250.18] loss=0.07 avg=0.37\n",
            "[167 | 251.08] loss=0.08 avg=0.37\n",
            "[168 | 251.98] loss=0.06 avg=0.36\n",
            "[169 | 252.88] loss=0.10 avg=0.36\n",
            "[170 | 253.78] loss=0.10 avg=0.36\n",
            "[171 | 254.68] loss=0.09 avg=0.35\n",
            "[172 | 255.58] loss=0.11 avg=0.35\n",
            "[173 | 256.48] loss=0.13 avg=0.35\n",
            "[174 | 257.38] loss=0.16 avg=0.34\n",
            "[175 | 258.28] loss=0.10 avg=0.34\n",
            "[176 | 259.18] loss=0.08 avg=0.34\n",
            "[177 | 260.09] loss=0.11 avg=0.34\n",
            "[178 | 260.98] loss=0.10 avg=0.33\n",
            "[179 | 261.88] loss=0.09 avg=0.33\n",
            "[180 | 262.78] loss=0.08 avg=0.33\n",
            "[181 | 263.68] loss=0.06 avg=0.32\n",
            "[182 | 264.58] loss=0.08 avg=0.32\n",
            "[183 | 265.48] loss=0.09 avg=0.32\n",
            "[184 | 266.38] loss=0.10 avg=0.32\n",
            "[185 | 267.28] loss=0.10 avg=0.31\n",
            "[186 | 268.18] loss=0.06 avg=0.31\n",
            "[187 | 269.08] loss=0.06 avg=0.31\n",
            "[188 | 269.98] loss=0.07 avg=0.30\n",
            "[189 | 270.88] loss=0.06 avg=0.30\n",
            "[190 | 271.78] loss=0.10 avg=0.30\n",
            "[191 | 272.68] loss=0.19 avg=0.30\n",
            "[192 | 273.58] loss=0.08 avg=0.29\n",
            "[193 | 274.48] loss=0.10 avg=0.29\n",
            "[194 | 275.38] loss=0.05 avg=0.29\n",
            "[195 | 276.29] loss=0.32 avg=0.29\n",
            "[196 | 277.18] loss=0.07 avg=0.29\n",
            "[197 | 278.09] loss=0.07 avg=0.28\n",
            "[198 | 278.98] loss=0.08 avg=0.28\n",
            "[199 | 279.88] loss=0.06 avg=0.28\n",
            "Saving checkpoint/run1/model-200\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            " also, that she had a great time with her friends and was very understanding. I also enjoyed working with my teammates and learning about their favorite foods and cultures.I would also like to thank my family for everything they have given me and wish them very the best in the future\".\n",
            "<|endoftext|\n",
            "\n",
            "\n",
            "<<< Please defer the receipt for approximately 5 minutes. ********************* .-.o \"I have a fantastic friend named Lucy who is an avid gamer. She enjoys playing video games and watching movies. She is also an avid reader and loves to spend time with her family.\"\n",
            "<|endoftext|\n",
            "\n",
            "\n",
            "<<< Please make certain the following paragraphs have been included. ********************* .-.o Lucy is known for herve been feeding her garden cat Takashi for a few months now. Takashi enjoys pawing over the garden and petting the plants. He is also very caring towards his cat, Tatsuhashi. ********************* .-.o Lucy is considered to be very kind and kind-hearted. She is also very understanding and understanding. She is very caring and kind to those around her. She is also very kind to those in her group. Lucy is extremely understanding and may not even know the name of her best friend. ********************* .-.o Lucy is a very personable and funny lady. She is extremely funny and knows how to make people laugh. She is extremely intelligent and has a passion for music. ********************* .-.o Lucy is extremely talented and is always planning ahead. She is also very artistic and has many different kinds of designs in her collection. She is a talented person with a passion for music and art ********************* .-.o Lucy is considered to be very funny man and woman. She is extremely funny and is very understanding, but she is also caring and understanding. She has a large family of her own and is very caring. ********************* .-.o Lucy is considered to be very funny and kind. She is extremely funny and kind toward all of her friends and family and is completely understanding towards the people she knows. She is also very kind towards those she meets online and knows. She is very protective of her friends and family and treats them with kindness and respect ********************* .-.o Lucy is considered to be very funny and kind. She is extremely funny and kind towards all of her friends and family and is completely understanding towards the people she knows ************* .-.o Lucy is considered to be very kind and kind towards all of her friends. She is extremely kind towards her friends and family and is completely understanding towards the people she knows ************* .-.o Lucy is considered to be very kind towards her best friend Hannah. Hannah is smooth and caring and has a healthy fearlessness in her eyes that makes her people. She is also very kind to her best friend Blake. They are very good friends and have been friends for over 10 years. They greatly value friendship and care for each other everyday ************* .-.o Hannah is a very private girl. She is very intelligent and funny. She is very funny, smooth and caring. She is really considerate and will not hesitate to be her friend. ************* .-.o Hannah is very kind and caring. She is always making sure to please me and every other person she meets. She is also very patient and positive in all of his/her needs. She is a fantastic teacher and friend ************* .-.o Hannah is a very kind and caring person. She is very understanding and knows how to take care of a loved one. She is also very kind and supportive. She is also very kind to strangers' expectations ************* .-.o Hannah is a very kind and caring person. She is always helpful and understanding when needed. She is a great listener and always knows how to tell me how to be more feeling ************* .-.o Hannah is a very kind and caring person. She is always kind to the people she meets and knows how to be with them. She is very compassionate and understanding when it is needed ************* .-.o Hannah is a very kind and generous person. She is very kind and understanding when it is needed. She is very happy to be here and be with people ************* .-.o Hannah is a very kind person. She is very kind to the people she meets. She is very understanding when it is necessary and makes sure to be with them often ************* .-.o Hannah is a very kind person. She is very kind to the people she meets. She is very kind to the people she knows. She is very kind to the strangers she meets ************* .-.o Hannah is a very kind and kind person. She is very kind to the strangers she meets. She is very kind to the people she knows ************* .-.o Hannah is a very kind person. She is a kind person to the strangers she meets. She is a kind person to the strangers she knows ************* .-.o Hannah is a\n",
            "\n",
            "[200 | 316.83] loss=0.08 avg=0.28\n",
            "[201 | 317.73] loss=0.09 avg=0.28\n",
            "[202 | 318.64] loss=0.04 avg=0.27\n",
            "[203 | 319.54] loss=0.06 avg=0.27\n",
            "[204 | 320.45] loss=0.11 avg=0.27\n",
            "[205 | 321.35] loss=0.07 avg=0.27\n",
            "[206 | 322.26] loss=0.07 avg=0.26\n",
            "[207 | 323.17] loss=0.08 avg=0.26\n",
            "[208 | 324.07] loss=0.12 avg=0.26\n",
            "[209 | 324.98] loss=0.07 avg=0.26\n",
            "[210 | 325.89] loss=0.06 avg=0.26\n",
            "[211 | 326.80] loss=0.06 avg=0.25\n",
            "[212 | 327.70] loss=0.10 avg=0.25\n",
            "[213 | 328.61] loss=0.06 avg=0.25\n",
            "[214 | 329.51] loss=0.08 avg=0.25\n",
            "[215 | 330.41] loss=0.06 avg=0.25\n",
            "[216 | 331.31] loss=0.10 avg=0.24\n",
            "[217 | 332.22] loss=0.06 avg=0.24\n",
            "[218 | 333.12] loss=0.06 avg=0.24\n",
            "[219 | 334.02] loss=0.11 avg=0.24\n",
            "[220 | 334.92] loss=0.06 avg=0.24\n",
            "[221 | 335.83] loss=0.08 avg=0.23\n",
            "[222 | 336.73] loss=0.05 avg=0.23\n",
            "[223 | 337.63] loss=0.08 avg=0.23\n",
            "[224 | 338.54] loss=0.06 avg=0.23\n",
            "[225 | 339.44] loss=0.05 avg=0.23\n",
            "[226 | 340.34] loss=0.14 avg=0.23\n",
            "[227 | 341.24] loss=0.07 avg=0.22\n",
            "[228 | 342.14] loss=0.04 avg=0.22\n",
            "[229 | 343.04] loss=0.06 avg=0.22\n",
            "[230 | 343.94] loss=0.04 avg=0.22\n",
            "[231 | 344.84] loss=0.04 avg=0.22\n",
            "[232 | 345.74] loss=0.05 avg=0.21\n",
            "[233 | 346.64] loss=0.07 avg=0.21\n",
            "[234 | 347.54] loss=0.06 avg=0.21\n",
            "[235 | 348.44] loss=0.05 avg=0.21\n",
            "[236 | 349.34] loss=0.06 avg=0.21\n",
            "[237 | 350.24] loss=0.05 avg=0.21\n",
            "[238 | 351.14] loss=0.07 avg=0.20\n",
            "[239 | 352.04] loss=0.06 avg=0.20\n",
            "[240 | 352.94] loss=0.06 avg=0.20\n",
            "[241 | 353.83] loss=0.03 avg=0.20\n",
            "[242 | 354.73] loss=0.06 avg=0.20\n",
            "[243 | 355.63] loss=0.06 avg=0.20\n",
            "[244 | 356.53] loss=0.04 avg=0.19\n",
            "[245 | 357.42] loss=0.05 avg=0.19\n",
            "[246 | 358.33] loss=0.12 avg=0.19\n",
            "[247 | 359.22] loss=0.06 avg=0.19\n",
            "[248 | 360.12] loss=0.07 avg=0.19\n",
            "[249 | 361.02] loss=0.03 avg=0.19\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            "\", [12]  \"I have been studying for my PhD in healthcare technology,\" [13]  \"I have been following the research project on my own and am learning a lot about the technology,\" [14]  \"I plan to continue studying in the future,\"  \"I plan to share my findings with others  \"  \"  \"  \"  \"  \"  I am grateful to have the opportunity to interact with my classmates at the school,\"  \"  \"I have a great work connection with my classmates,\"  \"  \"I am confident that I will make a significant contribution to the university,\"  \"I look forward to continuing my professional development\"  \"I look forward to continuing my career at the University of California at Davis\"  \"I look forward to visiting other renowned universities in the future\"  \"I hope to see my skills as a researcher continued\"  \"I look forward to continuing my career as a food planner\"  \"I look forward to continuing my hobby at the local high-tech shop\"  \"I hope to see the fruits of my labor during my time at the university\"  \"I hope to make a significant contribution to the community by sharing my passion for the arts with my friends and family\"  \"I hope to make a positive impact by being a part of local culture\"  \"I hope to make a significant contribution to the lives of New Yorkers by attending social events\"  \"I hope to make a significant contribution to a major economic project\"  \"I hope to make a significant contribution to a local community by donating large donations to the homeless shelter\"  \"I hope to make a significant contribution to a charitable effort by donating a small amount\"  \"I hope to use my philanthropy to help pay for my college education\"  \"I hope to have a future beyond college\"  \"I am grateful to have the opportunity to serve a large group of friends at a busy local restaurant\"  \"I am also grateful to have the opportunity to network with them through email communication\"  \"I have a passion for music and dance\"  \"I have a passion for the arts and technology\"  \"I have a passion for the good life chances for any given individual\"  \"I have a passion for the economic and environmental well-being of my community\"  \"I have a passion for the positive impact of my business efforts\"  \"I have a passion for the positive impact of the arts and technology\"  \"I have a passion for the good in every aspect of my life\"  \"I have a dream to present to my family in December 2015\"  \"I have a juried M.A. in social work and environmental sciences\"  \"I have a project in the works on my next project management project\"  \"I have a mentor or friend who are also practitioners in the arts\"  \"I have a mentor or friend who is also practicing in the arts\"  \"I have a photography teacher and a sound recording instructor\"  \"I have a book editor who is passionate about creating engaging stories\"  \"I have a photography teacher who is passionate about creating engaging stories\"  \"I have a book reviewer who is passionate about creating engaging stories\"  \"I have a motivational speaker who is passionate about creating engaging stories\"  \"I have a project manager who is passionate about creating engaging stories\"  \"I have a physical therapist who is passionate about creating engaging stories\"  \"I have a financial planner who is passionate about creating engaging stories\"  \"I have a physical therapist who is passionate about creating engaging stories\"  \"I have a speaker who is passionate about creating engaging stories\"  \"I have a project manager who is passionate about creating engaging stories\"  \"I have a physical therapist who is passionate about creating engaging stories\"  \"I have a project manager who is passionate about creating engaging stories\"  \"I have a project manager who is practicing medicine\"  \"I have a project manager who is practicing medicine\"  \"I have a project manager who is practicing medicine\"  \"I have a project manager who is practicing medicine\"  \"I have a project manager who is practicing medicine\"  \"I have a project manager who is practicing medicine\"  \"I have a project manager who is practicing medicine\"  \"Thank you to my family for their continued support and support\"  \"My friends and family for their continued support and support\"  \"My best friend for taking care of me while I was away from them\"  \"My best friend and I have been friends for over 30 years\"  \"My family is truly great\"  \"My best friend is also a doctor\"\n",
            "\n",
            "[250 | 394.87] loss=0.06 avg=0.19\n",
            "[251 | 395.77] loss=0.05 avg=0.19\n",
            "[252 | 396.67] loss=0.07 avg=0.18\n",
            "[253 | 397.56] loss=0.05 avg=0.18\n",
            "[254 | 398.46] loss=0.05 avg=0.18\n",
            "[255 | 399.36] loss=0.04 avg=0.18\n",
            "[256 | 400.26] loss=0.06 avg=0.18\n",
            "[257 | 401.16] loss=0.04 avg=0.18\n",
            "[258 | 402.05] loss=0.03 avg=0.18\n",
            "[259 | 402.95] loss=0.04 avg=0.17\n",
            "[260 | 403.85] loss=0.06 avg=0.17\n",
            "[261 | 404.75] loss=0.04 avg=0.17\n",
            "[262 | 405.65] loss=0.06 avg=0.17\n",
            "[263 | 406.55] loss=0.12 avg=0.17\n",
            "[264 | 407.44] loss=0.05 avg=0.17\n",
            "[265 | 408.34] loss=0.05 avg=0.17\n",
            "[266 | 409.25] loss=0.04 avg=0.17\n",
            "[267 | 410.14] loss=0.04 avg=0.16\n",
            "[268 | 411.04] loss=0.03 avg=0.16\n",
            "[269 | 411.94] loss=0.06 avg=0.16\n",
            "[270 | 412.85] loss=0.05 avg=0.16\n",
            "[271 | 413.75] loss=0.06 avg=0.16\n",
            "[272 | 414.65] loss=0.05 avg=0.16\n",
            "[273 | 415.54] loss=0.05 avg=0.16\n",
            "[274 | 416.45] loss=0.03 avg=0.16\n",
            "[275 | 417.34] loss=0.05 avg=0.15\n",
            "[276 | 418.24] loss=0.05 avg=0.15\n",
            "[277 | 419.14] loss=0.06 avg=0.15\n",
            "[278 | 420.04] loss=0.05 avg=0.15\n",
            "[279 | 420.94] loss=0.05 avg=0.15\n",
            "[280 | 421.84] loss=0.07 avg=0.15\n",
            "[281 | 422.74] loss=0.06 avg=0.15\n",
            "[282 | 423.64] loss=0.06 avg=0.15\n",
            "[283 | 424.54] loss=0.06 avg=0.15\n",
            "[284 | 425.44] loss=0.08 avg=0.15\n",
            "[285 | 426.34] loss=0.05 avg=0.14\n",
            "[286 | 427.24] loss=0.04 avg=0.14\n",
            "[287 | 428.14] loss=0.06 avg=0.14\n",
            "[288 | 429.04] loss=0.05 avg=0.14\n",
            "[289 | 429.94] loss=0.05 avg=0.14\n",
            "[290 | 430.84] loss=0.04 avg=0.14\n",
            "[291 | 431.74] loss=0.05 avg=0.14\n",
            "[292 | 432.65] loss=0.05 avg=0.14\n",
            "[293 | 433.55] loss=0.05 avg=0.14\n",
            "[294 | 434.45] loss=0.06 avg=0.14\n",
            "[295 | 435.35] loss=0.05 avg=0.14\n",
            "[296 | 436.25] loss=0.05 avg=0.13\n",
            "[297 | 437.15] loss=0.05 avg=0.13\n",
            "[298 | 438.05] loss=0.03 avg=0.13\n",
            "[299 | 438.95] loss=0.03 avg=0.13\n",
            "Saving checkpoint/run1/model-300\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            "ening-data> <p>The website provides visitors with the latest the city has to offer, with interactive maps to help them plan their next adventure<\\/p> <p>We hope to make it easier for people to find adventure locations through photography and art<\\/p> <p>We offer a wide variety of destination attractions including beaches, volcanoes, and underwater cultures all in one place, in one beautiful layout. The beauty of this location also informs our mission statement:</p> <p>We believe that being in nature can give us a sense of purpose and purpose is a powerful combination that can lead to positive change. We believe that by planting trees in nature and using nature as a guide, we can help create a better tomorrow<\\/p> <p>We are located in a small hamlet located in the middle of the countryside<\\/p> <p>We enjoy working with nature and having a great time playing nature friendly games<\\/p> <p>We have a nearby shop that allows customers to experiment with different products<\\/p> <p>Located in the heart of the small hamlet, we have a secluded courtyard and quiet street life<\\/p> <p>We offer quality services such as laundry, dishwashing, and heating elements, all of which make for an inviting and comfortable environment<\\/p> <p>We offer free wi-fi and are now friends with the animal department<\\/p> <p>We are excited to explore the nearby cities and try new food types<\\/p> <p>We have a small library in the living room that holds up to 2 books<\\/p> <p>We have a small studio where we share our creative juices and observe their progress<\\/p> <p>We are able to share our musical styles with others and make them more appreciated by others<\\/p> <p>We are also very creative and have a passion for music that goes beyond words<\\/p> <p>We have a passion for the beautiful flowers in the garden and try to keep them out of the way every time we grow them<\\/p> <p>We have a passion for the traditional Japanese dishes and try to recreate traditional Japanese dishes every time we make them<\\/p> <p>We have a small but supportive online community where everyone can point the camera and share their moments of joy with the world<\\/p> <p>We are very visible and considerate in the community and enjoy working with those who matter most to us<\\/p> <p>We are very creative and have a passion for photography*</p> <p>WE ARE CURRENTLY WORKING <7></7> <div class=\"clear clearleft\"> <p>The City of Seattle is an American city located in the State of Washington, US 20018. The City of Seattle is famous for its people, history, and culture. Seattle has been for more than 200 years and is considered one of Europe's great cities. It is a well-known and vibrant city located in the Pacific Northwest and the Westchester County region of New York. It is a large and peaceful borough of over 5,000 residents located in King County, New York. <br> <t>Seattle has been for over 200 years and is considered one of Europe's great cities. It is a well-known and peaceful borough of over 5,000 residents located in King County, New York.</t> </div>\" }, \"$:/core/images/sign\": { \"title\": \"$:/core/images/sign\", \"text\": \"<h2>Signs of the New York Giants\": <a href=\\\"https:\\/\\/www.famitrust.org\\/signs\\/\\\">Signs of the New York Giants</a></h2> <div class=\\\"tc-sign\\\"> </div> <div class=\\\"tc-mfoglis\\\">\n",
            "\n",
            "<div class=\\\"tc-sign mfoglis-gray-gray-white\\\">Sign of the New York Giants</div>\n",
            "\n",
            "\n",
            "<div class=\\\"tc-sign mfoglis-gray-gray-white\\\">Sign of the United States</div>\n",
            "\n",
            "\n",
            "<div class=\\\"tc-sign interlaced-gray tc-gray-gray-gray\\\">\n",
            "\n",
            "\n",
            "<div class=\\\"tc-sign diff tc-txt-gray-gray tc-txt-gray-gray\\\">\n",
            "\n",
            "\n",
            "<div class=\\\"tc-sign >\n",
            "<text>SOUTH LAFAYETTE,</text>\n",
            "\n",
            "\n",
            "<\\/text>\n",
            "\n",
            "\n",
            "<\\/div>\n",
            "\n",
            "\n",
            "<\\/div>\n",
            "\n",
            "\n",
            "<\\/div>\n",
            "\n",
            "\n",
            "<\\/div>\n",
            "\n",
            "\n",
            "<\\/div>\n",
            "\n",
            "\n",
            "<\\/div>\n",
            "\n",
            "\n",
            "<\\/div>\n",
            "\n",
            "\n",
            "<\\/div>\n",
            "\n",
            "\n",
            "<\\/div>\n",
            "\n",
            "\n",
            "<\\/div>\n",
            "\n",
            "\n",
            "<\\/div>\n",
            "\n",
            "\n",
            "<\\/div>\n",
            "\n",
            "\n",
            "<|endof\n",
            "\n",
            "[300 | 474.83] loss=0.03 avg=0.13\n",
            "[301 | 475.74] loss=0.05 avg=0.13\n",
            "[302 | 476.64] loss=0.04 avg=0.13\n",
            "[303 | 477.54] loss=0.05 avg=0.13\n",
            "[304 | 478.45] loss=0.06 avg=0.13\n",
            "[305 | 479.35] loss=0.03 avg=0.13\n",
            "[306 | 480.25] loss=0.03 avg=0.12\n",
            "[307 | 481.16] loss=0.04 avg=0.12\n",
            "[308 | 482.06] loss=0.07 avg=0.12\n",
            "[309 | 482.97] loss=0.06 avg=0.12\n",
            "[310 | 483.87] loss=0.04 avg=0.12\n",
            "[311 | 484.78] loss=0.06 avg=0.12\n",
            "[312 | 485.68] loss=0.06 avg=0.12\n",
            "[313 | 486.59] loss=0.07 avg=0.12\n",
            "[314 | 487.49] loss=0.03 avg=0.12\n",
            "[315 | 488.39] loss=0.08 avg=0.12\n",
            "[316 | 489.30] loss=0.03 avg=0.12\n",
            "[317 | 490.20] loss=0.06 avg=0.12\n",
            "[318 | 491.10] loss=0.05 avg=0.12\n",
            "[319 | 492.00] loss=0.04 avg=0.12\n",
            "[320 | 492.91] loss=0.04 avg=0.11\n",
            "[321 | 493.81] loss=0.04 avg=0.11\n",
            "[322 | 494.71] loss=0.05 avg=0.11\n",
            "[323 | 495.61] loss=0.05 avg=0.11\n",
            "[324 | 496.51] loss=0.05 avg=0.11\n",
            "[325 | 497.41] loss=0.04 avg=0.11\n",
            "[326 | 498.32] loss=0.05 avg=0.11\n",
            "[327 | 499.22] loss=0.04 avg=0.11\n",
            "[328 | 500.12] loss=0.04 avg=0.11\n",
            "[329 | 501.02] loss=0.05 avg=0.11\n",
            "[330 | 501.92] loss=0.06 avg=0.11\n",
            "[331 | 502.82] loss=0.02 avg=0.11\n",
            "[332 | 503.71] loss=0.02 avg=0.11\n",
            "[333 | 504.61] loss=0.04 avg=0.11\n",
            "[334 | 505.51] loss=0.04 avg=0.10\n",
            "[335 | 506.41] loss=0.05 avg=0.10\n",
            "[336 | 507.31] loss=0.04 avg=0.10\n",
            "[337 | 508.21] loss=0.05 avg=0.10\n",
            "[338 | 509.11] loss=0.03 avg=0.10\n",
            "[339 | 510.01] loss=0.02 avg=0.10\n",
            "[340 | 510.91] loss=0.03 avg=0.10\n",
            "[341 | 511.81] loss=0.03 avg=0.10\n",
            "[342 | 512.71] loss=0.03 avg=0.10\n",
            "[343 | 513.61] loss=0.05 avg=0.10\n",
            "[344 | 514.51] loss=0.05 avg=0.10\n",
            "[345 | 515.41] loss=0.03 avg=0.10\n",
            "[346 | 516.31] loss=0.04 avg=0.10\n",
            "[347 | 517.21] loss=0.03 avg=0.10\n",
            "[348 | 518.11] loss=0.04 avg=0.10\n",
            "[349 | 519.01] loss=0.04 avg=0.09\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            "John is a great leader and motivates me to excel in life\")\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I recently took up gardening as a hobby. I love growing my own vegetables and flowers, and watching nature through my plants. I've learned about soil composition, plant care, and the different seasons for planting. I enjoy working with my hands and being in nature, and find it to be a great form of stress relief. I hope to one day have a beautiful and abundant garden that provides for my family and friends. \n",
            "OUTPUT :\n",
            "\"I recently took up gardening as a hobby\",\n",
            "\"I love growing my own vegetables\",\n",
            "\"I love growing my own flowers\",\n",
            "\"I love watching nature through my plants\",\n",
            "\"I have learned about soil composition\",\n",
            "\"I have learned about plant care\",\n",
            "\"I have learned about the different seasons for planting\",\n",
            "\"I enjoy working with my hands\",\n",
            "\"I am in nature\",\n",
            "\"I enjoy working with my eyes are Open\",\n",
            "\"I am a good listener\",\n",
            "\"I always have a garden in me\",\n",
            "\"I garden the garden\",\n",
            "\"I garden the trees in the yard\",\n",
            "\"I grow my own vegetables in the garden\",\n",
            "\"I enjoy working with my hands\",\n",
            "\"I am a good listener\",\n",
            "\"I always have a garden in me\",\n",
            "\"I garden the garden\",\n",
            "\"I garden the trees in the yard\",\n",
            "\"I grow my own vegetables in the garden\",\n",
            "\"I enjoy working with my hands\",\n",
            "\"I am a good listener\",\n",
            "\"I always have a garden in me\",\n",
            "\"I garden the garden\",\n",
            "\"I grow my own vegetables in the garden\",\n",
            "\"I enjoy working with my hands\",\n",
            "\"I am a good listener\",\n",
            "\"I always have a garden in me\",\n",
            "\"I garden the garden\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I am learning how to play the guitar. I love listening to music and always wanted to play an instrument. I've been practicing every day for a few months now and can already play a few songs. I enjoy playing for friends and family and love to see the look on their faces when I play a song they recognize. I hope to one day be able to play for a large audience and share my passion for music with others. \n",
            "OUTPUT :\n",
            "\"I am learning how to play the guitar\",\n",
            "\"I love listening to music\",\n",
            "\"I always wanted to play an instrument\",\n",
            "\"I have been practicing guitar every day for a few months\",\n",
            "\"I can already play a few songs on the guitar\",\n",
            "\"I enjoy playing guitar for friends and family\",\n",
            "\"I love to see the look on their faces when I play a recognizable song\",\n",
            "\"I hope to one day be able to play guitar for a large audience\",\n",
            "\"I hope to share my passion for music with others through guitar playing\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I played a number song for a birthday party last year. It was one of my favorite songs of the year and was a huge hit with friends and family. I had no idea what to do with the song but I loved the way it told a story and made me laugh out loud. I hope to one day be able to play the song for a large audience and share my passion for music with others. \n",
            "OUTPUT :\n",
            "\"I played a number song for a birthday party last year\",\n",
            "\"The song was one of my favorite songs of the year\",\n",
            "\" was a huge hit with friends and family\",\n",
            "\"I had no idea what to do with the song\",\n",
            "\"I loved the way it told a story\",\n",
            "\"I loved the way it told a story made me laugh out loud\",\n",
            "\"I hope to one day be able to play the song for a large audience\",\n",
            "\"I hope to share my passion for music with others through music\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I'm a big fan of movies and TV shows. I enjoy watching different genres such as action, comedy, romance, and sci-fi. I also love to analyze the characters and story lines and predict what will happen next. I have a\n",
            "\n",
            "[350 | 552.75] loss=0.04 avg=0.09\n",
            "[351 | 553.65] loss=0.04 avg=0.09\n",
            "[352 | 554.55] loss=0.05 avg=0.09\n",
            "[353 | 555.45] loss=0.04 avg=0.09\n",
            "[354 | 556.35] loss=0.03 avg=0.09\n",
            "[355 | 557.25] loss=0.04 avg=0.09\n",
            "[356 | 558.15] loss=0.05 avg=0.09\n",
            "[357 | 559.05] loss=0.04 avg=0.09\n",
            "[358 | 559.95] loss=0.03 avg=0.09\n",
            "[359 | 560.85] loss=0.03 avg=0.09\n",
            "[360 | 561.74] loss=0.03 avg=0.09\n",
            "[361 | 562.64] loss=0.06 avg=0.09\n",
            "[362 | 563.54] loss=0.03 avg=0.09\n",
            "[363 | 564.44] loss=0.03 avg=0.09\n",
            "[364 | 565.34] loss=0.06 avg=0.09\n",
            "[365 | 566.24] loss=0.04 avg=0.09\n",
            "[366 | 567.14] loss=0.02 avg=0.09\n",
            "[367 | 568.04] loss=0.04 avg=0.09\n",
            "[368 | 568.94] loss=0.02 avg=0.08\n",
            "[369 | 569.84] loss=0.04 avg=0.08\n",
            "[370 | 570.74] loss=0.04 avg=0.08\n",
            "[371 | 571.64] loss=0.02 avg=0.08\n",
            "[372 | 572.54] loss=0.06 avg=0.08\n",
            "[373 | 573.44] loss=0.04 avg=0.08\n",
            "[374 | 574.34] loss=0.04 avg=0.08\n",
            "[375 | 575.24] loss=0.04 avg=0.08\n",
            "[376 | 576.14] loss=0.04 avg=0.08\n",
            "[377 | 577.04] loss=0.04 avg=0.08\n",
            "[378 | 577.94] loss=0.02 avg=0.08\n",
            "[379 | 578.84] loss=0.05 avg=0.08\n",
            "[380 | 579.74] loss=0.03 avg=0.08\n",
            "[381 | 580.64] loss=0.03 avg=0.08\n",
            "[382 | 581.54] loss=0.03 avg=0.08\n",
            "[383 | 582.44] loss=0.03 avg=0.08\n",
            "[384 | 583.34] loss=0.04 avg=0.08\n",
            "[385 | 584.24] loss=0.02 avg=0.08\n",
            "[386 | 585.14] loss=0.04 avg=0.08\n",
            "[387 | 586.04] loss=0.03 avg=0.08\n",
            "[388 | 586.94] loss=0.03 avg=0.08\n",
            "[389 | 587.84] loss=0.04 avg=0.08\n",
            "[390 | 588.74] loss=0.03 avg=0.07\n",
            "[391 | 589.65] loss=0.02 avg=0.07\n",
            "[392 | 590.55] loss=0.04 avg=0.07\n",
            "[393 | 591.45] loss=0.04 avg=0.07\n",
            "[394 | 592.35] loss=0.04 avg=0.07\n",
            "[395 | 593.25] loss=0.03 avg=0.07\n",
            "[396 | 594.15] loss=0.04 avg=0.07\n",
            "[397 | 595.06] loss=0.04 avg=0.07\n",
            "[398 | 595.96] loss=0.04 avg=0.07\n",
            "[399 | 596.86] loss=0.02 avg=0.07\n",
            "Saving checkpoint/run1/model-400\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            " in different countries, each country had its own unique flavour profile for its products. \n",
            "TO BE PART OF \n",
            " \n",
            "RIO APACHEON  \n",
            "riopocalypse.com is a leading resource for travellers planning a new trip to Europe. It provides a robust catalogue of destinations and offers up a variety of accommodation options, including private motels, night-time hotels, and online booking. It features the latest news, reviews, and booking tips. \n",
            "RIO PORTUGAL  \n",
            "riverportapocalypse.com is a British travel website founded in 2007. It was acquired by Virgin in 2006 and has grown to become one of the largest travel destinations in the world. It has been in the news a number of times and been featured in publications such as Travelers' Newswire, Travelocity, and RRPnet. It has been featured in several TV and Film films, won several awards, and have sold over 200,000 copies. \n",
            "WEEKLY TRIALS  \n",
            "On Sunday, January 30, 2013, I had the nerve to take a trip to the Europe exhibition at the British Museum. It was a transformative experience that included the opportunity to explore the history and culture of different countries in Europe and learn about their customs, customs solutions, and food. I also sat down with masters of the arts experts to discuss my point of view on each country and their unique culture. I also had the opportunity to interact with members of the public and heard their stories, and it was an eye-opening experience. \n",
            "WEEKEND BLUR\n",
            "On Monday, February 2, 2013, I had the luxury of staying in Paris for a three-day trip that involved visiting the TGV train stations and discovering the history of each of the major cities in France, as well as seeing historical landmarks and historical architecture. I also had the chance to learn about the daily lives of prominent figures in France, from Napoleon to Bismarck, and much more. I ended the trip with a candid telephone call that helped to shape my thoughts about this important event and allowed me to focus on all of the important points in my trip. I can't wait to continue to explore France and make more memories. \n",
            "RIO STRETCH GOAL  \n",
            "I have a hard time believing that I can make it to the 2014 Paris International Film Festival, which kicks off on March 24th. I plan to attend the shoot in person and then have a dinner with my friends there on the evening before the shoot, which is going to be a great look into the lives of the FILM FILMS and their fans. I also have some amazing plans in the works for the next few years, such as planning a trip to Japan next year to attend the Film Festival, and acting in Japan this year. \n",
            "RIO STRETCH GOAL  \n",
            "\"I have been working on a screenplay for a movie for my future book project\", \"I have finished writing the screenplay for the movie\", and \"I am writing a book project book about my love for movies\" were all very helpful steps in making this dream come true. I can't wait to make more memories of my amazing years with my family and friends. \n",
            "DAVE KEELER I am so happy to be a part of something so important. I hope to see more of my favorite people in the future. I hope to share my passion for art with others through photography and video games. I hope to connect with my fans on social media and find a special connection with my songs. It is a very humbling experience and a privilege to be a part of it. \n",
            "DAVE KEELER I am so grateful to have such a wonderful friend like my husband in life. He is truly a great friend and I am thankful to have him in my life. He is also very talented and has a passion for music and art. He is truly my friend and I am grateful to have him in my life. \n",
            "MARTIN SAMARSEN I am so grateful to have such a great family. My great-aunt had been a nurse for 5 years and spent her time helping out her community and visiting her favorite places. She was also very kind and supportive, always giving me everything she had. She is such a great friend and I am grateful to have her in my life. \n",
            "PAULO HERMIAULTTI I am so grateful to have such a wonderful and amazing husband. He is truly a great man and I am grateful to have him in me. He is truly a great friend and I am grateful to have him in my life. \n",
            "LAURA KEANE In July of 2012, I had the time of my life and finished my college studies. I had breakfast with a friend and then went to the movies with my friends. After that, we went to a local restaurant and enjoyed the scenery while drinking wine and eating pizza. It was a memorable weekend and I am truly grateful to have such a wonderful husband like\n",
            "\n",
            "[400 | 632.82] loss=0.03 avg=0.07\n",
            "[401 | 633.72] loss=0.02 avg=0.07\n",
            "[402 | 634.62] loss=0.05 avg=0.07\n",
            "[403 | 635.52] loss=0.02 avg=0.07\n",
            "[404 | 636.43] loss=0.04 avg=0.07\n",
            "[405 | 637.33] loss=0.14 avg=0.07\n",
            "[406 | 638.23] loss=0.03 avg=0.07\n",
            "[407 | 639.13] loss=0.02 avg=0.07\n",
            "[408 | 640.03] loss=0.03 avg=0.07\n",
            "[409 | 640.93] loss=0.03 avg=0.07\n",
            "[410 | 641.83] loss=0.04 avg=0.07\n",
            "[411 | 642.73] loss=0.04 avg=0.07\n",
            "[412 | 643.63] loss=0.03 avg=0.07\n",
            "[413 | 644.53] loss=0.04 avg=0.07\n",
            "[414 | 645.44] loss=0.05 avg=0.07\n",
            "[415 | 646.34] loss=0.03 avg=0.07\n",
            "[416 | 647.24] loss=0.03 avg=0.07\n",
            "[417 | 648.14] loss=0.04 avg=0.07\n",
            "[418 | 649.04] loss=0.04 avg=0.07\n",
            "[419 | 649.94] loss=0.02 avg=0.07\n",
            "[420 | 650.84] loss=0.03 avg=0.06\n",
            "[421 | 651.74] loss=0.02 avg=0.06\n",
            "[422 | 652.64] loss=0.02 avg=0.06\n",
            "[423 | 653.55] loss=0.04 avg=0.06\n",
            "[424 | 654.44] loss=0.05 avg=0.06\n",
            "[425 | 655.34] loss=0.03 avg=0.06\n",
            "[426 | 656.24] loss=0.02 avg=0.06\n",
            "[427 | 657.14] loss=0.03 avg=0.06\n",
            "[428 | 658.04] loss=0.03 avg=0.06\n",
            "[429 | 658.94] loss=0.03 avg=0.06\n",
            "[430 | 659.84] loss=0.02 avg=0.06\n",
            "[431 | 660.74] loss=0.04 avg=0.06\n",
            "[432 | 661.64] loss=0.04 avg=0.06\n",
            "[433 | 662.54] loss=0.03 avg=0.06\n",
            "[434 | 663.45] loss=0.05 avg=0.06\n",
            "[435 | 664.34] loss=0.04 avg=0.06\n",
            "[436 | 665.24] loss=0.03 avg=0.06\n",
            "[437 | 666.14] loss=0.04 avg=0.06\n",
            "[438 | 667.04] loss=0.03 avg=0.06\n",
            "[439 | 667.94] loss=0.02 avg=0.06\n",
            "[440 | 668.84] loss=0.03 avg=0.06\n",
            "[441 | 669.74] loss=0.04 avg=0.06\n",
            "[442 | 670.64] loss=0.04 avg=0.06\n",
            "[443 | 671.54] loss=0.04 avg=0.06\n",
            "[444 | 672.44] loss=0.02 avg=0.06\n",
            "[445 | 673.34] loss=0.02 avg=0.06\n",
            "[446 | 674.25] loss=0.04 avg=0.06\n",
            "[447 | 675.14] loss=0.03 avg=0.06\n",
            "[448 | 676.05] loss=0.02 avg=0.06\n",
            "[449 | 676.95] loss=0.03 avg=0.06\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            "\n",
            "\n",
            "She smiled and said,\n",
            "\n",
            "\"Today, I had a busy day at work. I started the day with a project update and then went shopping for something to wear tomorrow. I also had a meeting with my team to discuss the results of my project and ended the day with a team meeting to discuss our next move. I was very happy with the outcome of the meeting and went back to my seat in the room to sleep goodnight.\" \"I am truly grateful to have Sarah in my life\"\n",
            "\"She is a truly amazing person who stands up for what is right and for others to stand up for what is wrong\" \"I am grateful to have such a wonderful friend like Sarah in my life\" \"I hope to one day have a wonderful and successful career\"\n",
            "\"I hope to one day have a beautiful and successful family\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today was an amazing day for me. I had the busy day at school and finished up some important projects before going to bed. After school, I went to the gym and did some activity for my future plans, and then back home I went to bed early to get a good night's sleep. I was also very thankful to have such a wonderful friend like Sarah in my life. She made me feel at home and made me feel good about things. She was also very kind and understanding, and I'm grateful to have her in my life. \n",
            "OUTPUT :\n",
            "\"Today was an amazing day for me.\"\n",
            "\"I had the busy day at school and finished up some important projects before going to bed. After school, I went to the gym and did some activity for my future plans, and then back home I went to bed early to get a good night's sleep.\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Yesterday was a busy day as I had a busy work session at the office. I also had a meeting with my team to discuss the progress of our latest project and it was a productive meeting. Afterwards, I went to the library to check my papers and found a quiet nearby, and I wandered around the library looking for anything that might help me this morning. I determined today would be a good day forward and decided to go ahead and study for my exams next week. \n",
            "OUTPUT :\n",
            "\"Yesterday was a busy day as I had a busy work session at the office. I also had a meeting with my team to discuss the progress of our latest project and it was a productive meeting. Afterwards, I went to the library to check my papers and found a quiet nearby, and I wandered around the library looking for anything that might help me this morning.\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Last night, I had a great time with my friends at dinner. We talked about our favorite dishes, watched movies, and played games. I tried to avoid being too formal, but it made me feel comfortable talking about my feelings about them. I also tried to find quiet moments in the conversation where I could say something positive and constructive. \n",
            "OUTPUT :\n",
            "\"Last night I had a great time with my friends at dinner.\"\n",
            "\"We talked about our favorite dishes, watched movies, and played games. I tried to avoid being too formal, but it made me feel comfortable talking about my feelings about them. I also tried to find quiet moments in the conversation where I could say something positive and constructive. \n",
            "OUTPUT :\n",
            "\"Last night I had a great time with my friends at dinner.\"\n",
            "\"We talked about our favorite dishes, watched movies, and played games.\".\".\".\"I tried to avoid being too formal, but it made me feel comfortable talking about my feelings about them.\" I tried to find quiet moments in the conversation where I could say something positive and constructive. \n",
            "OUTPUT :\n",
            "\"Last night I had a great time with my friends at dinner.\"\n",
            "\"We talked about our favorite dishes.\".\".\"We talked about our favorite dishes.\".\"We also played games.\".\".\"I tried to avoid being too formal, but it made me feel comfortable talking about my feelings about them.\" I tried to find quiet moments in the conversation where I could say something positive and constructive. \n",
            "OUTPUT :\n",
            "\"Last night I had a great time with my friends at dinner.\"\n",
            "\"We talked about our favorite dishes.\".\"We talked about our favorite dishes.\".\"We also played games.\".\".\"I tried to avoid\n",
            "\n",
            "[450 | 709.99] loss=0.04 avg=0.06\n",
            "[451 | 710.90] loss=0.02 avg=0.06\n",
            "[452 | 711.80] loss=0.03 avg=0.06\n",
            "[453 | 712.70] loss=0.03 avg=0.06\n",
            "[454 | 713.59] loss=0.02 avg=0.06\n",
            "[455 | 714.49] loss=0.02 avg=0.05\n",
            "[456 | 715.38] loss=0.03 avg=0.05\n",
            "[457 | 716.28] loss=0.04 avg=0.05\n",
            "[458 | 717.18] loss=0.03 avg=0.05\n",
            "[459 | 718.08] loss=0.04 avg=0.05\n",
            "[460 | 718.98] loss=0.03 avg=0.05\n",
            "[461 | 719.88] loss=0.05 avg=0.05\n",
            "[462 | 720.77] loss=0.04 avg=0.05\n",
            "[463 | 721.67] loss=0.03 avg=0.05\n",
            "[464 | 722.57] loss=0.03 avg=0.05\n",
            "[465 | 723.47] loss=0.04 avg=0.05\n",
            "[466 | 724.37] loss=0.02 avg=0.05\n",
            "[467 | 725.27] loss=0.01 avg=0.05\n",
            "[468 | 726.17] loss=0.04 avg=0.05\n",
            "[469 | 727.07] loss=0.04 avg=0.05\n",
            "[470 | 727.97] loss=0.03 avg=0.05\n",
            "[471 | 728.87] loss=0.03 avg=0.05\n",
            "[472 | 729.77] loss=0.03 avg=0.05\n",
            "[473 | 730.66] loss=0.02 avg=0.05\n",
            "[474 | 731.56] loss=0.02 avg=0.05\n",
            "[475 | 732.46] loss=0.03 avg=0.05\n",
            "[476 | 733.36] loss=0.02 avg=0.05\n",
            "[477 | 734.26] loss=0.02 avg=0.05\n",
            "[478 | 735.16] loss=0.04 avg=0.05\n",
            "[479 | 736.06] loss=0.04 avg=0.05\n",
            "[480 | 736.96] loss=0.04 avg=0.05\n",
            "[481 | 737.87] loss=0.04 avg=0.05\n",
            "[482 | 738.77] loss=0.06 avg=0.05\n",
            "[483 | 739.67] loss=0.03 avg=0.05\n",
            "[484 | 740.57] loss=0.04 avg=0.05\n",
            "[485 | 741.47] loss=0.03 avg=0.05\n",
            "[486 | 742.37] loss=0.03 avg=0.05\n",
            "[487 | 743.27] loss=0.03 avg=0.05\n",
            "[488 | 744.17] loss=0.03 avg=0.05\n",
            "[489 | 745.07] loss=0.04 avg=0.05\n",
            "[490 | 745.97] loss=0.04 avg=0.05\n",
            "[491 | 746.87] loss=0.03 avg=0.05\n",
            "[492 | 747.77] loss=0.03 avg=0.05\n",
            "[493 | 748.67] loss=0.02 avg=0.05\n",
            "[494 | 749.58] loss=0.03 avg=0.05\n",
            "[495 | 750.48] loss=0.03 avg=0.05\n",
            "[496 | 751.38] loss=0.03 avg=0.05\n",
            "[497 | 752.29] loss=0.03 avg=0.05\n",
            "[498 | 753.19] loss=0.02 avg=0.05\n",
            "[499 | 754.09] loss=0.03 avg=0.05\n",
            "Saving checkpoint/run1/model-500\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            "i'm sorry.\" I said, \"I only have a single hand and a small room, but I love the feel of the blankets around my body and the comfortable mattress over my body.\"\n",
            "\"I can't wait to get to work on time\",\n",
            "\"I have a meeting with my team in the evening\",\n",
            "\"I'm planning to have dinner with my friends in the evening\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today at work, I had a busy day as usual, finishing up projects and meeting with clients. I also attended a training session on time management skills and had a one-on-one with my team to go over my skills, I then went for a team chat and had a cooking session, and then took a team photo I was good to go as was the meeting leader. I ended the day with 100% positive feedback and a 5.0\" a.k.a. \"I had a busy day\",\n",
            "\"I finished up projects and met with clients\",\n",
            "\"I attended a training session on time management skills\",\n",
            "\"I had a one-on-one with my team to go over my skills\",\n",
            "\"I had a one-and-one with my boss to go over my work\",\n",
            "\"I had a cooking session on time management skills\",\n",
            "\"I had a meeting with my team on time management skills\",\n",
            "\"I had a training session on time management skills\",\n",
            "\"I had a meeting on time management skills\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today, I woke up early and went for a jog in the park. After breakfast, I had a busy day finishing up projects and meeting with clients. I also had a one-on-one with my team to go over my skills, I had a one-on-one with my boss to go over my work, and then I had a one-on-one with my manager with the problem and solution interviews to go over today, it was a very busy day. \n",
            "OUTPUT :\n",
            "\"I woke up early today\",\n",
            "\"I went for a jog in the park\",\n",
            "\"I had a busy day finishing up projects and meeting with clients\",\n",
            "\"I had a one-on-one with my boss\",\n",
            "\"I had a busy day finishing up projects with meeting with clients\",\n",
            "\"I had a one-on-one boss with project interviews to go over today\",\n",
            "\"It was a very busy day\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today I woke up lazy and went for a jog in the park. After breakfast, I had a busy day finishing up projects and meeting with clients. I had a one-on-one with my boss to go over my skills, I had a one-on-one boss with boss interviews to go over today, it was a very busy day. \n",
            "OUTPUT :\n",
            "\"Today I woke up lazy\",\n",
            "\"I went for a jog in the park\",\n",
            "\"I had a busy day finishing up projects in the park\",\n",
            "\"I had a one-on-one boss\",\n",
            "\"I had boss interviews to go over today\",\n",
            "\"It was a busy day\",\n",
            "\"I had boss meetings to go over today\",\n",
            "\"It was a busy day\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I woke up lazy today but didn't seem to be too lazy to catch a flight or find a hotel room. I would usually go for a walk in the morning but then I went to the library and tried walking for 5 hours. I caught a lot of how-to-cast-a-walk-in-the-day-but-it-did-not-mean-it-did-Iwk 5 I spent the entire day being lazy but I also had a lot of inspiration in my eyes. \n",
            "OUTPUT :\n",
            "\"I woke up lazy today\",\n",
            "\"I didn't seem to be too lazy to catch a flight\",\n",
            "\"I had a walk in the morning\",\n",
            "\"I caught a lot of how-to-cast-a-walk-in-the-day\",\n",
            "\"I went for a walk in the morning\",\n",
            "\"I caught a walk in the morning\",\n",
            "\"I caught a\n",
            "\n",
            "[500 | 790.07] loss=0.04 avg=0.05\n",
            "[501 | 790.97] loss=0.02 avg=0.05\n",
            "[502 | 791.87] loss=0.03 avg=0.05\n",
            "[503 | 792.78] loss=0.03 avg=0.05\n",
            "[504 | 793.68] loss=0.03 avg=0.05\n",
            "[505 | 794.58] loss=0.02 avg=0.05\n",
            "[506 | 795.48] loss=0.03 avg=0.05\n",
            "[507 | 796.38] loss=0.02 avg=0.04\n",
            "[508 | 797.28] loss=0.04 avg=0.04\n",
            "[509 | 798.18] loss=0.04 avg=0.04\n",
            "[510 | 799.08] loss=0.05 avg=0.04\n",
            "[511 | 799.98] loss=0.03 avg=0.04\n",
            "[512 | 800.89] loss=0.04 avg=0.04\n",
            "[513 | 801.79] loss=0.03 avg=0.04\n",
            "[514 | 802.69] loss=0.02 avg=0.04\n",
            "[515 | 803.59] loss=0.02 avg=0.04\n",
            "[516 | 804.49] loss=0.03 avg=0.04\n",
            "[517 | 805.39] loss=0.02 avg=0.04\n",
            "[518 | 806.29] loss=0.02 avg=0.04\n",
            "[519 | 807.19] loss=0.02 avg=0.04\n",
            "[520 | 808.09] loss=0.03 avg=0.04\n",
            "[521 | 808.99] loss=0.03 avg=0.04\n",
            "[522 | 809.89] loss=0.03 avg=0.04\n",
            "[523 | 810.79] loss=0.02 avg=0.04\n",
            "[524 | 811.69] loss=0.05 avg=0.04\n",
            "[525 | 812.59] loss=0.02 avg=0.04\n",
            "[526 | 813.49] loss=0.04 avg=0.04\n",
            "[527 | 814.39] loss=0.02 avg=0.04\n",
            "[528 | 815.29] loss=0.02 avg=0.04\n",
            "[529 | 816.19] loss=0.03 avg=0.04\n",
            "[530 | 817.09] loss=0.02 avg=0.04\n",
            "[531 | 818.00] loss=0.04 avg=0.04\n",
            "[532 | 818.89] loss=0.04 avg=0.04\n",
            "[533 | 819.79] loss=0.04 avg=0.04\n",
            "[534 | 820.69] loss=0.03 avg=0.04\n",
            "[535 | 821.59] loss=0.04 avg=0.04\n",
            "[536 | 822.49] loss=0.03 avg=0.04\n",
            "[537 | 823.39] loss=0.03 avg=0.04\n",
            "[538 | 824.30] loss=0.02 avg=0.04\n",
            "[539 | 825.20] loss=0.03 avg=0.04\n",
            "[540 | 826.10] loss=0.02 avg=0.04\n",
            "[541 | 827.00] loss=0.01 avg=0.04\n",
            "[542 | 827.90] loss=0.03 avg=0.04\n",
            "[543 | 828.80] loss=0.03 avg=0.04\n",
            "[544 | 829.70] loss=0.04 avg=0.04\n",
            "[545 | 830.59] loss=0.03 avg=0.04\n",
            "[546 | 831.49] loss=0.04 avg=0.04\n",
            "[547 | 832.39] loss=0.01 avg=0.04\n",
            "[548 | 833.29] loss=0.03 avg=0.04\n",
            "[549 | 834.19] loss=0.03 avg=0.04\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            "hed on them and told them to keep quiet and enjoy each other's company. \n",
            "OUTPUT :\n",
            "\"I recently started volunteering at a local animal shelter\",\n",
            "\"I help care for the animals at the shelter\",\n",
            "\"I clean the cages of the animals at the shelter\",\n",
            "\"I play with the animals at the shelter\",\n",
            "\"Volunteering at the shelter has been a rewarding experience\",\n",
            "\"Volunteering at the shelter has given me a sense of purpose\",\n",
            "\"I am learning a lot about different animal breeds\",\n",
            "\"I am learning how to take care of different animal breeds\",\n",
            "\"I hope to continue volunteering at the shelter\",\n",
            "\"I hope to make a positive impact in the lives of the animals at the shelter\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I recently started a new job as a project manager. I'm excited to take on new challenges and responsibilities. I have a great team of coworkers who are supportive and knowledgeable. I enjoy learning about the latest project management techniques and finding creative solutions to problems. I'm confident that I will excel in this role and make a significant contribution to the company. \n",
            "OUTPUT :\n",
            "\"I recently started a new job as a project manager\",\n",
            "\"I am excited to take on new challenges as a project manager\",\n",
            "\"I am excited to take on new responsibilities as a project manager\",\n",
            "\"I have a great team of coworkers\",\n",
            "\"My coworkers are supportive\",\n",
            "\"My coworkers are knowledgeable\",\n",
            "\"I enjoy learning about the latest project management techniques\",\n",
            "\"I enjoy finding creative solutions to problems\",\n",
            "\"I am confident that I will excel in my role as a project manager\",\n",
            "\"I am confident that I will make a significant contribution to the company\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I recently took on a new role as a project manager. I am excited to take on new challenges as a project manager. I have a great team of coworkers who are supportive and knowledgeable. I enjoy learning about the latest project management techniques and finding creative solutions to problems. I am confident that I will excel in my role as a project manager\" \n",
            "OUTPUT :\n",
            "\"I recently took on a new role as a project manager\",\n",
            "\"I am excited to take on new challenges as a project manager\",\n",
            "\"I am excited to take on new responsibilities as a project manager\",\n",
            "\"I have a great team of coworkers\",\n",
            "\"My coworkers are supportive\",\n",
            "\"My coworkers are knowledgeable\",\n",
            "\"I enjoy learning about the latest project management techniques\",\n",
            "\"I enjoy finding creative solutions to problems\",\n",
            "\"I am confident that I will excel in my role as a project manager\" \n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I recently started a new hobby of photography. I love taking pictures of nature, architecture, and people. I've learned a lot about composition and lighting, and enjoy experimenting with different techniques. I have a passion for capturing the beauty in everyday moments and preserving them forever. I hope to continue to improve my skills and one day have a photography exhibit of my own. \n",
            "OUTPUT :\n",
            "\"I recently started a new hobby of photography\",\n",
            "\"I love taking pictures of nature\",\n",
            "\"I love taking pictures of architecture\",\n",
            "\"I love taking pictures of people\",\n",
            "\"I have learned a lot about composition in photography\",\n",
            "\"I have learned a lot about lighting in photography\",\n",
            "\"I enjoy experimenting with different photography techniques\",\n",
            "\"I have a passion for capturing the beauty in everyday moments\",\n",
            "\"I have a passion for preserving moments through photography\",\n",
            "\"I hope to continue to improve my photography skills\",\n",
            "\"I hope to one day have a photography exhibit of my own\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I recently took up gardening as a hobby. I love growing my own vegetables and flowers, and being able to see the fruits of my labor. I've learned about soil composition, plant care, and the different seasons for planting. I enjoy working with my hands and being in nature, and find it to be a great form of stress relief. I hope to one day have a beautiful and abundant garden that supports my creative urges and allows me to function better. \n",
            "OUTPUT :\n",
            "\n",
            "\n",
            "[550 | 867.42] loss=0.04 avg=0.04\n",
            "[551 | 868.31] loss=0.02 avg=0.04\n",
            "[552 | 869.21] loss=0.02 avg=0.04\n",
            "[553 | 870.11] loss=0.01 avg=0.04\n",
            "[554 | 871.01] loss=0.02 avg=0.04\n",
            "[555 | 871.90] loss=0.02 avg=0.04\n",
            "[556 | 872.80] loss=0.03 avg=0.04\n",
            "[557 | 873.70] loss=0.02 avg=0.04\n",
            "[558 | 874.60] loss=0.02 avg=0.04\n",
            "[559 | 875.50] loss=0.03 avg=0.04\n",
            "[560 | 876.40] loss=0.02 avg=0.04\n",
            "[561 | 877.30] loss=0.02 avg=0.04\n",
            "[562 | 878.20] loss=0.04 avg=0.04\n",
            "[563 | 879.10] loss=0.03 avg=0.04\n",
            "[564 | 880.00] loss=0.02 avg=0.04\n",
            "[565 | 880.90] loss=0.03 avg=0.04\n",
            "[566 | 881.80] loss=0.03 avg=0.04\n",
            "[567 | 882.70] loss=0.03 avg=0.04\n",
            "[568 | 883.59] loss=0.02 avg=0.04\n",
            "[569 | 884.49] loss=0.03 avg=0.04\n",
            "[570 | 885.39] loss=0.03 avg=0.04\n",
            "[571 | 886.29] loss=0.01 avg=0.04\n",
            "[572 | 887.19] loss=0.03 avg=0.04\n",
            "[573 | 888.09] loss=0.03 avg=0.04\n",
            "[574 | 888.99] loss=0.02 avg=0.04\n",
            "[575 | 889.89] loss=0.02 avg=0.04\n",
            "[576 | 890.79] loss=0.03 avg=0.04\n",
            "[577 | 891.69] loss=0.02 avg=0.04\n",
            "[578 | 892.59] loss=0.02 avg=0.04\n",
            "[579 | 893.49] loss=0.03 avg=0.04\n",
            "[580 | 894.40] loss=0.03 avg=0.04\n",
            "[581 | 895.30] loss=0.03 avg=0.04\n",
            "[582 | 896.19] loss=0.02 avg=0.04\n",
            "[583 | 897.09] loss=0.04 avg=0.04\n",
            "[584 | 897.99] loss=0.03 avg=0.04\n",
            "[585 | 898.89] loss=0.02 avg=0.04\n",
            "[586 | 899.79] loss=0.03 avg=0.04\n",
            "[587 | 900.69] loss=0.09 avg=0.04\n",
            "[588 | 901.59] loss=0.02 avg=0.04\n",
            "[589 | 902.50] loss=0.02 avg=0.04\n",
            "[590 | 903.40] loss=0.10 avg=0.04\n",
            "[591 | 904.30] loss=0.02 avg=0.04\n",
            "[592 | 905.20] loss=0.02 avg=0.04\n",
            "[593 | 906.10] loss=0.03 avg=0.04\n",
            "[594 | 907.00] loss=0.02 avg=0.04\n",
            "[595 | 907.91] loss=0.02 avg=0.04\n",
            "[596 | 908.81] loss=0.02 avg=0.04\n",
            "[597 | 909.71] loss=0.07 avg=0.04\n",
            "[598 | 910.60] loss=0.03 avg=0.04\n",
            "[599 | 911.50] loss=0.02 avg=0.04\n",
            "Saving checkpoint/run1/model-600\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py:1066: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py:1066: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            " instrument and piano\",\n",
            "\"John has been a volunteer at a local animal shelter for 10 years\",\n",
            "\"John is a nice guy who always has a smile on his face\",\n",
            "\"John is also very kind\",\n",
            "\"John is concerned about the well-being of the animals in his life\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today I had a math test and a science quiz, I studied hard for both but only got a D in math and a B in science, my teacher said I need to work on my problem solving skills and practice more for my future exams \n",
            "OUTPUT :\n",
            "\"Today I had a math test\",\n",
            "\"Today I had a science quiz\",\n",
            "\"I studied hard for both math test and science quiz\",\n",
            "\"I got a B in math test\",\n",
            "\"I got a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I went to the library after school to study for my exams, I found a quiet corner and started studying, I studied for 2 hours and then I decided to take a break, I walked around the library and saw my friend John who was also studying, we talked for a while and then I went back to my seat and continued studying. \n",
            "OUTPUT :\n",
            "\"I went to the library after school to study for my exams\",\n",
            "\"I found a quiet corner in the library and started studying\",\n",
            "\"I studied for 2 hours\",\n",
            "\"I decided to take a break from studying\",\n",
            "\"I walked around the library\",\n",
            "\"I saw my friend John who was also studying\",\n",
            "\"We talked for a while\",\n",
            "\"I went back to my seat and continued studying\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I had a great time playing basketball with my friends and my favorite team won the game, we also went to a nearby restaurant and tried new dishes, it was a fantastic day overall. \n",
            "OUTPUT :\n",
            "\"I had a great time playing basketball with my friends\",\n",
            "\"my favorite team won the game\",\n",
            "\"we also went to a nearby restaurant\",\n",
            "\"we tried new dishes at the restaurant\",\n",
            "\"it was a fantastic day overall\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I went to the library today and studied for my exams, I also attended a workshop on how to study effectively and learned some new techniques, I finished my day by going for a walk in the park and listening to music \n",
            "OUTPUT :\n",
            "\"I went to the library today\",\n",
            "\"I studied for my exams at the university\",\n",
            "\"I attended a workshop on how to study effectively\",\n",
            "\"I learned some new techniques in the workshop\",\n",
            "\"I finished my day by going for a walk in the park\",\n",
            "\"I listened to music while walking in the park\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I had a meeting with my boss and the CEO of the company this morning and discussed the progress of our project and discussed the budget for the next quarter. Afterwards, I worked on the report for the project and sent it to my team and then went to the gym and had a great workout \n",
            "OUTPUT :\n",
            "\"I had a meeting with my boss and the CEO of the company this morning\",\n",
            "\"In the meeting, we discussed the progress of our project\",\n",
            "\"We also discussed the budget for the next quarter\",\n",
            "\"Afterwards, I worked on the report for the project\",\n",
            "\"I sent it to my team\",\n",
            "\"I then went to the gym\",\n",
            "\"I had a great workout at the gym\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today I woke up early, went for a jog and did my daily chores\n",
            "\n",
            "[600 | 946.69] loss=0.02 avg=0.04\n",
            "[601 | 947.59] loss=0.02 avg=0.04\n",
            "[602 | 948.49] loss=0.04 avg=0.04\n",
            "[603 | 949.40] loss=0.02 avg=0.03\n",
            "[604 | 950.30] loss=0.02 avg=0.03\n",
            "[605 | 951.20] loss=0.03 avg=0.03\n",
            "[606 | 952.10] loss=0.03 avg=0.03\n",
            "[607 | 953.01] loss=0.04 avg=0.03\n",
            "[608 | 953.91] loss=0.03 avg=0.03\n",
            "[609 | 954.81] loss=0.03 avg=0.03\n",
            "[610 | 955.71] loss=0.02 avg=0.03\n",
            "[611 | 956.62] loss=0.02 avg=0.03\n",
            "[612 | 957.52] loss=0.02 avg=0.03\n",
            "[613 | 958.42] loss=0.02 avg=0.03\n",
            "[614 | 959.32] loss=0.03 avg=0.03\n",
            "[615 | 960.22] loss=0.02 avg=0.03\n",
            "[616 | 961.12] loss=0.03 avg=0.03\n",
            "[617 | 962.02] loss=0.02 avg=0.03\n",
            "[618 | 962.93] loss=0.02 avg=0.03\n",
            "[619 | 963.83] loss=0.02 avg=0.03\n",
            "[620 | 964.74] loss=0.01 avg=0.03\n",
            "[621 | 965.64] loss=0.03 avg=0.03\n",
            "[622 | 966.54] loss=0.03 avg=0.03\n",
            "[623 | 967.45] loss=0.02 avg=0.03\n",
            "[624 | 968.35] loss=0.02 avg=0.03\n",
            "[625 | 969.25] loss=0.02 avg=0.03\n",
            "[626 | 970.15] loss=0.04 avg=0.03\n",
            "[627 | 971.06] loss=0.02 avg=0.03\n",
            "[628 | 971.96] loss=0.03 avg=0.03\n",
            "[629 | 972.86] loss=0.01 avg=0.03\n",
            "[630 | 973.76] loss=0.02 avg=0.03\n",
            "[631 | 974.67] loss=0.02 avg=0.03\n",
            "[632 | 975.57] loss=0.03 avg=0.03\n",
            "[633 | 976.47] loss=0.01 avg=0.03\n",
            "[634 | 977.37] loss=0.02 avg=0.03\n",
            "[635 | 978.27] loss=0.02 avg=0.03\n",
            "[636 | 979.17] loss=0.03 avg=0.03\n",
            "[637 | 980.08] loss=0.03 avg=0.03\n",
            "[638 | 980.98] loss=0.02 avg=0.03\n",
            "[639 | 981.88] loss=0.03 avg=0.03\n",
            "[640 | 982.78] loss=0.02 avg=0.03\n",
            "[641 | 983.68] loss=0.02 avg=0.03\n",
            "[642 | 984.58] loss=0.02 avg=0.03\n",
            "[643 | 985.48] loss=0.02 avg=0.03\n",
            "[644 | 986.39] loss=0.02 avg=0.03\n",
            "[645 | 987.29] loss=0.02 avg=0.03\n",
            "[646 | 988.19] loss=0.02 avg=0.03\n",
            "[647 | 989.09] loss=0.03 avg=0.03\n",
            "[648 | 989.99] loss=0.02 avg=0.03\n",
            "[649 | 990.89] loss=0.02 avg=0.03\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            "\n",
            "I got a job as a project manager at a major multinational corporation and started learning about the different markets in Europe. I also had the chance to learn a few new words in different languages and even tried speaking with locals. I ended up speaking with both locals and foreigners and learned a lot about the different cultures in Europe and about how to make money in them. I can't wait to plan my next adventure and make more money here. \n",
            "OUTPUT :\n",
            "\"I got a call from my boss at the company's headquarters in Paris\",\n",
            "\"My boss was thinking about a new project\",\n",
            "\"I said, 'Get this project off the back of a busy schedule'\",\n",
            "\"My boss replied, \"It's an exciting project\",\n",
            "\"The team is looking forward to a productive day\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Samantha is a nurse who loves to travel and see different cultures. She has been to 5 different countries and learned about their history, customs and food. She is planning to go on a trip to Nepal next year to explore their beautiful culture and try new food. \n",
            "OUTPUT :\n",
            "\"Samantha is a nurse\",\n",
            "\"Samantha loves to travel and see different cultures\",\n",
            "\"Samantha has been to 5 different countries\",\n",
            "\"Samantha has learned about their history, customs and food\",\n",
            "\"Samantha is planning to go on a trip to Nepal next year\",\n",
            "\"Samantha wants to explore the beautiful culture of Nepal\",\n",
            "\"Samantha wants to try new food in Nepal\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Michael is a professional chef who enjoys cooking different dishes and experimenting with new ingredients. He has been working at a famous restaurant for 5 years and has won several awards for his exceptional culinary skills. He also loves teaching cooking classes and sharing his passion for food with others. \n",
            "OUTPUT :\n",
            "\"Michael is a professional chef\",\n",
            "\"Michael enjoys cooking different dishes and experimenting with new ingredients\",\n",
            "\"Michael has been working at a famous restaurant for 5 years\",\n",
            "\"Michael has won several awards for his exceptional culinary skills\",\n",
            "\"Michael loves teaching cooking classes\",\n",
            "\"Michael loves sharing his passion for food with others\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Emily is an avid reader who loves to spend her weekends at the library and discovering new authors. She has read over 200 books and has a library in her room with all of her favorite books. She also enjoys writing book reviews and sharing her thoughts with others \n",
            "OUTPUT :\n",
            "\"Emily is an avid reader\",\n",
            "\"Emily loves to spend her weekends at the library and discovering new authors\",\n",
            "\"Emily has read over 200 books\",\n",
            "\"Emily has a library in her room with all of her favorite books\",\n",
            "\"Emily enjoys writing book reviews\",\n",
            "\"Emily enjoys sharing her thoughts about books with others\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today was a busy day for Sarah. She had to attend her math and science classes in the morning and then had a math test in her history class in the afternoon. After school, she went to the gym to work out and then spent the evening studying for her exams next week. She also made sure to call her grandmother before bed to catch up. \n",
            "OUTPUT :\n",
            "\"Today was a busy day for Sarah\",\n",
            "\"Sarah had to attend her math and science classes in the morning\",\n",
            "\"Sarah had a math test in her history class in the afternoon\",\n",
            "\"After school, Sarah went to the gym to work out\",\n",
            "\"Sarah spent the evening studying for her exams next week\",\n",
            "\"Sarah made sure to call her grandmother before bed to catch up\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : John had a great day today. He started the day with a healthy breakfast and then went for a jog in the park. He attended his college classes and had a productive study session with his friends. After dinner, he played basketball with his team and then relaxed by reading a book before bed \n",
            "OUTPUT :\n",
            "\"\n",
            "\n",
            "[650 | 1023.43] loss=0.02 avg=0.03\n",
            "[651 | 1024.33] loss=0.02 avg=0.03\n",
            "[652 | 1025.23] loss=0.02 avg=0.03\n",
            "[653 | 1026.13] loss=0.02 avg=0.03\n",
            "[654 | 1027.03] loss=0.03 avg=0.03\n",
            "[655 | 1027.93] loss=0.03 avg=0.03\n",
            "[656 | 1028.83] loss=0.02 avg=0.03\n",
            "[657 | 1029.73] loss=0.02 avg=0.03\n",
            "[658 | 1030.63] loss=0.03 avg=0.03\n",
            "[659 | 1031.53] loss=0.04 avg=0.03\n",
            "[660 | 1032.43] loss=0.02 avg=0.03\n",
            "[661 | 1033.33] loss=0.03 avg=0.03\n",
            "[662 | 1034.23] loss=0.02 avg=0.03\n",
            "[663 | 1035.13] loss=0.02 avg=0.03\n",
            "[664 | 1036.03] loss=0.03 avg=0.03\n",
            "[665 | 1036.93] loss=0.02 avg=0.03\n",
            "[666 | 1037.83] loss=0.02 avg=0.03\n",
            "[667 | 1038.73] loss=0.02 avg=0.03\n",
            "[668 | 1039.63] loss=0.03 avg=0.03\n",
            "[669 | 1040.53] loss=0.02 avg=0.03\n",
            "[670 | 1041.43] loss=0.05 avg=0.03\n",
            "[671 | 1042.33] loss=0.02 avg=0.03\n",
            "[672 | 1043.23] loss=0.02 avg=0.03\n",
            "[673 | 1044.13] loss=0.01 avg=0.03\n",
            "[674 | 1045.03] loss=0.02 avg=0.03\n",
            "[675 | 1045.93] loss=0.03 avg=0.03\n",
            "[676 | 1046.83] loss=0.02 avg=0.03\n",
            "[677 | 1047.73] loss=0.02 avg=0.03\n",
            "[678 | 1048.63] loss=0.02 avg=0.03\n",
            "[679 | 1049.53] loss=0.02 avg=0.03\n",
            "[680 | 1050.43] loss=0.02 avg=0.03\n",
            "[681 | 1051.33] loss=0.02 avg=0.03\n",
            "[682 | 1052.23] loss=0.02 avg=0.03\n",
            "[683 | 1053.13] loss=0.02 avg=0.03\n",
            "[684 | 1054.03] loss=0.02 avg=0.03\n",
            "[685 | 1054.94] loss=0.01 avg=0.03\n",
            "[686 | 1055.84] loss=0.02 avg=0.03\n",
            "[687 | 1056.74] loss=0.02 avg=0.03\n",
            "[688 | 1057.64] loss=0.03 avg=0.03\n",
            "[689 | 1058.54] loss=0.02 avg=0.03\n",
            "[690 | 1059.44] loss=0.02 avg=0.03\n",
            "[691 | 1060.34] loss=0.02 avg=0.03\n",
            "[692 | 1061.24] loss=0.02 avg=0.03\n",
            "[693 | 1062.14] loss=0.02 avg=0.03\n",
            "[694 | 1063.04] loss=0.04 avg=0.03\n",
            "[695 | 1063.94] loss=0.02 avg=0.03\n",
            "[696 | 1064.84] loss=0.01 avg=0.03\n",
            "[697 | 1065.74] loss=0.03 avg=0.03\n",
            "[698 | 1066.64] loss=0.03 avg=0.03\n",
            "[699 | 1067.54] loss=0.02 avg=0.03\n",
            "Saving checkpoint/run1/model-700\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            " basketball company and had a great time. He is survived by his dog, Pip, and 2 cats, Max, and Alex. <3 <>\n",
            "<p>Michael is survived by his 2 great-grandchildren, Alex and Michael, and he is also in his 80s and is in his 30s. Michael is also in his thirties and is in his first car accident.</p>\n",
            "<p>Michael is survived by his 2 great-great-great-grandchildren, Paul and Sarah, and he is also in his 60s and is in his first car accident.</p>\n",
            "<p>Michael is survived by his mother, who is in her early thirties, and his grandmother is in her early thirties. Michael is also in his soccer team soccer team and is in her math team math team mom isin isis is is is is is a.k.a. Sophia is a professional wrestler who has won an amateur and major championship in the past.</p>\n",
            "<p>Samantha is a professional wrestler who has won an amateur and major championship in the past.</p>\n",
            "<p>Alexis is a professional basketball player who has played for the Orlando Magic, New York Knicks, and Washington Wizards. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a professional football player who has played for the New York Giants and New York Jets. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a professional volleyball player who has played for the New England Patriots and Seattle Seahawks. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a professional basketball player who has played for the New York Knicks and New York Islanders. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a professional hockey player who has played for the New Jersey Devils and New York Islanders. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a professional basketball player who has played for the New York Knicks and New York Islanders. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a professional baseball player who has played for the Philadelphia Phillies and Baltimore Orioles. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a professional hockey player who has played for the New York Rangers and Anaheim Ducks. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a professional tennis player who has played for the New York Red Bulls and Chicago Fire. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a professional soccer player who has played for New York Red Bulls and New York Red Bulls II. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a professional basketball player who has played for New York Knicks and New York Islanders. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a professional soccer player who has played for New York Red Bulls and New York Red Bulls II. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a professional tennis player who has played for New York Red Bulls and New York Red Bulls II. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a professional tennis defender who has played for New York Red Bulls and New York Islanders. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a professional soccer player who has played for New York Red Bulls and New York Islanders. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a professional volleyball player who has played for New York Red Bulls and New York Islanders. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a professional triathlone who has played for New York Red Bulls and New York Islanders. She has won two tournaments and has won the Wimbledon and Wimbledon cups.</p>\n",
            "<p>Alexis is a member of the New York City FC club soccer team. She leads her team in attacking and stopping the ball. The ball is extremely dangerous to a team and is often intercepted by defenders. Jessica Betancourt, who is also on the team, said, \"Her exceptional play shows that soccer is a wonderful sport for kids\n",
            "\n",
            "[700 | 1105.70] loss=0.02 avg=0.03\n",
            "[701 | 1106.61] loss=0.03 avg=0.03\n",
            "[702 | 1107.52] loss=0.02 avg=0.03\n",
            "[703 | 1108.43] loss=0.02 avg=0.03\n",
            "[704 | 1109.33] loss=0.02 avg=0.03\n",
            "[705 | 1110.24] loss=0.02 avg=0.03\n",
            "[706 | 1111.15] loss=0.02 avg=0.03\n",
            "[707 | 1112.06] loss=0.03 avg=0.03\n",
            "[708 | 1112.96] loss=0.02 avg=0.03\n",
            "[709 | 1113.87] loss=0.02 avg=0.03\n",
            "[710 | 1114.78] loss=0.03 avg=0.03\n",
            "[711 | 1115.68] loss=0.02 avg=0.03\n",
            "[712 | 1116.59] loss=0.02 avg=0.03\n",
            "[713 | 1117.50] loss=0.03 avg=0.03\n",
            "[714 | 1118.40] loss=0.03 avg=0.03\n",
            "[715 | 1119.31] loss=0.02 avg=0.03\n",
            "[716 | 1120.22] loss=0.02 avg=0.03\n",
            "[717 | 1121.12] loss=0.02 avg=0.03\n",
            "[718 | 1122.03] loss=0.02 avg=0.03\n",
            "[719 | 1122.93] loss=0.02 avg=0.03\n",
            "[720 | 1123.83] loss=0.03 avg=0.03\n",
            "[721 | 1124.74] loss=0.02 avg=0.03\n",
            "[722 | 1125.64] loss=0.02 avg=0.03\n",
            "[723 | 1126.55] loss=0.01 avg=0.03\n",
            "[724 | 1127.45] loss=0.02 avg=0.03\n",
            "[725 | 1128.36] loss=0.01 avg=0.03\n",
            "[726 | 1129.26] loss=0.02 avg=0.03\n",
            "[727 | 1130.16] loss=0.03 avg=0.03\n",
            "[728 | 1131.07] loss=0.01 avg=0.03\n",
            "[729 | 1131.97] loss=0.02 avg=0.03\n",
            "[730 | 1132.87] loss=0.02 avg=0.03\n",
            "[731 | 1133.77] loss=0.04 avg=0.03\n",
            "[732 | 1134.67] loss=0.02 avg=0.03\n",
            "[733 | 1135.58] loss=0.02 avg=0.03\n",
            "[734 | 1136.48] loss=0.02 avg=0.03\n",
            "[735 | 1137.38] loss=0.03 avg=0.03\n",
            "[736 | 1138.28] loss=0.01 avg=0.03\n",
            "[737 | 1139.18] loss=0.02 avg=0.03\n",
            "[738 | 1140.09] loss=0.01 avg=0.03\n",
            "[739 | 1140.99] loss=0.02 avg=0.03\n",
            "[740 | 1141.89] loss=0.01 avg=0.03\n",
            "[741 | 1142.79] loss=0.03 avg=0.03\n",
            "[742 | 1143.69] loss=0.02 avg=0.03\n",
            "[743 | 1144.59] loss=0.01 avg=0.03\n",
            "[744 | 1145.49] loss=0.02 avg=0.03\n",
            "[745 | 1146.39] loss=0.02 avg=0.03\n",
            "[746 | 1147.29] loss=0.02 avg=0.03\n",
            "[747 | 1148.19] loss=0.02 avg=0.03\n",
            "[748 | 1149.09] loss=0.04 avg=0.03\n",
            "[749 | 1149.99] loss=0.03 avg=0.03\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            " is\n",
            "\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I recently started a new job as a marketing manager. My role involves creating and implementing marketing strategies, managing a team, and analyzing market data. It's a challenging but exciting role that allows me to use my creativity and problem-solving skills. I look forward to growing in my career and making a significant impact on the company's success. \n",
            "OUTPUT :\n",
            "\"I recently started a new job as a marketing manager\",\n",
            "\"My role involves creating marketing strategies\",\n",
            "\"My role involves implementing marketing strategies\",\n",
            "\"My role involves managing a team\",\n",
            "\"My role involves analyzing market data\",\n",
            "\"The job is challenging but exciting\",\n",
            "\"The job allows me to use my creativity\",\n",
            "\"The job allows me to use my problem-solving skills\",\n",
            "\"I look forward to growing in my career\",\n",
            "\"I look forward to making a significant impact on the company's success\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I recently took up gardening as a hobby. I enjoy learning about different plants, how to care for them, and watching them grow. I have a small garden in my backyard where I grow a variety of vegetables, flowers, and herbs. Gardening has been a great way to connect with nature and relieve stress. I plan to expand my garden and try growing new plants in the future. \n",
            "OUTPUT :\n",
            "\"I recently took up gardening as a hobby\",\n",
            "\"I enjoy learning about different plants\",\n",
            "\"I enjoy learning how to care for different plants\",\n",
            "\"I enjoy watching plants grow\",\n",
            "\"I have a small garden in my backyard\",\n",
            "\"I grow a variety of vegetables in my backyard garden\",\n",
            "\"I grow a variety of flowers in my backyard garden\",\n",
            "\"Gardening has been a great way to connect with nature\",\n",
            "\"Gardening has been a great way to relieve stress\",\n",
            "\"I plan to expand my garden in the future\",\n",
            "\"I plan to try growing new plants in the future\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I recently started practicing yoga to improve my physical and mental well-being. I attend classes at a local studio and enjoy the challenge of different poses. The practice has helped me become more flexible, stronger, and calmer. I also appreciate the mindfulness and breathing techniques that are a part of the practice. I look forward to continuing my yoga journey and experiencing its benefits. \n",
            "OUTPUT :\n",
            "\"I recently started practicing yoga\",\n",
            "\"I started practicing yoga to improve my physical well-being\",\n",
            "\"I started practicing yoga to improve my mental well-being\",\n",
            "\"I attend yoga classes at a local studio\",\n",
            "\"I enjoy the challenge of different yoga poses\",\n",
            "\"Practicing yoga has helped me become more flexible\",\n",
            "\"Practicing yoga has helped me become stronger\",\n",
            "\"Practicing yoga has helped me become calmer\",\n",
            "\"I appreciate the mindfulness techniques in yoga\",\n",
            "\"I appreciate the breathing techniques in yoga\",\n",
            "\"I look forward to continuing my yoga journey\",\n",
            "\"I look forward to experiencing the benefits of practicing yoga\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I recently started volunteering at a local animal shelter. I love spending time with the animals and taking care of them. It's been a great way to give back to my community and make a positive impact. I also enjoy working with the staff and volunteers and learning about animal behavior and care. Volunteering has been a rewarding experience and I plan to continue doing it for a long time. \n",
            "OUTPUT :\n",
            "\"I recently started volunteering at a local animal shelter\",\n",
            "\"I love spending time with the animals at the shelter\",\n",
            "\"I love taking care of the animals at the shelter\",\n",
            "\"Volunteering at the animal shelter is a great way to give back to my community\",\n",
            "\"Volunteering at the animal shelter is a great way to make a positive impact\",\n",
            "\"I enjoy working with the staff at the animal shelter\",\n",
            "\"I enjoy working with the volunteers at the animal shelter\",\n",
            "\"I enjoy learning about animal behavior at the animal shelter\",\n",
            "\"I enjoy learning about animal care at the animal shelter\",\n",
            "\"Volunteering at the animal\n",
            "\n",
            "[750 | 1184.93] loss=0.02 avg=0.03\n",
            "[751 | 1185.83] loss=0.01 avg=0.03\n",
            "[752 | 1186.73] loss=0.03 avg=0.03\n",
            "[753 | 1187.63] loss=0.02 avg=0.03\n",
            "[754 | 1188.52] loss=0.03 avg=0.03\n",
            "[755 | 1189.42] loss=0.02 avg=0.03\n",
            "[756 | 1190.32] loss=0.06 avg=0.03\n",
            "[757 | 1191.22] loss=0.01 avg=0.03\n",
            "[758 | 1192.13] loss=0.02 avg=0.03\n",
            "[759 | 1193.03] loss=0.03 avg=0.03\n",
            "[760 | 1193.93] loss=0.02 avg=0.03\n",
            "[761 | 1194.83] loss=0.02 avg=0.03\n",
            "[762 | 1195.73] loss=0.02 avg=0.03\n",
            "[763 | 1196.64] loss=0.02 avg=0.02\n",
            "[764 | 1197.54] loss=0.01 avg=0.02\n",
            "[765 | 1198.44] loss=0.03 avg=0.02\n",
            "[766 | 1199.34] loss=0.03 avg=0.02\n",
            "[767 | 1200.23] loss=0.03 avg=0.02\n",
            "[768 | 1201.13] loss=0.03 avg=0.02\n",
            "[769 | 1202.03] loss=0.02 avg=0.02\n",
            "[770 | 1202.93] loss=0.03 avg=0.02\n",
            "[771 | 1203.84] loss=0.03 avg=0.02\n",
            "[772 | 1204.74] loss=0.02 avg=0.02\n",
            "[773 | 1205.64] loss=0.02 avg=0.02\n",
            "[774 | 1206.54] loss=0.02 avg=0.02\n",
            "[775 | 1207.45] loss=0.01 avg=0.02\n",
            "[776 | 1208.34] loss=0.02 avg=0.02\n",
            "[777 | 1209.25] loss=0.04 avg=0.02\n",
            "[778 | 1210.15] loss=0.03 avg=0.02\n",
            "[779 | 1211.05] loss=0.02 avg=0.02\n",
            "[780 | 1211.95] loss=0.03 avg=0.02\n",
            "[781 | 1212.86] loss=0.03 avg=0.02\n",
            "[782 | 1213.76] loss=0.02 avg=0.02\n",
            "[783 | 1214.66] loss=0.02 avg=0.02\n",
            "[784 | 1215.56] loss=0.03 avg=0.02\n",
            "[785 | 1216.47] loss=0.01 avg=0.02\n",
            "[786 | 1217.37] loss=0.05 avg=0.02\n",
            "[787 | 1218.27] loss=0.04 avg=0.03\n",
            "[788 | 1219.17] loss=0.01 avg=0.02\n",
            "[789 | 1220.08] loss=0.01 avg=0.02\n",
            "[790 | 1220.98] loss=0.02 avg=0.02\n",
            "[791 | 1221.89] loss=0.02 avg=0.02\n",
            "[792 | 1222.79] loss=0.01 avg=0.02\n",
            "[793 | 1223.69] loss=0.01 avg=0.02\n",
            "[794 | 1224.59] loss=0.02 avg=0.02\n",
            "[795 | 1225.49] loss=0.01 avg=0.02\n",
            "[796 | 1226.39] loss=0.03 avg=0.02\n",
            "[797 | 1227.30] loss=0.02 avg=0.02\n",
            "[798 | 1228.20] loss=0.02 avg=0.02\n",
            "[799 | 1229.10] loss=0.02 avg=0.02\n",
            "Saving checkpoint/run1/model-800\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            " for my friends over at the restaurants \n",
            "I always make sure to give my all and make sure to ask for and receive good customer service from time to time. \n",
            "OUTPUT :\n",
            "\"I always make sure to make sure to give back to my guests after dinner\",\n",
            "\"I enjoy making sure to serve my guests good food and clean facilities\",\n",
            "\"I look forward to growing in my celebrity value over the next few years\",\n",
            "\"I am confident that I will make a significant impact in the lives of my guests and family\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I have been friends with John for over 10 years now and he is one of the kindest and funniest people I know. He always knows how to make me laugh and I always feel comfortable around him. He is extremely talented and has a passion for music and art. He is also very caring and supportive, always there for me when I need him. I admire his positive attitude and his ability to see the best in people. John is truly a great friend and I am grateful to have him in my life. \n",
            "OUTPUT :\n",
            "\"I have been friends with John for over 10 years\",\n",
            "\"John is one of the kindest and funniest people I know\",\n",
            "\"John always knows how to make me laugh and I feel comfortable around him\",\n",
            "\"John is extremely talented and has a passion for music and art\",\n",
            "\"John is very caring and supportive and is always there for me when I need him\",\n",
            "\"I admire John's positive attitude and his ability to see the best in people\",\n",
            "\"John is truly a great friend and I am grateful to have him in my life\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I have been friends with John for over 10 years now and he is one of the kindest and funniest people I know. He always knows how to make me laugh and I always feel comfortable around him. He is extremely talented and has a passion for music and art. He is also very caring and supportive, always there for me when I need him. I admire his positive attitude and his ability to see the best in people. John is truly a great friend and I am grateful to have him in my life. \n",
            "OUTPUT :\n",
            "\"I have been friends with John for over 10 years\",\n",
            "\"John is one of the kindest people I know\",\n",
            "\"John is one of the funniest people I know\",\n",
            "\"John always knows how to make me laugh\",\n",
            "\"I always feel comfortable around John\",\n",
            "\"John is extremely talented\",\n",
            "\"John has a passion for music\",\n",
            "\"John has a passion for art\",\n",
            "\"John is very caring\",\n",
            "\"John is supportive\",\n",
            "\"John is always there for me when I need him\",\n",
            "\"I admire John's positive attitude\",\n",
            "\"I admire John's ability to see the best in people\",\n",
            "\"John is truly a great friend\",\n",
            "\"I am grateful to have John in my life\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : My friend Sarah is a talented artist and loves to spend her free time painting and drawing. She is also very athletic and enjoys playing soccer, basketball, and tennis. Sarah is a good listener and always gives me good advice when I need it. She is also very funny and knows how to make me laugh. I am grateful to have such a wonderful friend like Sarah in my life. \n",
            "OUTPUT :\n",
            "\"My friend Sarah is a talented artist\",\n",
            "\"Sarah loves to spend her free time painting\",\n",
            "\"Sarah loves to spend her free time drawing\",\n",
            "\"Sarah is also very athletic\",\n",
            "\"Sarah enjoys playing soccer\",\n",
            "\"Sarah enjoys playing basketball\",\n",
            "\"Sarah enjoys playing tennis\",\n",
            "\"Sarah is a good listener\",\n",
            "\"Sarah always gives me good advice when I need it\",\n",
            "\"Sarah is also very funny\",\n",
            "\"Sarah knows how to make me laugh\",\n",
            "\"I am grateful to have such a wonderful friend like Sarah in my life\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : My boss is a very intelligent and hardworking person who always sets high standards for himself and others. He is also very fair and treats all of his employees with respect and kindness. I have\n",
            "\n",
            "[800 | 1265.61] loss=0.02 avg=0.02\n",
            "[801 | 1266.51] loss=0.02 avg=0.02\n",
            "[802 | 1267.42] loss=0.03 avg=0.02\n",
            "[803 | 1268.32] loss=0.02 avg=0.02\n",
            "[804 | 1269.22] loss=0.02 avg=0.02\n",
            "[805 | 1270.12] loss=0.03 avg=0.02\n",
            "[806 | 1271.03] loss=0.03 avg=0.02\n",
            "[807 | 1271.94] loss=0.02 avg=0.02\n",
            "[808 | 1272.84] loss=0.02 avg=0.02\n",
            "[809 | 1273.73] loss=0.03 avg=0.02\n",
            "[810 | 1274.63] loss=0.01 avg=0.02\n",
            "[811 | 1275.53] loss=0.02 avg=0.02\n",
            "[812 | 1276.43] loss=0.02 avg=0.02\n",
            "[813 | 1277.33] loss=0.02 avg=0.02\n",
            "[814 | 1278.23] loss=0.01 avg=0.02\n",
            "[815 | 1279.13] loss=0.01 avg=0.02\n",
            "[816 | 1280.03] loss=0.02 avg=0.02\n",
            "[817 | 1280.93] loss=0.01 avg=0.02\n",
            "[818 | 1281.83] loss=0.02 avg=0.02\n",
            "[819 | 1282.73] loss=0.01 avg=0.02\n",
            "[820 | 1283.63] loss=0.02 avg=0.02\n",
            "[821 | 1284.53] loss=0.02 avg=0.02\n",
            "[822 | 1285.43] loss=0.02 avg=0.02\n",
            "[823 | 1286.32] loss=0.02 avg=0.02\n",
            "[824 | 1287.22] loss=0.02 avg=0.02\n",
            "[825 | 1288.12] loss=0.02 avg=0.02\n",
            "[826 | 1289.02] loss=0.01 avg=0.02\n",
            "[827 | 1289.92] loss=0.02 avg=0.02\n",
            "[828 | 1290.82] loss=0.01 avg=0.02\n",
            "[829 | 1291.72] loss=0.02 avg=0.02\n",
            "[830 | 1292.63] loss=0.01 avg=0.02\n",
            "[831 | 1293.52] loss=0.02 avg=0.02\n",
            "[832 | 1294.42] loss=0.02 avg=0.02\n",
            "[833 | 1295.32] loss=0.03 avg=0.02\n",
            "[834 | 1296.22] loss=0.02 avg=0.02\n",
            "[835 | 1297.12] loss=0.01 avg=0.02\n",
            "[836 | 1298.02] loss=0.02 avg=0.02\n",
            "[837 | 1298.91] loss=0.03 avg=0.02\n",
            "[838 | 1299.82] loss=0.02 avg=0.02\n",
            "[839 | 1300.72] loss=0.02 avg=0.02\n",
            "[840 | 1301.62] loss=0.02 avg=0.02\n",
            "[841 | 1302.52] loss=0.03 avg=0.02\n",
            "[842 | 1303.41] loss=0.01 avg=0.02\n",
            "[843 | 1304.31] loss=0.02 avg=0.02\n",
            "[844 | 1305.21] loss=0.02 avg=0.02\n",
            "[845 | 1306.11] loss=0.03 avg=0.02\n",
            "[846 | 1307.02] loss=0.01 avg=0.02\n",
            "[847 | 1307.92] loss=0.01 avg=0.02\n",
            "[848 | 1308.82] loss=0.02 avg=0.02\n",
            "[849 | 1309.72] loss=0.03 avg=0.02\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            " :\n",
            "\"John had a busy day as usual at work including cleaning up after a busy day at work, meeting with clients and checking in to a new profile\",\n",
            "\"I had a meeting with my team to discuss our progress on a new project\",\n",
            "\"We also had a one-on-one meeting with my creative team to discuss our next move\",\n",
            "\"After that, I attended a cooking class for both of us\",\n",
            "\"We continued our productive lives at the restaurant\",\n",
            "\"In the next few weeks, we can all plan our next adventure\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today, I woke up late and missed my morning workout. I was too lazy to make breakfast so I ordered pizza and watched TV all day. I also skipped my afternoon nap and didn't do any work. I spent the entire day being lazy and not doing anything productive. \n",
            "OUTPUT :\n",
            "\"Today, I woke up late\",\n",
            "\"I missed my morning workout\",\n",
            "\"I was too lazy to make breakfast\",\n",
            "\"I ordered pizza for breakfast\",\n",
            "\"I watched TV all day\",\n",
            "\"I skipped my afternoon nap\",\n",
            "\"I didn't do any work\",\n",
            "\"I spent the entire day being lazy\",\n",
            "\"I didn't do anything productive\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today I overslept and missed my morning meeting, which was a major project update and my boss was not happy about it. I tried to make excuses and explained that I had a long night and didn't set an alarm, but my boss was uninterested in my excuses and told me to be more responsible in the future. \n",
            "OUTPUT :\n",
            "\"Today I overslept\",\n",
            "\"I missed my morning meeting\",\n",
            "\"The meeting was a major project update\",\n",
            "\"My boss was not happy about me missing the meeting\",\n",
            "\"I tried to make excuses for missing the meeting\",\n",
            "\"I explained that I had a long night and didn't set an alarm\",\n",
            "\"My boss was uninterested in my excuses\",\n",
            "\"My boss told me to be more responsible in the future\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I woke up this morning feeling lazy but I forced myself to go to the gym and exercise. I ran on the treadmill for 30 minutes and did some weightlifting. Afterwards, I went grocery shopping and bought ingredients for dinner tonight which is going to be grilled chicken and steamed vegetables. I then came back home and took a nap before starting my work. \n",
            "OUTPUT :\n",
            "\"I woke up this morning feeling lazy\",\n",
            "\"I forced myself to go to the gym\",\n",
            "\"I exercised at the gym\",\n",
            "\"I ran on the treadmill for 30 minutes\",\n",
            "\"I did some weightlifting at the gym\",\n",
            "\"I went grocery shopping\",\n",
            "\"I bought ingredients for dinner tonight\",\n",
            "\"Dinner tonight is going to be grilled chicken and steamed vegetables\",\n",
            "\"I came back home\",\n",
            "\"I took a nap before starting my work\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : As the CEO of Facebook, I was busy handling company's operations and meeting with potential investors yesterday. I also had a call with my team in the morning to discuss the progress of our latest project and it was a productive meeting. In the evening, I went for a walk and spent some time with my family, discussing our future plans and catching up on each other's lives. \n",
            "OUTPUT :\n",
            "\"As the CEO of Facebook, I was busy handling company's operations yesterday\",\n",
            "\"I also had meetings with potential investors yesterday\",\n",
            "\"I had a call with my team in the morning to discuss the progress of our latest project\",\n",
            "\"The call was productive\",\n",
            "\"In the evening, I went for a walk\",\n",
            "\"I spent some time with my family\",\n",
            "\"We discussed our future plans\",\n",
            "\"We caught up on each other's lives\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : As a singer, today I had a busy day. I started the day with a\n",
            "\n",
            "[850 | 1343.62] loss=0.02 avg=0.02\n",
            "[851 | 1344.52] loss=0.02 avg=0.02\n",
            "[852 | 1345.42] loss=0.02 avg=0.02\n",
            "[853 | 1346.32] loss=0.02 avg=0.02\n",
            "[854 | 1347.22] loss=0.02 avg=0.02\n",
            "[855 | 1348.12] loss=0.02 avg=0.02\n",
            "[856 | 1349.02] loss=0.03 avg=0.02\n",
            "[857 | 1349.92] loss=0.02 avg=0.02\n",
            "[858 | 1350.82] loss=0.04 avg=0.02\n",
            "[859 | 1351.72] loss=0.02 avg=0.02\n",
            "[860 | 1352.62] loss=0.01 avg=0.02\n",
            "[861 | 1353.51] loss=0.01 avg=0.02\n",
            "[862 | 1354.41] loss=0.02 avg=0.02\n",
            "[863 | 1355.31] loss=0.01 avg=0.02\n",
            "[864 | 1356.21] loss=0.03 avg=0.02\n",
            "[865 | 1357.12] loss=0.02 avg=0.02\n",
            "[866 | 1358.02] loss=0.01 avg=0.02\n",
            "[867 | 1358.92] loss=0.02 avg=0.02\n",
            "[868 | 1359.82] loss=0.01 avg=0.02\n",
            "[869 | 1360.72] loss=0.02 avg=0.02\n",
            "[870 | 1361.62] loss=0.02 avg=0.02\n",
            "[871 | 1362.52] loss=0.02 avg=0.02\n",
            "[872 | 1363.42] loss=0.02 avg=0.02\n",
            "[873 | 1364.32] loss=0.03 avg=0.02\n",
            "[874 | 1365.22] loss=0.02 avg=0.02\n",
            "[875 | 1366.12] loss=0.02 avg=0.02\n",
            "[876 | 1367.02] loss=0.03 avg=0.02\n",
            "[877 | 1367.93] loss=0.02 avg=0.02\n",
            "[878 | 1368.82] loss=0.02 avg=0.02\n",
            "[879 | 1369.72] loss=0.02 avg=0.02\n",
            "[880 | 1370.63] loss=0.01 avg=0.02\n",
            "[881 | 1371.53] loss=0.01 avg=0.02\n",
            "[882 | 1372.43] loss=0.02 avg=0.02\n",
            "[883 | 1373.33] loss=0.01 avg=0.02\n",
            "[884 | 1374.23] loss=0.01 avg=0.02\n",
            "[885 | 1375.14] loss=0.01 avg=0.02\n",
            "[886 | 1376.04] loss=0.02 avg=0.02\n",
            "[887 | 1376.94] loss=0.01 avg=0.02\n",
            "[888 | 1377.84] loss=0.02 avg=0.02\n",
            "[889 | 1378.74] loss=0.02 avg=0.02\n",
            "[890 | 1379.64] loss=0.02 avg=0.02\n",
            "[891 | 1380.54] loss=0.02 avg=0.02\n",
            "[892 | 1381.44] loss=0.01 avg=0.02\n",
            "[893 | 1382.35] loss=0.02 avg=0.02\n",
            "[894 | 1383.24] loss=0.02 avg=0.02\n",
            "[895 | 1384.14] loss=0.02 avg=0.02\n",
            "[896 | 1385.05] loss=0.02 avg=0.02\n",
            "[897 | 1385.95] loss=0.04 avg=0.02\n",
            "[898 | 1386.85] loss=0.01 avg=0.02\n",
            "[899 | 1387.75] loss=0.02 avg=0.02\n",
            "Saving checkpoint/run1/model-900\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            " day is spent with my friends and family at our new adventure campfire is a beautiful and traditional campfire in our new home that we love making. \n",
            "OUTPUT :\n",
            "\"Today I woke up early\",\n",
            "\"I went for a jog and did my daily chores\",\n",
            "\"My daily chores included cleaning the house and cooking breakfast\",\n",
            "\"After that, I attended my online yoga class and also finished my work for the day\",\n",
            "\"In the evening, I met my best friend for a walk\",\n",
            "\"We talked about our future plans and also had a small picnic\",\n",
            "\"Overall, it was a productive day\",\n",
            "\"Today I am feeling a bit exhausted but happy with the time spent with my friends\".\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Last weekend, I went on a camping trip with my friends. We set up camp near a lake and spent the day fishing, hiking, and cooking meals over the fire. In the evening, we sat around the campfire, told stories, and stargazed. On Sunday, we packed up and went on a scenic drive before heading back home. It was a much-needed break from the city and a great opportunity to connect with nature and my friends. \n",
            "OUTPUT :\n",
            "\"Last weekend I went on a camping trip with my friends\",\n",
            "\"We set up camp near a lake\",\n",
            "\"We spent the day fishing\",\n",
            "\"We spent the day hiking\",\n",
            "\"We cooked meals over the fire during the day\",\n",
            "\"In the evening, we sat around the campfire\",\n",
            "\"We told stories around the campfire in the evening\",\n",
            "\"We stargazed in the evening\",\n",
            "\"On Sunday, we packed up\",\n",
            "\"We went on a scenic drive on Sunday\",\n",
            "\"We headed back home on Sunday\",\n",
            "\"The camping trip was a much-needed break from the city\",\n",
            "\"It was a great opportunity to connect with nature\",\n",
            "\"It was a great opportunity to connect with my friends\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I recently took a trip to Europe and had the time of my life. I visited several countries including France, Italy, and Spain and tried new foods, explored historical landmarks, and met new people. One of my highlights was visiting the Eiffel Tower in Paris and taking a gondola ride in Venice. I also took part in a cooking class in Tuscany and learned how to make traditional Italian dishes. I can't wait to plan my next adventure and make more memories. \n",
            "OUTPUT :\n",
            "\"I recently took a trip to Europe\",\n",
            "\"I had the time of my life during the trip\",\n",
            "\"I visited several countries including France, Italy, and Spain\",\n",
            "\"I tried new foods during the trip\",\n",
            "\"I explored historical landmarks during the trip\",\n",
            "\"I met new people during the trip\",\n",
            "\"One of my highlights was visiting the Eiffel Tower in Paris\",\n",
            "\"I took a gondola ride in Venice\",\n",
            "\"I took part in a cooking class in Tuscany\",\n",
            "\"I learned how to make traditional Italian dishes in Tuscany\",\n",
            "\"I can't wait to plan my next adventure\",\n",
            "\"I can't wait to make more memories on my next adventure\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I recently started volunteering at a local animal shelter. I help care for the animals, clean their cages, and play with them. It's been a wonderful experience and has given me a sense of purpose. I'm also learning a lot about different breeds and how to take care of them. I hope to continue volunteering and make a positive impact in the lives of these animals. \n",
            "OUTPUT :\n",
            "\"I recently started volunteering at a local animal shelter\",\n",
            "\"I help care for the animals at the shelter\",\n",
            "\"I clean the cages of the animals at the shelter\",\n",
            "\"I play with the animals at the shelter\",\n",
            "\"Volunteering at the shelter has been a wonderful experience\",\n",
            "\"Volunteering at the shelter has given me a sense of purpose\",\n",
            "\"I am learning a lot about different animal breeds\",\n",
            "\"I am learning how to take care of different animal breeds\",\n",
            "\"I hope to continue volunteering at the shelter\",\n",
            "\"I hope to make a positive impact in the lives of the animals at the shelter\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below\n",
            "\n",
            "[900 | 1424.07] loss=0.02 avg=0.02\n",
            "[901 | 1424.98] loss=0.01 avg=0.02\n",
            "[902 | 1425.88] loss=0.01 avg=0.02\n",
            "[903 | 1426.78] loss=0.03 avg=0.02\n",
            "[904 | 1427.69] loss=0.03 avg=0.02\n",
            "[905 | 1428.59] loss=0.02 avg=0.02\n",
            "[906 | 1429.49] loss=0.01 avg=0.02\n",
            "[907 | 1430.39] loss=0.01 avg=0.02\n",
            "[908 | 1431.30] loss=0.02 avg=0.02\n",
            "[909 | 1432.20] loss=0.02 avg=0.02\n",
            "[910 | 1433.10] loss=0.02 avg=0.02\n",
            "[911 | 1434.01] loss=0.02 avg=0.02\n",
            "[912 | 1434.91] loss=0.03 avg=0.02\n",
            "[913 | 1435.81] loss=0.02 avg=0.02\n",
            "[914 | 1436.71] loss=0.02 avg=0.02\n",
            "[915 | 1437.62] loss=0.02 avg=0.02\n",
            "[916 | 1438.52] loss=0.02 avg=0.02\n",
            "[918 | 1440.33] loss=0.01 avg=0.02\n",
            "[919 | 1441.23] loss=0.01 avg=0.02\n",
            "[920 | 1442.13] loss=0.02 avg=0.02\n",
            "[921 | 1443.03] loss=0.02 avg=0.02\n",
            "[922 | 1443.94] loss=0.02 avg=0.02\n",
            "[923 | 1444.84] loss=0.01 avg=0.02\n",
            "[924 | 1445.74] loss=0.02 avg=0.02\n",
            "[925 | 1446.64] loss=0.02 avg=0.02\n",
            "[926 | 1447.55] loss=0.01 avg=0.02\n",
            "[927 | 1448.45] loss=0.01 avg=0.02\n",
            "[928 | 1449.35] loss=0.02 avg=0.02\n",
            "[929 | 1450.25] loss=0.03 avg=0.02\n",
            "[930 | 1451.15] loss=0.02 avg=0.02\n",
            "[931 | 1452.06] loss=0.02 avg=0.02\n",
            "[932 | 1452.96] loss=0.02 avg=0.02\n",
            "[933 | 1453.86] loss=0.02 avg=0.02\n",
            "[934 | 1454.76] loss=0.02 avg=0.02\n",
            "[935 | 1455.66] loss=0.02 avg=0.02\n",
            "[936 | 1456.57] loss=0.02 avg=0.02\n",
            "[937 | 1457.47] loss=0.01 avg=0.02\n",
            "[938 | 1458.38] loss=0.02 avg=0.02\n",
            "[939 | 1459.28] loss=0.01 avg=0.02\n",
            "[940 | 1460.18] loss=0.01 avg=0.02\n",
            "[941 | 1461.09] loss=0.02 avg=0.02\n",
            "[942 | 1461.99] loss=0.02 avg=0.02\n",
            "[943 | 1462.89] loss=0.01 avg=0.02\n",
            "[944 | 1463.79] loss=0.02 avg=0.02\n",
            "[945 | 1464.69] loss=0.01 avg=0.02\n",
            "[946 | 1465.59] loss=0.02 avg=0.02\n",
            "[947 | 1466.49] loss=0.02 avg=0.02\n",
            "[948 | 1467.39] loss=0.01 avg=0.02\n",
            "[949 | 1468.29] loss=0.02 avg=0.02\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            " prizes\n",
            "\n",
            "$5 cash prizes\n",
            "\n",
            "Dinner is being prepared for tonight at a nearby restaurant\n",
            "\n",
            "RT @chrisfrau: We were too lazy to set up camp for breakfast tonight\n",
            "\n",
            "One of the first things we did was set up a campfire for the evening\n",
            "After breakfast, we spent the entire day being lazy and not doing anything productive\n",
            "2/3 of the homeless people in this shelter live in the city\n",
            "Dinner was very well prepared and included a grill and some fresh vegetables\n",
            "Our volunteers also cooked a delicious dinner for the homeless people and got a good look at the city\n",
            "It was a great opportunity to share my passion for food with the homeless people and make them feel comfortable walking around their city\n",
            "I urge others to join me in volunteering their time to help the homeless people in need\n",
            "More info : https://www.facebook.com/events/102283345671119/ \n",
            "OUTPUT :\n",
            "\"Today at work\",\n",
            "\"I had a meeting with a large group of executives about a new product\",\n",
            "\"I had a meeting with a small group of consultants about a new project\",\n",
            "\"I had a meeting with a marketer about a new brand\",\n",
            "\"I had a meeting with a market team about a new problem\",\n",
            "\"One of my co-workers had a different project idea for a future project\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today I woke up late and missed my morning workout. I was too lazy to make breakfast so I ordered pizza and watched TV all day. I also skipped my afternoon nap and didn't do any work. I spent the entire day being lazy and not doing anything productive. \n",
            "OUTPUT :\n",
            "\"Today I woke up late\",\n",
            "\"I missed my morning workout\",\n",
            "\"I was too lazy to make breakfast\",\n",
            "\"I ordered pizza for breakfast\",\n",
            "\"I watched TV all day\",\n",
            "\"I skipped my afternoon nap\",\n",
            "\"I didn't do any work\",\n",
            "\"I spent the entire day being lazy\",\n",
            "\"I didn't do anything productive\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today at work, I had a busy day finishing up projects and meeting with clients. I also attended a training session on time management skills and had a team meeting to discuss our current progress on a new project. I also had a one-on-one with my manager to go over my performance and received positive feedback, which made me feel good about my contributions to the company. After work, I went for a run and then had dinner with friends, discussing our plans for the weekend. \n",
            "OUTPUT :\n",
            "\"Today at work, I had a busy day finishing up projects and meeting with clients.\" \"I attended a training session on time management skills.\" \"I had a team meeting to discuss our current progress on a new project.\" \"I had a one-on-one with my manager to go over my performance.\" \"I received positive feedback from my manager, which made me feel good about my contributions to the company.\" \"After work, I went for a run.\" \"I had dinner with friends, discussing our plans for the weekend.\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today, I woke up late and missed my morning workout. I was too lazy to make breakfast so I ordered pizza for breakfast, and watched TV all day. I skipped my afternoon nap and didn't do any work, which made me feel lazy. After my nap, I went for a jog, made sure to use the gym restroom, and took a yoga break. \n",
            "OUTPUT :\n",
            "\"Today, I woke up late\",\n",
            "\"I missed my morning workout\",\n",
            "\"I was too lazy to make breakfast\",\n",
            "\"I ordered pizza for breakfast\",\n",
            "\"I watched TV all day\",\n",
            "\"I had a jog with me in the gym\",\n",
            "\"I made sure to use the gym restroom before bed\",\n",
            "\"I took a yoga break after\",\n",
            "\"I went for a yoga break after\",\n",
            "\"I didn't make sure to take a nap before bed\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today I overslept and missed my morning meeting, which was a major project update and my boss was not happy about\n",
            "\n",
            "[950 | 1503.84] loss=0.02 avg=0.02\n",
            "[951 | 1504.74] loss=0.02 avg=0.02\n",
            "[952 | 1505.64] loss=0.01 avg=0.02\n",
            "[953 | 1506.54] loss=0.01 avg=0.02\n",
            "[954 | 1507.44] loss=0.02 avg=0.02\n",
            "[955 | 1508.33] loss=0.02 avg=0.02\n",
            "[956 | 1509.23] loss=0.01 avg=0.02\n",
            "[957 | 1510.13] loss=0.01 avg=0.02\n",
            "[958 | 1511.03] loss=0.02 avg=0.02\n",
            "[959 | 1511.93] loss=0.01 avg=0.02\n",
            "[960 | 1512.83] loss=0.02 avg=0.02\n",
            "[961 | 1513.72] loss=0.01 avg=0.02\n",
            "[962 | 1514.62] loss=0.02 avg=0.02\n",
            "[963 | 1515.52] loss=0.01 avg=0.02\n",
            "[964 | 1516.42] loss=0.01 avg=0.02\n",
            "[965 | 1517.31] loss=0.02 avg=0.02\n",
            "[966 | 1518.22] loss=0.01 avg=0.02\n",
            "[967 | 1519.11] loss=0.02 avg=0.02\n",
            "[968 | 1520.01] loss=0.02 avg=0.02\n",
            "[969 | 1520.90] loss=0.02 avg=0.02\n",
            "[970 | 1521.80] loss=0.02 avg=0.02\n",
            "[971 | 1522.70] loss=0.02 avg=0.02\n",
            "[972 | 1523.60] loss=0.02 avg=0.02\n",
            "[973 | 1524.50] loss=0.02 avg=0.02\n",
            "[974 | 1525.40] loss=0.02 avg=0.02\n",
            "[975 | 1526.30] loss=0.03 avg=0.02\n",
            "[976 | 1527.20] loss=0.02 avg=0.02\n",
            "[977 | 1528.10] loss=0.01 avg=0.02\n",
            "[978 | 1528.99] loss=0.02 avg=0.02\n",
            "[979 | 1529.89] loss=0.03 avg=0.02\n",
            "[980 | 1530.79] loss=0.02 avg=0.02\n",
            "[981 | 1531.69] loss=0.02 avg=0.02\n",
            "[982 | 1532.59] loss=0.02 avg=0.02\n",
            "[983 | 1533.49] loss=0.02 avg=0.02\n",
            "[984 | 1534.39] loss=0.01 avg=0.02\n",
            "[985 | 1535.29] loss=0.02 avg=0.02\n",
            "[986 | 1536.19] loss=0.02 avg=0.02\n",
            "[987 | 1537.09] loss=0.02 avg=0.02\n",
            "[988 | 1537.99] loss=0.02 avg=0.02\n",
            "[989 | 1538.89] loss=0.02 avg=0.02\n",
            "[990 | 1539.79] loss=0.01 avg=0.02\n",
            "[991 | 1540.69] loss=0.03 avg=0.02\n",
            "[992 | 1541.59] loss=0.02 avg=0.02\n",
            "[993 | 1542.49] loss=0.01 avg=0.02\n",
            "[994 | 1543.39] loss=0.02 avg=0.02\n",
            "[995 | 1544.29] loss=0.02 avg=0.02\n",
            "[996 | 1545.19] loss=0.01 avg=0.02\n",
            "[997 | 1546.09] loss=0.03 avg=0.02\n",
            "[998 | 1547.00] loss=0.02 avg=0.02\n",
            "[999 | 1547.90] loss=0.01 avg=0.02\n",
            "Saving checkpoint/run1/model-1000\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            " day is spent making sure my friends are feeling well, and about to go on a trip. \n",
            "OUTPUT :\n",
            "\"Today at work, I had a busy day finishing up projects and meeting with clients.\"\n",
            "\"I attended a training session on time management skills.\"\n",
            "\"I had a team meeting to discuss our current progress on a new project.\"\n",
            "\"I had a one-on-one with my manager to go over my performance.\"\n",
            "\"I received positive feedback, which made me feel good about my contributions to the company.\"\n",
            "\"After work, I went for a run.\"\n",
            "\"I had dinner with friends, discussing our plans for the weekend.\"\n",
            "\"I had a productive conversation with a colleague about our plans for the weekend.\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today, I woke up late and missed my morning workout. I was too lazy to make breakfast so I ordered pizza and watched TV all day. I also skipped my afternoon nap and didn't do any work. I spent the entire day being lazy and not doing anything productive. \n",
            "OUTPUT :\n",
            "\"Today, I woke up late\",\n",
            "\"I missed my morning workout\",\n",
            "\"I was too lazy to make breakfast\",\n",
            "\"I ordered pizza for breakfast\",\n",
            "\"I watched TV all day\",\n",
            "\"I skipped my afternoon nap\",\n",
            "\"I didn't do any work\",\n",
            "\"I spent the entire day being lazy\",\n",
            "\"I didn't do anything productive\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today I overslept and missed my morning meeting, which was a major project update and my boss was not happy about it. I tried to make excuses and explained that I had a long night and didn't set an alarm, but my boss was uninterested in my excuses and told me to be more responsible in the future. \n",
            "OUTPUT :\n",
            "\"Today I overslept\",\n",
            "\"I missed my morning meeting\",\n",
            "\"The meeting was a major project update\",\n",
            "\"My boss was not happy about me missing the meeting\",\n",
            "\"I tried to make excuses for missing the meeting\",\n",
            "\"I explained that I had a long night and didn't set an alarm\",\n",
            "\"My boss was uninterested in my excuses\",\n",
            "\"My boss told me to be more responsible in the future\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I woke up this morning feeling lazy but I forced myself to go to the gym and exercise. I ran on the treadmill for 30 minutes and did some weightlifting. Afterwards, I went grocery shopping and bought ingredients for dinner tonight which is going to be grilled chicken and steamed vegetables. I then came back home and took a nap before starting my work. \n",
            "OUTPUT :\n",
            "\"I woke up this morning feeling lazy\",\n",
            "\"I forced myself to go to the gym\",\n",
            "\"I exercised at the gym\",\n",
            "\"I ran on the treadmill for 30 minutes\",\n",
            "\"I did some weightlifting at the gym\",\n",
            "\"I went grocery shopping\",\n",
            "\"I bought ingredients for dinner tonight\",\n",
            "\"Dinner tonight is going to be grilled chicken and steamed vegetables\",\n",
            "\"I came back home\",\n",
            "\"I took a nap before starting my work\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : As the CEO of Facebook, I was busy handling company's operations and meeting with potential investors yesterday. I also had a call with my team in the morning to discuss the progress of our latest project and it was a productive meeting. In the evening, I went for a walk and spent some time with my family, discussing our future plans and catching up on each other's lives. \n",
            "OUTPUT :\n",
            "\"As the CEO of Facebook, I was busy handling company's operations yesterday\",\n",
            "\"I also had meetings with potential investors yesterday\",\n",
            "\"I had a call with my team in the morning to discuss the progress of our latest project\",\n",
            "\"The call was productive\",\n",
            "\"In the evening, I went for a walk\",\n",
            "\"I spent some time with my family\",\n",
            "\"We discussed our future plans\",\n",
            "\"We caught up on each other's lives\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple\n",
            "\n",
            "[1000 | 1582.69] loss=0.01 avg=0.02\n",
            "[1001 | 1583.59] loss=0.02 avg=0.02\n",
            "[1002 | 1584.49] loss=0.02 avg=0.02\n",
            "[1003 | 1585.39] loss=0.01 avg=0.02\n",
            "[1004 | 1586.29] loss=0.02 avg=0.02\n",
            "[1005 | 1587.19] loss=0.02 avg=0.02\n",
            "[1006 | 1588.09] loss=0.02 avg=0.02\n",
            "[1007 | 1588.99] loss=0.02 avg=0.02\n",
            "[1008 | 1589.89] loss=0.02 avg=0.02\n",
            "[1009 | 1590.79] loss=0.02 avg=0.02\n",
            "[1010 | 1591.69] loss=0.02 avg=0.02\n",
            "[1011 | 1592.60] loss=0.02 avg=0.02\n",
            "[1012 | 1593.50] loss=0.02 avg=0.02\n",
            "[1013 | 1594.40] loss=0.01 avg=0.02\n",
            "[1014 | 1595.30] loss=0.02 avg=0.02\n",
            "[1015 | 1596.20] loss=0.01 avg=0.02\n",
            "[1016 | 1597.09] loss=0.03 avg=0.02\n",
            "[1017 | 1597.99] loss=0.02 avg=0.02\n",
            "[1018 | 1598.90] loss=0.02 avg=0.02\n",
            "[1019 | 1599.80] loss=0.01 avg=0.02\n",
            "[1020 | 1600.70] loss=0.01 avg=0.02\n",
            "[1021 | 1601.60] loss=0.01 avg=0.02\n",
            "[1022 | 1602.50] loss=0.03 avg=0.02\n",
            "[1023 | 1603.41] loss=0.01 avg=0.02\n",
            "[1024 | 1604.31] loss=0.02 avg=0.02\n",
            "[1025 | 1605.21] loss=0.02 avg=0.02\n",
            "[1026 | 1606.11] loss=0.02 avg=0.02\n",
            "[1027 | 1607.01] loss=0.02 avg=0.02\n",
            "[1028 | 1607.91] loss=0.02 avg=0.02\n",
            "[1029 | 1608.82] loss=0.01 avg=0.02\n",
            "[1030 | 1609.72] loss=0.02 avg=0.02\n",
            "[1031 | 1610.62] loss=0.02 avg=0.02\n",
            "[1032 | 1611.52] loss=0.02 avg=0.02\n",
            "[1033 | 1612.42] loss=0.02 avg=0.02\n",
            "[1034 | 1613.32] loss=0.02 avg=0.02\n",
            "[1035 | 1614.22] loss=0.02 avg=0.02\n",
            "[1036 | 1615.12] loss=0.02 avg=0.02\n",
            "[1037 | 1616.02] loss=0.02 avg=0.02\n",
            "[1038 | 1616.92] loss=0.02 avg=0.02\n",
            "[1039 | 1617.82] loss=0.03 avg=0.02\n",
            "[1040 | 1618.72] loss=0.02 avg=0.02\n",
            "[1041 | 1619.62] loss=0.01 avg=0.02\n",
            "[1042 | 1620.52] loss=0.01 avg=0.02\n",
            "[1043 | 1621.43] loss=0.03 avg=0.02\n",
            "[1044 | 1622.33] loss=0.02 avg=0.02\n",
            "[1045 | 1623.23] loss=0.01 avg=0.02\n",
            "[1046 | 1624.13] loss=0.01 avg=0.02\n",
            "[1047 | 1625.03] loss=0.02 avg=0.02\n",
            "[1048 | 1625.93] loss=0.02 avg=0.02\n",
            "[1049 | 1626.83] loss=0.03 avg=0.02\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            "PUT INPUT OUTPUT OUTPUT\n",
            "\n",
            "INPUT : Today I woke up early I went for a jog and did my daily chores including cleaning the house and cooking breakfast I then went to the library and did my daily chores including meeting the parents tomorrow morning and studying for my exams I then walked around the library and saw my friend John who was also studying, we talked for a while and then I went for a walk and spent the evening reading a book John then came back home and took a nap before bed\n",
            "OUTPUT :\n",
            "\"Today I woke up early\",\n",
            "\"I went for a jog and did my daily chores\",\n",
            "\"My daily chores included cleaning the house and cooking breakfast\",\n",
            "\"I then went under the bus to get my friends', I found them at the local electronics shop\",\n",
            "\"I took a trip to Europe with my friends\",\n",
            "\"We stayed in different cities in Europe during the trip\",\n",
            "\"We tried new foods in Europe during the trip\",\n",
            "\"We tried cooking breakfast at the cafe we stayed in in Europe\",\n",
            "\"We also went hiking in Europe during the trip\",\n",
            "\"We caught wind of the trip by walking for 5 kilometers\",\n",
            "\"We then turned around and continued walking\",\n",
            "\"We finished our hike in Europe during the trip\",\n",
            "\"We caught up with my friend John in the evening\",\n",
            "\"We talked for a while after that\",\n",
            "\"We went sightseeing in Europe during the trip\",\n",
            "\"We stayed in different cities in Europe during the trip\",\n",
            "\"We tried new foods in Europe during the trip\",\n",
            "\"We tried cooking breakfast at the cafe we stayed in Europe\",\n",
            "\"We also went hiking in Europe during the trip\",\n",
            "\"We caught up with my friend John in the evening\",\n",
            "\"We talked for a while after that\",\n",
            "\"We went sightseeing in Europe during the trip\",\n",
            "\"We stayed in different cities in Europe during the trip\",\n",
            "\"We tried new foods in Europe during the trip\",\n",
            "\"We tried cooking breakfast at the cafe we stayed in Europe\",\n",
            "\"We also went hiking in Europe during the trip\",\n",
            "\"We caught up with my friend John in the evening\",\n",
            "\"We talked for a while after that\",\n",
            "\"We went sightseeing in Europe during the trip\",\n",
            "\"We stayed in different cities in Europe during the trip\",\n",
            "\"We tried new foods in Europe during the trip\",\n",
            "\"We tried cooking breakfast at the cafe we stayed in Europe\",\n",
            "\"We also went hiking in Europe during the trip\",\n",
            "\"We caught up with my friend John in the evening\",\n",
            "\"We talked for a while after that\",\n",
            "\"We went sightseeing in Europe during the trip\",\n",
            "\"We stayed in different cities in Europe during the trip\",\n",
            "\"We tried new foods in Europe during the trip\",\n",
            "\"We tried cooking breakfast at the cafe we stayed in Europe\",\n",
            "\"We also went hiking in Europe during the trip\",\n",
            "\"We caught up with my friend John in the evening\",\n",
            "\"We talked for a while after that\",\n",
            "\"We went sightseeing in Europe during the trip\",\n",
            "\"We stayed in different cities in Europe during the trip\",\n",
            "\"We tried new foods in Europe during the trip\",\n",
            "\"We tried cooking breakfast at the cafe we stayed in Europe\",\n",
            "\"We also went hiking in Europe during the trip\",\n",
            "\"We caught up with my friend John in the evening\",\n",
            "\"We talked for a while after that\",\n",
            "\"We went sightseeing in Europe during the trip\",\n",
            "\"We stayed in different cities in Europe during the trip\",\n",
            "\"We tried new foods in Europe during the trip\",\n",
            "\"We tried cooking breakfast at the cafe we stayed in Europe\",\n",
            "\"We also went hiking in Europe during the trip\",\n",
            "\"We caught up with my friend John in the evening\",\n",
            "\"We talked for a while after that\",\n",
            "\"We went sightseeing in Europe during the trip\",\n",
            "\"We stayed in different cities in Europe during the trip\",\n",
            "\"We tried new foods in Europe during the trip\",\n",
            "\"We tried cooking breakfast at the cafe we stayed in Europe\",\n",
            "\"We also went hiking in Europe during the trip\",\n",
            "\"We caught up with my friend John in the evening\",\n",
            "\"We talked for a while after that\",\n",
            "\"We went sightseeing in Europe during the trip\",\n",
            "\"We stayed in different cities in Europe during the trip\",\n",
            "\"We tried new foods in Europe during the trip\",\n",
            "\"We tried cooking breakfast at the cafe we stayed in Europe\",\n",
            "\"We also went hiking in Europe during the trip\",\n",
            "\"We caught up with my friend John in the evening\",\n",
            "\"We talked for a while after that\",\n",
            "\"We went sightseeing in Europe during the trip\",\n",
            "\"We stayed in different cities in Europe during the trip\",\n",
            "\"We tried new foods in Europe during the trip\",\n",
            "\"We tried cooking breakfast at the cafe we stayed in Europe\n",
            "\n",
            "[1050 | 1660.08] loss=0.01 avg=0.02\n",
            "[1051 | 1660.98] loss=0.02 avg=0.02\n",
            "[1052 | 1661.87] loss=0.02 avg=0.02\n",
            "[1053 | 1662.77] loss=0.02 avg=0.02\n",
            "[1054 | 1663.67] loss=0.01 avg=0.02\n",
            "[1055 | 1664.57] loss=0.01 avg=0.02\n",
            "[1056 | 1665.47] loss=0.02 avg=0.02\n",
            "[1057 | 1666.37] loss=0.02 avg=0.02\n",
            "[1058 | 1667.27] loss=0.02 avg=0.02\n",
            "[1059 | 1668.17] loss=0.02 avg=0.02\n",
            "[1060 | 1669.07] loss=0.01 avg=0.02\n",
            "[1061 | 1669.97] loss=0.02 avg=0.02\n",
            "[1062 | 1670.87] loss=0.02 avg=0.02\n",
            "[1063 | 1671.76] loss=0.03 avg=0.02\n",
            "[1064 | 1672.66] loss=0.01 avg=0.02\n",
            "[1065 | 1673.56] loss=0.02 avg=0.02\n",
            "[1066 | 1674.46] loss=0.01 avg=0.02\n",
            "[1067 | 1675.36] loss=0.01 avg=0.02\n",
            "[1068 | 1676.26] loss=0.02 avg=0.02\n",
            "[1069 | 1677.16] loss=0.02 avg=0.02\n",
            "[1070 | 1678.06] loss=0.02 avg=0.02\n",
            "[1071 | 1678.96] loss=0.02 avg=0.02\n",
            "[1072 | 1679.86] loss=0.01 avg=0.02\n",
            "[1073 | 1680.76] loss=0.02 avg=0.02\n",
            "[1074 | 1681.65] loss=0.02 avg=0.02\n",
            "[1075 | 1682.56] loss=0.01 avg=0.02\n",
            "[1076 | 1683.46] loss=0.02 avg=0.02\n",
            "[1077 | 1684.36] loss=0.02 avg=0.02\n",
            "[1078 | 1685.26] loss=0.02 avg=0.02\n",
            "[1079 | 1686.16] loss=0.02 avg=0.02\n",
            "[1080 | 1687.05] loss=0.03 avg=0.02\n",
            "[1081 | 1687.95] loss=0.02 avg=0.02\n",
            "[1082 | 1688.85] loss=0.03 avg=0.02\n",
            "[1083 | 1689.75] loss=0.02 avg=0.02\n",
            "[1084 | 1690.65] loss=0.02 avg=0.02\n",
            "[1085 | 1691.55] loss=0.03 avg=0.02\n",
            "[1086 | 1692.45] loss=0.02 avg=0.02\n",
            "[1087 | 1693.34] loss=0.02 avg=0.02\n",
            "[1088 | 1694.24] loss=0.02 avg=0.02\n",
            "[1089 | 1695.14] loss=0.01 avg=0.02\n",
            "[1090 | 1696.04] loss=0.02 avg=0.02\n",
            "[1091 | 1696.94] loss=0.01 avg=0.02\n",
            "[1092 | 1697.84] loss=0.02 avg=0.02\n",
            "[1093 | 1698.74] loss=0.02 avg=0.02\n",
            "[1094 | 1699.64] loss=0.02 avg=0.02\n",
            "[1095 | 1700.54] loss=0.02 avg=0.02\n",
            "[1096 | 1701.44] loss=0.01 avg=0.02\n",
            "[1097 | 1702.34] loss=0.02 avg=0.02\n",
            "[1098 | 1703.24] loss=0.01 avg=0.02\n",
            "[1099 | 1704.14] loss=0.02 avg=0.02\n",
            "Saving checkpoint/run1/model-1100\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            " to a high level of mindfulness\",\n",
            "\"My mindfulness is based on noticing and experiencing the nature of things and their context\",\n",
            "\"My mindfulness is being able to see how different aspects of the world feel together\",\n",
            "\"I am able to see how different aspects of the world feel together without thinking about it\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I recently took up gardening as a hobby. I enjoy learning about different plants, how to care for them, and watching them grow. I have a small garden in my backyard where I grow a variety of vegetables, herbs, and flowers. Gardening has been a great way to connect with nature and relieve stress. I plan to expand my garden and try growing new plants in the future. \n",
            "OUTPUT :\n",
            "\"I recently took up gardening as a hobby\",\n",
            "\"I enjoy learning about different plants\",\n",
            "\"I enjoy learning how to care for different plants\",\n",
            "\"I enjoy watching plants grow\",\n",
            "\"I have a small garden in my backyard\",\n",
            "\"I grow a variety of vegetables in my backyard garden\",\n",
            "\"I grow a variety of herbs in my backyard garden\",\n",
            "\"I grow a variety of flowers in my backyard garden\",\n",
            "\"Gardening has been a great way to connect with nature\",\n",
            "\"Gardening has been a great way to relieve stress\",\n",
            "\"I plan to expand my garden in the future\",\n",
            "\"I plan to try growing new plants in the future\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I recently started practicing yoga to improve my physical and mental well-being. I attend classes at a local studio and enjoy the challenge of different poses. The practice has helped me become more flexible, stronger, and calmer. I also appreciate the mindfulness and breathing techniques that are a part of the practice. I look forward to continuing my yoga journey and experiencing its benefits. \n",
            "OUTPUT :\n",
            "\"I recently started practicing yoga\",\n",
            "\"I started practicing yoga to improve my physical well-being\",\n",
            "\"I started practicing yoga to improve my mental well-being\",\n",
            "\"I attend yoga classes at a local studio\",\n",
            "\"I enjoy the challenge of different yoga poses\",\n",
            "\"Practicing yoga has helped me become more flexible\",\n",
            "\"Practicing yoga has helped me become stronger\",\n",
            "\"Practicing yoga has helped me become calmer\",\n",
            "\"I appreciate the mindfulness techniques in yoga\",\n",
            "\"I appreciate the breathing techniques in yoga\",\n",
            "\"I look forward to continuing my yoga journey\",\n",
            "\"I look forward to experiencing the benefits of practicing yoga\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I recently started volunteering at a local animal shelter. I love spending time with the animals and taking care of them. It's been a great way to give back to my community and make a positive impact. I also enjoy working with the staff and volunteers and learning about animal behavior and care. Volunteering has been a rewarding experience and I plan to continue doing it for a long time. \n",
            "OUTPUT :\n",
            "\"I recently started volunteering at a local animal shelter\",\n",
            "\"I love spending time with the animals at the shelter\",\n",
            "\"I love taking care of the animals at the shelter\",\n",
            "\"Volunteering at the animal shelter is a great way to give back to my community\",\n",
            "\"Volunteering at the animal shelter is a great way to make a positive impact\",\n",
            "\"I enjoy working with the staff at the animal shelter\",\n",
            "\"I enjoy working with the volunteers at the animal shelter\",\n",
            "\"I enjoy learning about animal behavior at the animal shelter\",\n",
            "\"I enjoy learning about animal care at the animal shelter\",\n",
            "\"Volunteering at the animal shelter has been a rewarding experience\",\n",
            "\"I plan to continue volunteering at the animal shelter for a long time\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I recently started a new job as a project manager. I'm excited to take on new challenges and responsibilities. I have a great team of coworkers who are supportive and knowledgeable. I enjoy learning about the latest project management techniques and finding creative solutions to problems. I'm confident that I will excel in this role and make a significant contribution to the company. \n",
            "OUTPUT :\n",
            "\"I recently started a new job as a project manager\",\n",
            "\n",
            "[1100 | 1741.12] loss=0.01 avg=0.02\n",
            "[1101 | 1742.02] loss=0.02 avg=0.02\n",
            "[1102 | 1742.91] loss=0.02 avg=0.02\n",
            "[1103 | 1743.82] loss=0.02 avg=0.02\n",
            "[1104 | 1744.71] loss=0.02 avg=0.02\n",
            "[1105 | 1745.62] loss=0.02 avg=0.02\n",
            "[1106 | 1746.52] loss=0.02 avg=0.02\n",
            "[1107 | 1747.42] loss=0.01 avg=0.02\n",
            "[1108 | 1748.33] loss=0.02 avg=0.02\n",
            "[1109 | 1749.23] loss=0.02 avg=0.02\n",
            "[1110 | 1750.14] loss=0.01 avg=0.02\n",
            "[1111 | 1751.04] loss=0.02 avg=0.02\n",
            "[1112 | 1751.94] loss=0.02 avg=0.02\n",
            "[1113 | 1752.84] loss=0.01 avg=0.02\n",
            "[1114 | 1753.74] loss=0.03 avg=0.02\n",
            "[1115 | 1754.64] loss=0.01 avg=0.02\n",
            "[1116 | 1755.55] loss=0.02 avg=0.02\n",
            "[1117 | 1756.45] loss=0.02 avg=0.02\n",
            "[1118 | 1757.35] loss=0.01 avg=0.02\n",
            "[1119 | 1758.26] loss=0.01 avg=0.02\n",
            "[1120 | 1759.15] loss=0.01 avg=0.02\n",
            "[1121 | 1760.06] loss=0.02 avg=0.02\n",
            "[1122 | 1760.96] loss=0.02 avg=0.02\n",
            "[1123 | 1761.86] loss=0.02 avg=0.02\n",
            "[1124 | 1762.76] loss=0.02 avg=0.02\n",
            "[1125 | 1763.67] loss=0.01 avg=0.02\n",
            "[1126 | 1764.57] loss=0.02 avg=0.02\n",
            "[1127 | 1765.47] loss=0.03 avg=0.02\n",
            "[1128 | 1766.38] loss=0.01 avg=0.02\n",
            "[1129 | 1767.28] loss=0.02 avg=0.02\n",
            "[1130 | 1768.18] loss=0.02 avg=0.02\n",
            "[1131 | 1769.08] loss=0.02 avg=0.02\n",
            "[1132 | 1769.98] loss=0.01 avg=0.02\n",
            "[1133 | 1770.88] loss=0.02 avg=0.02\n",
            "[1134 | 1771.78] loss=0.02 avg=0.02\n",
            "[1135 | 1772.68] loss=0.03 avg=0.02\n",
            "[1136 | 1773.58] loss=0.02 avg=0.02\n",
            "[1137 | 1774.49] loss=0.02 avg=0.02\n",
            "[1138 | 1775.39] loss=0.01 avg=0.02\n",
            "[1139 | 1776.29] loss=0.02 avg=0.02\n",
            "[1140 | 1777.19] loss=0.01 avg=0.02\n",
            "[1141 | 1778.09] loss=0.02 avg=0.02\n",
            "[1142 | 1778.99] loss=0.01 avg=0.02\n",
            "[1143 | 1779.89] loss=0.04 avg=0.02\n",
            "[1144 | 1780.79] loss=0.01 avg=0.02\n",
            "[1145 | 1781.69] loss=0.02 avg=0.02\n",
            "[1146 | 1782.59] loss=0.02 avg=0.02\n",
            "[1147 | 1783.49] loss=0.01 avg=0.02\n",
            "[1148 | 1784.40] loss=0.02 avg=0.02\n",
            "[1149 | 1785.30] loss=0.01 avg=0.02\n",
            "Generating samples...\n",
            "======== SAMPLE 3 ========\n",
            " text !\">\n",
            "<</if>>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I went to the library after school to study for my exams, I found a quiet corner and started studying, I studied for 2 hours and then I decided to take a break, I walked around the library and saw my friend John who was also studying, we talked for a while and then I went back to my seat and continued studying. \n",
            "OUTPUT :\n",
            "\"I went to the library after school to study for my exams\",\n",
            "\"I found a quiet corner in the library and started studying\",\n",
            "\"I studied for 2 hours\",\n",
            "\"I decided to take a break from studying\",\n",
            "\"I walked around the library\",\n",
            "\"I saw my friend John who was also studying\",\n",
            "\"We talked for a while\",\n",
            "\"I went back to my seat and continued studying\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I had a great time playing basketball with my friends and my favorite team won the game, we also went to a nearby restaurant and tried new dishes, it was a fantastic day overall. \n",
            "OUTPUT :\n",
            "\"I had a great time playing basketball with my friends\",\n",
            "\"my favorite team won the game\",\n",
            "\"we also went to a nearby restaurant\",\n",
            "\"we tried new dishes at the restaurant\",\n",
            "\"it was a fantastic day overall\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I went to the library today and studied for my exams, I also attended a workshop on how to study effectively and learned some new techniques, I finished my day by going for a walk in the park and listening to music \n",
            "OUTPUT :\n",
            "\"I went to the library today\",\n",
            "\"I studied for my exams at the library\",\n",
            "\"I attended a workshop on how to study effectively\",\n",
            "\"I learned some new techniques in the workshop\",\n",
            "\"I finished my day by going for a walk in the park\",\n",
            "\"I listened to music while walking in the park\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : I had a meeting with my boss and the CEO of the company this morning and discussed the progress of our project and discussed the budget for the next quarter. Afterwards, I worked on the report for the project and sent it to my team and then went to the gym and had a great workout \n",
            "OUTPUT :\n",
            "\"I had a meeting with my boss and the CEO of the company this morning\",\n",
            "\"In the meeting, we discussed the progress of our project\",\n",
            "\"We also discussed the budget for the next quarter\",\n",
            "\"Afterwards, I worked on the report for the project\",\n",
            "\"I sent it to my team\",\n",
            "\"I then went to gym\",\n",
            "\"I had a great workout at the gym\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today I woke up early, went for a jog and did my daily chores including cleaning the house and cooking breakfast. After that, I attended my online yoga class and also finished my work for the day. In the evening, I met my best friend for a walk and we talked about our future plans and also had a small picnic. Overall, it was a productive day and I am feeling very content. \n",
            "OUTPUT :\n",
            "\"Today I woke up early\",\n",
            "\"I went for a jog and did my daily chores\",\n",
            "\"My daily chores included cleaning the house and cooking breakfast\",\n",
            "\"After that, I attended my online yoga class\",\n",
            "\"I finished my work for the day\",\n",
            "\"In the evening, I met my best friend for a walk\",\n",
            "\"We talked about our future plans and also had a small picnic\",\n",
            "\"Overall, it was a productive day\",\n",
            "\"I am feeling very content\"\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it. \n",
            "\n",
            "INPUT : Today at work, I had a busy day as usual, finishing up projects and meeting with clients. I also attended a training session on time management skills\n",
            "\n",
            "[1150 | 1817.95] loss=0.02 avg=0.02\n",
            "[1151 | 1818.85] loss=0.01 avg=0.02\n",
            "[1152 | 1819.75] loss=0.02 avg=0.02\n",
            "[1153 | 1820.65] loss=0.03 avg=0.02\n",
            "[1154 | 1821.55] loss=0.02 avg=0.02\n",
            "[1155 | 1822.45] loss=0.02 avg=0.02\n",
            "[1156 | 1823.35] loss=0.02 avg=0.02\n",
            "[1157 | 1824.25] loss=0.02 avg=0.02\n",
            "[1158 | 1825.14] loss=0.01 avg=0.02\n",
            "[1159 | 1826.04] loss=0.01 avg=0.02\n",
            "[1160 | 1826.94] loss=0.01 avg=0.02\n",
            "[1161 | 1827.83] loss=0.01 avg=0.02\n",
            "[1162 | 1828.73] loss=0.01 avg=0.02\n",
            "[1163 | 1829.63] loss=0.03 avg=0.02\n",
            "[1164 | 1830.53] loss=0.02 avg=0.02\n",
            "[1165 | 1831.43] loss=0.03 avg=0.02\n",
            "[1166 | 1832.33] loss=0.02 avg=0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt = \"model-400\"\n",
        "newmodel = \"models/STC\"\n",
        "f1 = f\"{ckpt}.data-00000-of-00001\"\n",
        "f2 = f\"{ckpt}.index\"\n",
        "f3 = f\"{ckpt}.meta\"\n",
        "f4 = f\"checkpoint\"\n",
        "\n",
        "f11 = f\"model.ckpt.data-00000-of-00001\"\n",
        "f21 = f\"model.ckpt.index\"\n",
        "f31 = f\"model.ckpt.meta\"\n",
        "\n",
        "!cp checkpoint/run1/$f1 $newmodel/$f11\n",
        "!cp checkpoint/run1/$f2 $newmodel/$f21\n",
        "!cp checkpoint/run1/$f3 $newmodel/$f31\n",
        "!cp models/$base/$f4 $newmodel/$f4\n",
        "\n",
        "!cp models/$base/encoder.json $newmodel/encoder.json\n",
        "!cp models/$base/hparams.json $newmodel/hparams.json\n",
        "!cp models/$base/vocab.bpe $newmodel/vocab.bpe"
      ],
      "metadata": {
        "id": "W8hN_FIpr2_6"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##INFERENCE\n",
        "\n",
        "!python gpt-2/src/generate_unconditional_samples.py --temperature 1 --top_k 0 --top_p 1.0 --model_name STC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUb2KjfqtWy6",
        "outputId": "0d7f3522-0bfe-4221-d0b7-26c3bb5be77a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-10 11:51:25.229092: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "======================================== SAMPLE 1 ========================================\n",
            "Wonder if my Internet connection is working.I tried using a standard DVD burner but it is not working.I tried playing some songs on the iPod touch but it is not working.I tried playing a few songs on the radio but it is not working.I tried listening to music on the iPods but it is not working.I tried watching TV shows on the iPods but it is not working.I tried taking pictures on the iPods but it is not working.I tried downloading movies on the iPods but it is not working.I tried listening to music on the iPods but it is not working.\n",
            "\n",
            "kx2ppk Profile Joined October 2013 United States 10 Posts Last Edited: 2015-11-31 18:41:01 #10\n",
            "\n",
            "\n",
            "I tried downloading game content from the internet but it is not working.\n",
            "\n",
            "\n",
            "I tried listening to music on the iPod touch but it is not working. I tried watching TV shows on the iPod touch but it is not working. I tried taking pictures on the iPod touch but it is not working. I tried watching movies on the iPod touch but it is not working. I tried downloading web pages from the internet but it is not working.\n",
            "\n",
            "kevinweetley Profile Joined August 2013 Finland 30 Posts #11 On November 31 2015 10:53 kevinweetley wrote:\n",
            "\n",
            "On November 31 2015 10:42 kevinweetley wrote:\n",
            "\n",
            "I tried downloading game content from the internet but it is not working.\n",
            "\n",
            "\n",
            "I tried listening to music on the iPod touch but it is not working. I tried watching TV shows on the iPod touch but it is not working. I tried taking pictures on the iPod touch but it is not working. I tried watching movies on the iPod touch but it is not working.\n",
            "\n",
            "\n",
            "Awesome game, I love the music. I am also planning to go to a concert with my friends next month. Can't wait to experience good music while experiencing bad.\n",
            "\n",
            "gtkinfernon Profile Blog Joined December 2013 France 1813 Posts #12 On November 31 2015 10:46 kx2ppk wrote:\n",
            "\n",
            "I tried downloading game content from the internet but it is not working.\n",
            "\n",
            "\n",
            "I tried listening to music on the iPod touch but it is not working.\n",
            "\n",
            "\n",
            "I tried watching TV shows on the iPod touch but it is not working. I tried taking pictures on the iPod touch but it is not working. I tried taking pictures in the movie I love the music. I am also planning to go to a concert with my friends next month. Can't wait to experience good music while experiencing bad.\n",
            "\n",
            "clipz431 Profile Joined February 2014 United States 2 Posts #13 On November 31 2015 10:51 fridaymal22 wrote:\n",
            "\n",
            "Show nested quote +\n",
            "\n",
            "On November 31 2015 10:44 bittvot wrote:\n",
            "\n",
            "On November 31 2015 10:42 bittvot wrote:\n",
            "\n",
            "I tried downloading game content from the internet but it is not working.\n",
            "\n",
            "\n",
            "I tried listening to music on the iPod touch but it is not working.\n",
            "\n",
            "\n",
            "I tried watching TV shows on the iPod touch but it is not working. I tried taking pictures on the iPod touch but it is not working. I tried taking pictures in the movie I love the music. I am also planning to go to a concert with my friends next month. Can't wait to experience good music while experiencing bad.\n",
            "\n",
            "megd Profile Joined October 2007 Australia 565 Posts #14 Great job @deletingEGiA\n",
            "\n",
            "Contestant of the Year !!!!!! #1 !!!!!!! Congratulations TO OFD ON !!!!!! !!! **TOP 5 TOC 2013 WINNER !!!!!! !!! !!! !!! !!! !!! !!! !!! !!! !!! !!!!!! !!! !!! !!!\n",
            "\n",
            "chakedowns86 Profile Blog Joined August 2011 Germany 5789 Posts #15 I got to watch the first 5 games of clans games to help my friend with his exams!!! Great job @KillingEvils <3\n",
            "\n",
            "ReaperOfTime Profile Blog Joined January 2011 Italy 1198 Posts Last Edited: 2015-11-31 01:02:17* Last edit: ReaperOfTime on Nov 1 2015 18:37 jukka wrote:\n",
            "\n",
            "I got to watch the first 5 games of clans games to help my friend with his exams!!! Great job @KillingEvils <3\n",
            "\n",
            "I'm an avid soccer fan and always try to take a back seat to the bigger picture. I'm an avid soccer fan and always try to take a back seat to the bigger picture.\n",
            "\n",
            "chakedowns86 Profile Blog Joined August 2011 Germany 5789 Posts Last Edited: 2015-11-31 01:03:45* Last edit: ReaperOfTime on Nov 1 2015 18:52 skynx3700 wrote:\n",
            "\n",
            "I got to watch the first 5 games of clans games to help my friend with his exams!!! Great job @K\n",
            "======================================== SAMPLE 2 ========================================\n",
            "I recently started learning Turkish-inspired cooking and it has been very helpful in reviving my faith in food. I also love cooking in restaurants and finding new ways to make delicious food. In just a few months, I hope to have a small kitchen and enjoy learning more about different cultures.\n",
            "\n",
            "Today\n",
            "\n",
            "I'm spending my free time cooking and cleaning up after my friends. We've been messing around a lot lately and some of the time we didn't make it past lunchtime. I try to keep an eye on his back and make sure he is feeling well, but sometimes he refuses to move a muscle. I try to take care of him and make sure his friends have fun after work and then we go to the beach and relax.\n",
            "\n",
            "I also have a busy day where I go to bed early and go to bed empty-handed. I make sure to call my friends and make sure to give them goodnight talk and then go to bed early. After that, I go to work and make sure everyone is having a great day. I then read a book and go to the club while my friends and I discuss our plans for the weekend.\n",
            "\n",
            "Yum days have been challenging but I am grateful for the time spent being human and having a productive day.\n",
            "\n",
            "(Visited 5,885 times, 2 visits today)<|endoftext|>Today I had dinner with friends and loved ones at the lovely Sushi Tavern along the San Fernando River in Venice. We talked seafood dishes, sangria, and danced to songs about our favorite foods. In the evening, we gamedevailed and spent the day on the sofa, reading a book and playing games. \n",
            "Today I had dinner with friends and loved ones at the lovely Sushi Tavern along the San Fernando River in Venice. We talked seafood dishes, sangria, and danced to songs about our favorite foods. In the evening, we gamedevailed and spent the day on the sofa, reading a book and playing games. \n",
            "Today I had dinner with friends and loved others at the beautiful Sushi Tavern along the San Fernando River in Venice. We talked seafood dishes, sangria, and danced to songs about our favorite foods. In the evening, we gamedevailed and spent the day on the sofa, reading a book and playing games \n",
            "Today I had dinner with friends and loved others at the beautiful Sushi Tavern along the San Fernando River in Venice. We talked seafood dishes, sangria, and danced to songs about our favorite foods. In the evening, we gamedevailed and spent the day on the sofa, reading a book and playing games \n",
            "Today I had dinner with friends and loved others at the beautiful Sushi Tavern along the San Fernando River in Venice. We talked seafood dishes, sangria, and danced to songs about our favorite foods. In the evening, we gamedevailed and spent the day on the sofa, reading a book and playing games \n",
            "Today I had dinner with friends and loved others at the beautiful Sushi Tavern along the San Fernando River in Venice. We talked seafood dishes, sangria, and danced to songs about our favorite foods. In the evening, we gamedevailed and spent the day on the sofa, reading a book and playing games\n",
            "Today I had dinner with friends and loved others at the beautiful Sushi Tavern along the San Fernando River in Venice. We talked seafood dishes, sangria, and danced to songs about our favorite foods. In the evening, we gamedevailed and spent the day on the sofa, reading a book and playing games\n",
            "Today\n",
            "Today I told my parents about the today and it was a pretty amazing morning. I went to the library and started studying for my exams, then I went to the park and played some soccer and walked around the area. I heard music and then I went back to my room and finished my studies. After that, I went to the library and started studying for my exams again, this time at a different library. I tried to find a quiet area and saw a stranger, but he was too busy studying for his exams to notice me. I told him I had friends who were also students and invited them to join me in our study areas. After that, we continued studying for about 10 minutes, and then a quiet servant came and took us to his house. He was very friendly, explained about our history and where we were going, and then we went on our way. He sat beside me on the sofa and told me stories that I had heard before and then he told me how he had been born in Venice and raised there, how he had great friends there and that they also loved him and tried to make him love them. I told him that I had learned so much from their conversation and that they would do anything for it, and that I would have them repeat it to me every time they were home. \n",
            "Today I learned a lot about history and how it had an impact on my past and future \n",
            "Today I learned a lot about\n",
            "Traceback (most recent call last):\n",
            "  File \"gpt-2/src/generate_unconditional_samples.py\", line 79, in <module>\n",
            "    fire.Fire(sample_model)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/fire/core.py\", line 141, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/fire/core.py\", line 475, in _Fire\n",
            "    component, remaining_args = _CallAndUpdateTrace(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/fire/core.py\", line 691, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"gpt-2/src/generate_unconditional_samples.py\", line 71, in sample_model\n",
            "    out = sess.run(output)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\", line 967, in run\n",
            "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\", line 1190, in _run\n",
            "    results = self._do_run(handle, final_targets, final_fetches,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\", line 1370, in _do_run\n",
            "    return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\", line 1377, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\n",
            "    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\n",
            "    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python gpt-2/src/interactive_conditional_samples.py --temperature 0.1 --top_k 40 --top_p 1.0 --model_name 'STC'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaIIgBTBuPxs",
        "outputId": "1e53f9ed-dabe-4d8f-bc5e-443fccecee9d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-02-10 12:11:59.127331: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "Model prompt >>> Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it.\\n\\nINPUT : anand came home today and we had a great time . went to kochi for dinner. \\nOUTPUT :\n",
            "======================================== SAMPLE 1 ========================================\n",
            " A few days ago, I had a job as a marketing manager at a multinational corporation. I was responsible for creating and implementing a large-scale marketing strategy for the company.  I also had the opportunity to interact with the CEO and COO, who had a productive day and relaxed the workload, and also had me play a role in the success of the campaign.  I had a very exciting meeting with the CEO and COO, in which we discussed the progress of the campaign and also discussed the possible rewards of the campaign.  The meeting was very productive and made me feel good about the success of the campaign.  I also had the opportunity to interact with the COO and CEO during the meeting, and they made me feel good about the success of the campaign.\\n\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it.\\n\\nINPUT : today was a big day for me. I went to the gym and did some weightlifting, read a book and had a picnic. Afterwards, I went to the restaurant and had a great time eating and laughing at each other\\'s mistakes.\\n\\n\\n\\ n: The only non-fiction book I own is a book by a friend who is a writer. She describes herself as a \"long-time reader\", and she reads a lot of books. She also like to travel and see different cultures. She has a few upcoming dates where she will be taking a trip to Europe with her family.\\n\\n\\ n: I just finished reading her book and can't wait to share it with my friends and family. It is going to be an amazing journey and I am looking forward to a very special present from my friends and family soon.\\n\\n\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it.\\n\\n\n",
            "\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain only single knowledge meaning in it.\\n\\n\n",
            "\n",
            "<|endoftext|>\n",
            "\n",
            "\n",
            "Below is a given INPUT as text and OUTPUT is its multiple non dividable sentences such that each sentence contain\n",
            "================================================================================\n",
            "Model prompt >>> Traceback (most recent call last):\n",
            "  File \"gpt-2/src/interactive_conditional_samples.py\", line 73, in interact_model\n",
            "    raw_text = input(\"Model prompt >>> \")\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"gpt-2/src/interactive_conditional_samples.py\", line 91, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/fire/core.py\", line 141, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/fire/core.py\", line 475, in _Fire\n",
            "    component, remaining_args = _CallAndUpdateTrace(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/fire/core.py\", line 691, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"gpt-2/src/interactive_conditional_samples.py\", line 88, in interact_model\n",
            "    print(\"=\" * 80)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\", line 1620, in __exit__\n",
            "    def __exit__(self, exec_type, exec_value, exec_tb):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}