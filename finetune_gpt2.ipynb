{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3ZMzpv9Tsl3QQZy+qTSWl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0363b142d1664c7fbb1ffe9c7e6ba908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcd09622d6784d3a835e16013de7d469",
              "IPY_MODEL_ab6b6a292a7941bb8c7677c2180288a9",
              "IPY_MODEL_b68815e3ddec4609b26139b8e0078d7c"
            ],
            "layout": "IPY_MODEL_44df1d933bc74e56aaab9cc428c9737e"
          }
        },
        "bcd09622d6784d3a835e16013de7d469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f3acfdf3d284a578385b0f2408bb20b",
            "placeholder": "​",
            "style": "IPY_MODEL_95faab1310114d5caf85b51912cc40fc",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "ab6b6a292a7941bb8c7677c2180288a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3242198c78042d88925a474b9ff01d3",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb650d54d6784462a3aa6b53d8842353",
            "value": 1042301
          }
        },
        "b68815e3ddec4609b26139b8e0078d7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5aaf72b8929645de8f7ac61e2539682c",
            "placeholder": "​",
            "style": "IPY_MODEL_40440495296341a2a073e434735ea64f",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 4.95MB/s]"
          }
        },
        "44df1d933bc74e56aaab9cc428c9737e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f3acfdf3d284a578385b0f2408bb20b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95faab1310114d5caf85b51912cc40fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3242198c78042d88925a474b9ff01d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb650d54d6784462a3aa6b53d8842353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5aaf72b8929645de8f7ac61e2539682c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40440495296341a2a073e434735ea64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38e0ccb6d07c40fca410401aa61be425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d477d5e223d4f03b0e130745039de86",
              "IPY_MODEL_689f98dfff8640138832e0e52a5f31d8",
              "IPY_MODEL_cc30bcde33df469cac1d64a8740b68d1"
            ],
            "layout": "IPY_MODEL_fe8646107b5e494bb21ec27fb3fee210"
          }
        },
        "2d477d5e223d4f03b0e130745039de86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68977372dd214b8d8b547cdb0b112ac1",
            "placeholder": "​",
            "style": "IPY_MODEL_63b32fd8ae3f492d92e9e60c89d96457",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "689f98dfff8640138832e0e52a5f31d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_808b577e6b5b444e90f408d0fceee9fc",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eda3dcba211e4c329f159ca4af93cd9e",
            "value": 456318
          }
        },
        "cc30bcde33df469cac1d64a8740b68d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a42452c6df984295878df16a8a5667e6",
            "placeholder": "​",
            "style": "IPY_MODEL_dad96c7a9d6a4ada9c3d50bac75fd0fe",
            "value": " 456k/456k [00:00&lt;00:00, 2.65MB/s]"
          }
        },
        "fe8646107b5e494bb21ec27fb3fee210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68977372dd214b8d8b547cdb0b112ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63b32fd8ae3f492d92e9e60c89d96457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "808b577e6b5b444e90f408d0fceee9fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eda3dcba211e4c329f159ca4af93cd9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a42452c6df984295878df16a8a5667e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dad96c7a9d6a4ada9c3d50bac75fd0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "629ac868d29a44878e44ce6d70d267be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_337899346f9542dd8be4639749806232",
              "IPY_MODEL_ffb4041c1058434ea9315a1136ea112f",
              "IPY_MODEL_cb49463d1d354631a02d7c2f259e9f4f"
            ],
            "layout": "IPY_MODEL_6bfba1402b164de7afa9ffe27b5092fa"
          }
        },
        "337899346f9542dd8be4639749806232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e569a6f3b91247f4a7c7d6120e78d0f7",
            "placeholder": "​",
            "style": "IPY_MODEL_bb42a8604a0f4065b4e6b24ffe4fd386",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ffb4041c1058434ea9315a1136ea112f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81a4b2acb5f34639baed96e31cc9d39b",
            "max": 718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_465ad94909964a228630e52e942a8968",
            "value": 718
          }
        },
        "cb49463d1d354631a02d7c2f259e9f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a06bb61c29d44589ab5495bcda6a411",
            "placeholder": "​",
            "style": "IPY_MODEL_3a0ede7ca0da4dea84cb37c5bbb3d2bc",
            "value": " 718/718 [00:00&lt;00:00, 14.7kB/s]"
          }
        },
        "6bfba1402b164de7afa9ffe27b5092fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e569a6f3b91247f4a7c7d6120e78d0f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb42a8604a0f4065b4e6b24ffe4fd386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81a4b2acb5f34639baed96e31cc9d39b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "465ad94909964a228630e52e942a8968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a06bb61c29d44589ab5495bcda6a411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a0ede7ca0da4dea84cb37c5bbb3d2bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca76941c8cff4ab0a44dedd08535b827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecafe5b52ccb4453a5ce4326749efda4",
              "IPY_MODEL_cb4bf319e85141adbd5514a7672cab54",
              "IPY_MODEL_4b73954019c948d1aad3e7620749ad9a"
            ],
            "layout": "IPY_MODEL_f013b3dddde9449baad514be1dbd49e0"
          }
        },
        "ecafe5b52ccb4453a5ce4326749efda4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b251231076aa435b87bf2d09aca7d459",
            "placeholder": "​",
            "style": "IPY_MODEL_a16ec94be6e64b958c88a144191dcd3f",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "cb4bf319e85141adbd5514a7672cab54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7c0850e01a64cddbe314fc34622529a",
            "max": 1520013706,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ed7a4e0e3b94d5e81fad66321d60a29",
            "value": 1520013706
          }
        },
        "4b73954019c948d1aad3e7620749ad9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2a3d3610e71452ea1efd181a5f9d19a",
            "placeholder": "​",
            "style": "IPY_MODEL_90fd41424c174c489a92269dd01999cd",
            "value": " 1.52G/1.52G [00:10&lt;00:00, 129MB/s]"
          }
        },
        "f013b3dddde9449baad514be1dbd49e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b251231076aa435b87bf2d09aca7d459": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a16ec94be6e64b958c88a144191dcd3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7c0850e01a64cddbe314fc34622529a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ed7a4e0e3b94d5e81fad66321d60a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2a3d3610e71452ea1efd181a5f9d19a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90fd41424c174c489a92269dd01999cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39efd999a098482385ea1d7efb4169a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05c1e588351d49d9bdcba1bfc5ca891d",
              "IPY_MODEL_431af1a8c048413b999e3843815e4c0b",
              "IPY_MODEL_36cf6e8ebd3c43808e06929fc4f54425"
            ],
            "layout": "IPY_MODEL_585e751117d34912b6b5b1d9604cadce"
          }
        },
        "05c1e588351d49d9bdcba1bfc5ca891d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3084cb19ba24017ab7502fc06d9b8f7",
            "placeholder": "​",
            "style": "IPY_MODEL_e82b6cc758934b6086989ab12bdea869",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "431af1a8c048413b999e3843815e4c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2be93c09dc6f4a74ad9e717a3a4b1d46",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbd1515ea2a94ef7be5a62b0f40d9de1",
            "value": 124
          }
        },
        "36cf6e8ebd3c43808e06929fc4f54425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2624a1a6ba574ff3bb4951652f350149",
            "placeholder": "​",
            "style": "IPY_MODEL_0b9a515c6d9d4471880609132bcdce1b",
            "value": " 124/124 [00:00&lt;00:00, 5.32kB/s]"
          }
        },
        "585e751117d34912b6b5b1d9604cadce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3084cb19ba24017ab7502fc06d9b8f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e82b6cc758934b6086989ab12bdea869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2be93c09dc6f4a74ad9e717a3a4b1d46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbd1515ea2a94ef7be5a62b0f40d9de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2624a1a6ba574ff3bb4951652f350149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b9a515c6d9d4471880609132bcdce1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameerfayiz/ML-notebooks/blob/main/finetune_gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RXV7b_qHomJ",
        "outputId": "1848f6bf-ae2d-4a0e-e5e9-cd5f25a5495a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XoW6qxaIGvAb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import numpy as np\n",
        "\n",
        "import logging\n",
        "logging.getLogger().setLevel(logging.CRITICAL)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "0363b142d1664c7fbb1ffe9c7e6ba908",
            "bcd09622d6784d3a835e16013de7d469",
            "ab6b6a292a7941bb8c7677c2180288a9",
            "b68815e3ddec4609b26139b8e0078d7c",
            "44df1d933bc74e56aaab9cc428c9737e",
            "8f3acfdf3d284a578385b0f2408bb20b",
            "95faab1310114d5caf85b51912cc40fc",
            "e3242198c78042d88925a474b9ff01d3",
            "fb650d54d6784462a3aa6b53d8842353",
            "5aaf72b8929645de8f7ac61e2539682c",
            "40440495296341a2a073e434735ea64f",
            "38e0ccb6d07c40fca410401aa61be425",
            "2d477d5e223d4f03b0e130745039de86",
            "689f98dfff8640138832e0e52a5f31d8",
            "cc30bcde33df469cac1d64a8740b68d1",
            "fe8646107b5e494bb21ec27fb3fee210",
            "68977372dd214b8d8b547cdb0b112ac1",
            "63b32fd8ae3f492d92e9e60c89d96457",
            "808b577e6b5b444e90f408d0fceee9fc",
            "eda3dcba211e4c329f159ca4af93cd9e",
            "a42452c6df984295878df16a8a5667e6",
            "dad96c7a9d6a4ada9c3d50bac75fd0fe",
            "629ac868d29a44878e44ce6d70d267be",
            "337899346f9542dd8be4639749806232",
            "ffb4041c1058434ea9315a1136ea112f",
            "cb49463d1d354631a02d7c2f259e9f4f",
            "6bfba1402b164de7afa9ffe27b5092fa",
            "e569a6f3b91247f4a7c7d6120e78d0f7",
            "bb42a8604a0f4065b4e6b24ffe4fd386",
            "81a4b2acb5f34639baed96e31cc9d39b",
            "465ad94909964a228630e52e942a8968",
            "3a06bb61c29d44589ab5495bcda6a411",
            "3a0ede7ca0da4dea84cb37c5bbb3d2bc",
            "ca76941c8cff4ab0a44dedd08535b827",
            "ecafe5b52ccb4453a5ce4326749efda4",
            "cb4bf319e85141adbd5514a7672cab54",
            "4b73954019c948d1aad3e7620749ad9a",
            "f013b3dddde9449baad514be1dbd49e0",
            "b251231076aa435b87bf2d09aca7d459",
            "a16ec94be6e64b958c88a144191dcd3f",
            "d7c0850e01a64cddbe314fc34622529a",
            "3ed7a4e0e3b94d5e81fad66321d60a29",
            "d2a3d3610e71452ea1efd181a5f9d19a",
            "90fd41424c174c489a92269dd01999cd",
            "39efd999a098482385ea1d7efb4169a2",
            "05c1e588351d49d9bdcba1bfc5ca891d",
            "431af1a8c048413b999e3843815e4c0b",
            "36cf6e8ebd3c43808e06929fc4f54425",
            "585e751117d34912b6b5b1d9604cadce",
            "b3084cb19ba24017ab7502fc06d9b8f7",
            "e82b6cc758934b6086989ab12bdea869",
            "2be93c09dc6f4a74ad9e717a3a4b1d46",
            "dbd1515ea2a94ef7be5a62b0f40d9de1",
            "2624a1a6ba574ff3bb4951652f350149",
            "0b9a515c6d9d4471880609132bcdce1b"
          ]
        },
        "id": "PgmMtmabG3L_",
        "outputId": "992ad439-6553-452b-ac75-af59db11c9b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0363b142d1664c7fbb1ffe9c7e6ba908"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38e0ccb6d07c40fca410401aa61be425"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "629ac868d29a44878e44ce6d70d267be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca76941c8cff4ab0a44dedd08535b827"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39efd999a098482385ea1d7efb4169a2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def choose_from_top(probs, n=5):\n",
        "    ind = np.argpartition(probs, -n)[-n:]\n",
        "    top_prob = probs[ind]\n",
        "    top_prob = top_prob / np.sum(top_prob) # Normalize\n",
        "    choice = np.random.choice(n, 1, p = top_prob)\n",
        "    token_id = ind[choice][0]\n",
        "    return int(token_id)"
      ],
      "metadata": {
        "id": "RHrVEDhDG6qm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import json\n",
        "import csv\n",
        "\n",
        "class JokesDataset(Dataset):\n",
        "    def __init__(self, jokes_dataset_path = '/content'):\n",
        "        super().__init__()\n",
        "\n",
        "        short_jokes_path = os.path.join(jokes_dataset_path, 'sentence_to_chunks.csv')\n",
        "\n",
        "        self.joke_list = []\n",
        "        self.end_of_text_token = \"<|endoftext|>\"\n",
        "        \n",
        "        with open(short_jokes_path) as csv_file:\n",
        "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "            \n",
        "            x = 0\n",
        "            for row in csv_reader:\n",
        "                joke_str = \"\"\"Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \n",
        "                \n",
        "                INPUT : {text}\n",
        "                OUTPUT : {out}\n",
        "                <|endoftext|>\n",
        "                \"\"\".replace(\"{text}\",row[0]).replace(\"{out}\",row[1])\n",
        "                self.joke_list.append(joke_str)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.joke_list)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.joke_list[item]"
      ],
      "metadata": {
        "id": "pLgjoM1UG9n6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = JokesDataset()\n",
        "joke_loader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "xX4CmxwbHAsg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.joke_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7oB0hM4XXQg",
        "outputId": "c48b6f7e-8e39-46ad-b45b-290e149e5110"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : ameer and abi went to beach yesterday. abi is ceo of pillsbee which is found by abi and edison in 2019\\n                OUTPUT : \"ameer and abhi went to beach yesterday\",\\n\"Abi is the CEO of Pillsbee\",\\n\"Abi and edison are fouders of pillsbee\",\\n\"pillsbee was founded in 2019\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : John lives in New York and works as a software engineer. He has been living in New York for 5 years and has a dog named Max. He enjoys playing basketball in his free time and is a big fan of the New York Knicks.\\n                OUTPUT : \"John lives in New York\",\\n\"john works as a software engineer in newyork\",\\n\"john has been living in New York for 5 years\",\\n\"john has a dog named Max\",\\n\"john enjoys playing basketball in his free time\",\\n\"john is a big fan of the New York Knicks\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Amazon is a multinational technology company based in Seattle, Washington. It was founded by Jeff Bezos in 1994 and has grown to become one of the largest online retailers in the world. Amazon also offers cloud computing services and produces consumer electronics.\\n                OUTPUT : \"Amazon is a multinational technology company based in Seattle, Washington\",\\n\"Amazon was founded by Jeff Bezos in 1994\",\\n\"Amazon has grown to become one of the largest online retailers in the world\",\\n\"Amazon also offers cloud computing services\",\\n\"Amazon produces consumer electronics\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Tesla is a leading electric car manufacturer based in Palo Alto, California. It was founded by Elon Musk in 2003 and has revolutionized the automobile industry with its innovative designs and technology. Tesla is also known for its sustainable energy solutions, including solar panels and energy storage systems.\\n                OUTPUT : \"Tesla is a leading electric car manufacturer based in Palo Alto, California\",\\n\"Tesla was founded by Elon Musk in 2003\",\\n\"Tesla has revolutionized the automobile industry with its innovative designs and technology\",\\n\"Tesla is known for its sustainable energy solutions\",\\n\"Tesla provides solar panels and energy storage systems\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Mount Everest is the tallest mountain in the world, located in the Himalayas between Nepal and Tibet. It was first climbed by Sir Edmund Hillary and Tenzing Norgay in 1953 and has since been a popular destination for mountaineers and adventurers. Climbing Mount Everest is considered a dangerous and challenging endeavor, with altitude sickness, severe weather conditions, and limited oxygen being major concerns.\\n                OUTPUT : \"Mount Everest is the tallest mountain in the world, located in the Himalayas between Nepal and Tibet\",\\n\"Mount Everest was first climbed by Sir Edmund Hillary and Tenzing Norgay in 1953\",\\n\"Mount Everest has since been a popular destination for mountaineers and adventurers\",\\n\"Climbing Mount Everest is considered a dangerous and challenging endeavor\",\\n\"Altitude sickness, severe weather conditions, and limited oxygen are major concerns for climbers of Mount Everest\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : The Great Barrier Reef is the world\\'s largest coral reef system, located off the coast of Australia. It is home to an abundance of marine life and is considered one of the world\\'s most important ecosystems. The Great Barrier Reef is under threat from climate change, pollution, and overfishing, leading to significant declines in coral cover and biodiversity in recent years.\\n                OUTPUT : \"The Great Barrier Reef is the world\\'s largest coral reef system, located off the coast of Australia\",\\n\"The Great Barrier Reef is home to an abundance of marine life and is considered one of the world\\'s most important ecosystems\",\\n\"The Great Barrier Reef is under threat from climate change, pollution, and overfishing\",\\n\"Significant declines in coral cover and biodiversity have occurred in recent years due to these threats to the Great Barrier Reef\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Today I woke up early and went for a jog in the park. After breakfast, I had a busy day at work and finished up some important projects. In the evening, I caught up with a friend over dinner and went to bed early to get a good night\\'s sleep. Tomorrow I have a meeting with a potential client and plan to prepare for it tonight.\\n                OUTPUT : \"I woke up early today\",\\n\"I went for a jog in the park\",\\n\"I had breakfast after the jog\",\\n\"I had a busy day at work and finished up some important projects\",\\n\"I caught up with a friend over dinner in the evening\",\\n\"I went to bed early to get a good night\\'s sleep\",\\n\"I have a meeting with a potential client tomorrow\",\\n\"I plan to prepare for the meeting tonight\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Yesterday was a relaxing day for me. I went for a walk in the morning and then spent some time reading a book in the park. In the afternoon, I took a yoga class and went grocery shopping. In the evening, I cooked a delicious dinner and watched a movie with my family. Today I have a busy schedule with back-to-back appointments, but I am looking forward to a productive day.\\n                OUTPUT : \"Yesterday was a relaxing day for me\",\\n\"I went for a walk in the morning\",\\n\"I spent some time reading a book in the park\",\\n\"I took a yoga class in the afternoon\",\\n\"I went grocery shopping after yoga\",\\n\"I cooked a delicious dinner in the evening\",\\n\"I watched a movie with my family after dinner\",\\n\"Today I have a busy schedule with back-to-back appointments\",\\n\"I am looking forward to a productive day\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Last weekend, I went on a camping trip with my friends. We set up camp near a lake and spent the day fishing, hiking, and cooking meals over the fire. In the evening, we sat around the campfire, told stories, and stargazed. On Sunday, we packed up and went on a scenic drive before heading back home. It was a much-needed break from the city and a great opportunity to connect with nature and my friends.\\n                OUTPUT : \"Last weekend I went on a camping trip with my friends\",\\n\"We set up camp near a lake\",\\n\"We spent the day fishing\",\\n\"We spent the day hiking\",\\n\"We cooked meals over the fire during the day\",\\n\"In the evening, we sat around the campfire\",\\n\"We told stories around the campfire in the evening\",\\n\"We stargazed in the evening\",\\n\"On Sunday, we packed up\",\\n\"We went on a scenic drive on Sunday\",\\n\"We headed back home on Sunday\",\\n\"The camping trip was a much-needed break from the city\",\\n\"It was a great opportunity to connect with nature\",\\n\"It was a great opportunity to connect with my friends\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I recently took a trip to Europe and had the time of my life. I visited several countries including France, Italy, and Spain and tried new foods, explored historical landmarks, and met new people. One of my highlights was visiting the Eiffel Tower in Paris and taking a gondola ride in Venice. I also took part in a cooking class in Tuscany and learned how to make traditional Italian dishes. I can\\'t wait to plan my next adventure and make more memories.\\n                OUTPUT : \"I recently took a trip to Europe\",\\n\"I had the time of my life during the trip\",\\n\"I visited several countries including France, Italy, and Spain\",\\n\"I tried new foods during the trip\",\\n\"I explored historical landmarks during the trip\",\\n\"I met new people during the trip\",\\n\"One of my highlights was visiting the Eiffel Tower in Paris\",\\n\"I took a gondola ride in Venice\",\\n\"I took part in a cooking class in Tuscany\",\\n\"I learned how to make traditional Italian dishes in Tuscany\",\\n\"I can\\'t wait to plan my next adventure\",\\n\"I can\\'t wait to make more memories on my next adventure\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I recently started volunteering at a local animal shelter. I help care for the animals, clean their cages, and play with them. It\\'s been a wonderful experience and has given me a sense of purpose. I\\'m also learning a lot about different breeds and how to take care of them. I hope to continue volunteering and make a positive impact in the lives of these animals.\\n                OUTPUT : \"I recently started volunteering at a local animal shelter\",\\n\"I help care for the animals at the shelter\",\\n\"I clean the cages of the animals at the shelter\",\\n\"I play with the animals at the shelter\",\\n\"Volunteering at the shelter has been a wonderful experience\",\\n\"Volunteering at the shelter has given me a sense of purpose\",\\n\"I am learning a lot about different animal breeds\",\\n\"I am learning how to take care of different animal breeds\",\\n\"I hope to continue volunteering at the shelter\",\\n\"I hope to make a positive impact in the lives of the animals at the shelter\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I recently started a new job as a marketing manager. My role involves creating and implementing marketing strategies, managing a team, and analyzing market data. It\\'s a challenging but exciting role that allows me to use my creativity and problem-solving skills. I look forward to growing in my career and making a significant impact on the company\\'s success.\\n                OUTPUT : \"I recently started a new job as a marketing manager\",\\n\"My role involves creating marketing strategies\",\\n\"My role involves implementing marketing strategies\",\\n\"My role involves managing a team\",\\n\"My role involves analyzing market data\",\\n\"The job is challenging but exciting\",\\n\"The job allows me to use my creativity\",\\n\"The job allows me to use my problem-solving skills\",\\n\"I look forward to growing in my career\",\\n\"I look forward to making a significant impact on the company\\'s success\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I recently took up gardening as a hobby. I enjoy learning about different plants, how to care for them, and watching them grow. I have a small garden in my backyard where I grow a variety of vegetables, herbs, and flowers. Gardening has been a great way to connect with nature and relieve stress. I plan to expand my garden and try growing new plants in the future.\\n                OUTPUT : \"I recently took up gardening as a hobby\",\\n\"I enjoy learning about different plants\",\\n\"I enjoy learning how to care for different plants\",\\n\"I enjoy watching plants grow\",\\n\"I have a small garden in my backyard\",\\n\"I grow a variety of vegetables in my backyard garden\",\\n\"I grow a variety of herbs in my backyard garden\",\\n\"I grow a variety of flowers in my backyard garden\",\\n\"Gardening has been a great way to connect with nature\",\\n\"Gardening has been a great way to relieve stress\",\\n\"I plan to expand my garden in the future\",\\n\"I plan to try growing new plants in the future\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I recently started practicing yoga to improve my physical and mental well-being. I attend classes at a local studio and enjoy the challenge of different poses. The practice has helped me become more flexible, stronger, and calmer. I also appreciate the mindfulness and breathing techniques that are a part of the practice. I look forward to continuing my yoga journey and experiencing its benefits.\\n                OUTPUT : \"I recently started practicing yoga\",\\n\"I started practicing yoga to improve my physical well-being\",\\n\"I started practicing yoga to improve my mental well-being\",\\n\"I attend yoga classes at a local studio\",\\n\"I enjoy the challenge of different yoga poses\",\\n\"Practicing yoga has helped me become more flexible\",\\n\"Practicing yoga has helped me become stronger\",\\n\"Practicing yoga has helped me become calmer\",\\n\"I appreciate the mindfulness techniques in yoga\",\\n\"I appreciate the breathing techniques in yoga\",\\n\"I look forward to continuing my yoga journey\",\\n\"I look forward to experiencing the benefits of practicing yoga\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I recently started volunteering at a local animal shelter. I love spending time with the animals and taking care of them. It\\'s been a great way to give back to my community and make a positive impact. I also enjoy working with the staff and volunteers and learning about animal behavior and care. Volunteering has been a rewarding experience and I plan to continue doing it for a long time.\\n                OUTPUT : \"I recently started volunteering at a local animal shelter\",\\n\"I love spending time with the animals at the shelter\",\\n\"I love taking care of the animals at the shelter\",\\n\"Volunteering at the animal shelter is a great way to give back to my community\",\\n\"Volunteering at the animal shelter is a great way to make a positive impact\",\\n\"I enjoy working with the staff at the animal shelter\",\\n\"I enjoy working with the volunteers at the animal shelter\",\\n\"I enjoy learning about animal behavior at the animal shelter\",\\n\"I enjoy learning about animal care at the animal shelter\",\\n\"Volunteering at the animal shelter has been a rewarding experience\",\\n\"I plan to continue volunteering at the animal shelter for a long time\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I recently started a new job as a project manager. I\\'m excited to take on new challenges and responsibilities. I have a great team of coworkers who are supportive and knowledgeable. I enjoy learning about the latest project management techniques and finding creative solutions to problems. I\\'m confident that I will excel in this role and make a significant contribution to the company.\\n                OUTPUT : \"I recently started a new job as a project manager\",\\n\"I am excited to take on new challenges as a project manager\",\\n\"I am excited to take on new responsibilities as a project manager\",\\n\"I have a great team of coworkers\",\\n\"My coworkers are supportive\",\\n\"My coworkers are knowledgeable\",\\n\"I enjoy learning about the latest project management techniques\",\\n\"I enjoy finding creative solutions to problems\",\\n\"I am confident that I will excel in my role as a project manager\",\\n\"I am confident that I will make a significant contribution to the company\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I recently started a new hobby of photography. I love taking pictures of nature, architecture, and people. I\\'ve learned a lot about composition and lighting, and enjoy experimenting with different techniques. I have a passion for capturing the beauty in everyday moments and preserving them forever. I hope to continue to improve my skills and one day have a photography exhibit of my own.\\n                OUTPUT : \"I recently started a new hobby of photography\",\\n\"I love taking pictures of nature\",\\n\"I love taking pictures of architecture\",\\n\"I love taking pictures of people\",\\n\"I have learned a lot about composition in photography\",\\n\"I have learned a lot about lighting in photography\",\\n\"I enjoy experimenting with different photography techniques\",\\n\"I have a passion for capturing the beauty in everyday moments\",\\n\"I have a passion for preserving moments through photography\",\\n\"I hope to continue to improve my photography skills\",\\n\"I hope to one day have a photography exhibit of my own\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I recently took up gardening as a hobby. I love growing my own vegetables and flowers, and being able to see the fruits of my labor. I\\'ve learned about soil composition, plant care, and the different seasons for planting. I enjoy working with my hands and being in nature, and find it to be a great form of stress relief. I hope to one day have a beautiful and abundant garden that provides for my family and friends.\\n                OUTPUT : \"I recently took up gardening as a hobby\",\\n\"I love growing my own vegetables\",\\n\"I love growing my own flowers\",\\n\"I love being able to see the fruits of my labor in gardening\",\\n\"I have learned about soil composition in gardening\",\\n\"I have learned about plant care in gardening\",\\n\"I have learned about the different seasons for planting in gardening\",\\n\"I enjoy working with my hands in gardening\",\\n\"I enjoy being in nature while gardening\",\\n\"Gardening is a great form of stress relief for me\",\\n\"I hope to one day have a beautiful and abundant garden\",\\n\"I hope my garden will provide for my family and friends\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I am learning how to play the guitar. I love listening to music and always wanted to play an instrument. I\\'ve been practicing every day for a few months now and can already play a few songs. I enjoy playing for friends and family and love to see the look on their faces when I play a song they recognize. I hope to one day be able to play for a large audience and share my passion for music with others.\\n                OUTPUT : \"I am learning how to play the guitar\",\\n\"I love listening to music\",\\n\"I always wanted to play an instrument\",\\n\"I have been practicing guitar every day for a few months\",\\n\"I can already play a few songs on the guitar\",\\n\"I enjoy playing guitar for friends and family\",\\n\"I love to see the look on their faces when I play a recognizable song\",\\n\"I hope to one day be able to play guitar for a large audience\",\\n\"I hope to share my passion for music with others through guitar playing\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I went on a trip to Europe with my family last summer, visiting countries such as Italy, France, and Spain. We stayed in different cities and tried new foods, went sightseeing and took a lot of pictures. I loved exploring the different cultures, seeing historical landmarks and learning about the history of each country. I also had the chance to learn some new words in different languages and even tried speaking with locals. I truly enjoyed this trip and hope to travel more in the future.\\n                OUTPUT : \"I went on a trip to Europe with my family last summer\",\\n\"I visited Italy, France, and Spain during my trip to Europe\",\\n\"I stayed in different cities in Europe during my trip\",\\n\"I tried new foods in Europe during my trip\",\\n\"I went sightseeing in Europe during my trip\",\\n\"I took a lot of pictures in Europe during my trip\",\\n\"I loved exploring the different cultures in Europe during my trip\",\\n\"I saw historical landmarks in Europe during my trip\",\\n\"I learned about the history of each country I visited in Europe\",\\n\"I had the chance to learn some new words in different languages during my trip\",\\n\"I tried speaking with locals during my trip\",\\n\"I truly enjoyed my trip to Europe\",\\n\"I hope to travel more in the future\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I am a big fan of movies and TV shows. I enjoy watching different genres such as action, comedy, romance, and sci-fi. I also love to analyze the characters and story lines and predict what will happen next. I have a vast collection of movies and TV shows on my DVD and Blu-ray collection and I always make sure to keep up with the latest releases. I have a group of friends who share the same passion for movies and TV shows, and we often have movie nights where we watch our favorite films together.\\n                OUTPUT : \"I am a big fan of movies and TV shows\",\\n\"I enjoy watching different genres of movies and TV shows such as action, comedy, romance, and sci-fi\",\\n\"I love to analyze the characters and story lines of movies and TV shows\",\\n\"I enjoy predicting what will happen next in movies and TV shows\",\\n\"I have a vast collection of movies and TV shows on DVD and Blu-ray\",\\n\"I always make sure to keep up with the latest movie and TV show releases\",\\n\"I have a group of friends who share my passion for movies and TV shows\",\\n\"We often have movie nights where we watch our favorite films together\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I have been friends with John for over 10 years now and he is one of the kindest and funniest people I know. He always knows how to make me laugh and I always feel comfortable around him. He is extremely talented and has a passion for music and art. He is also very caring and supportive, always there for me when I need him. I admire his positive attitude and his ability to see the best in people. John is truly a great friend and I am grateful to have him in my life.\\n                OUTPUT : \"I have been friends with John for over 10 years\",\\n\"John is one of the kindest and funniest people I know\",\\n\"John always knows how to make me laugh and I feel comfortable around him\",\\n\"John is extremely talented and has a passion for music and art\",\\n\"John is very caring and supportive and is always there for me when I need him\",\\n\"I admire John\\'s positive attitude and his ability to see the best in people\",\\n\"John is truly a great friend and I am grateful to have him in my life\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I have been friends with John for over 10 years now and he is one of the kindest and funniest people I know. He always knows how to make me laugh and I always feel comfortable around him. He is extremely talented and has a passion for music and art. He is also very caring and supportive, always there for me when I need him. I admire his positive attitude and his ability to see the best in people. John is truly a great friend and I am grateful to have him in my life.\\n                OUTPUT : \"I have been friends with John for over 10 years\",\\n\"John is one of the kindest people I know\",\\n\"John is one of the funniest people I know\",\\n\"John always knows how to make me laugh\",\\n\"I always feel comfortable around John\",\\n\"John is extremely talented\",\\n\"John has a passion for music\",\\n\"John has a passion for art\",\\n\"John is very caring\",\\n\"John is supportive\",\\n\"John is always there for me when I need him\",\\n\"I admire John\\'s positive attitude\",\\n\"I admire John\\'s ability to see the best in people\",\\n\"John is truly a great friend\",\\n\"I am grateful to have John in my life\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : My friend Sarah is a talented artist and loves to spend her free time painting and drawing. She is also very athletic and enjoys playing soccer, basketball, and tennis. Sarah is a good listener and always gives me good advice when I need it. She is also very funny and knows how to make me laugh. I am grateful to have such a wonderful friend like Sarah in my life.\\n                OUTPUT : \"My friend Sarah is a talented artist\",\\n\"Sarah loves to spend her free time painting\",\\n\"Sarah loves to spend her free time drawing\",\\n\"Sarah is also very athletic\",\\n\"Sarah enjoys playing soccer\",\\n\"Sarah enjoys playing basketball\",\\n\"Sarah enjoys playing tennis\",\\n\"Sarah is a good listener\",\\n\"Sarah always gives me good advice when I need it\",\\n\"Sarah is also very funny\",\\n\"Sarah knows how to make me laugh\",\\n\"I am grateful to have such a wonderful friend like Sarah in my life\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : My boss is a very intelligent and hardworking person who always sets high standards for himself and others. He is also very fair and treats all of his employees with respect and kindness. I have learned a lot from my boss and I am grateful for the opportunities he has given me to grow professionally. He is a great leader and I have the utmost respect for him.\\n                OUTPUT : \"My boss is a very intelligent person\",\\n\"My boss is a hardworking person\",\\n\"My boss always sets high standards for himself\",\\n\"My boss sets high standards for others\",\\n\"My boss is very fair\",\\n\"My boss treats all of his employees with respect\",\\n\"My boss treats all of his employees with kindness\",\\n\"I have learned a lot from my boss\",\\n\"I am grateful for the opportunities my boss has given me to grow professionally\",\\n\"My boss is a great leader\",\\n\"I have the utmost respect for my boss\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Samantha is a nurse who loves to travel and see different cultures. She has been to 5 different countries and learned about their history, customs and food. She is planning to go on a trip to Japan next year to explore their beautiful culture and try new food.\\n                OUTPUT : \"Samantha is a nurse\",\\n\"Samantha loves to travel and see different cultures\",\\n\"Samantha has been to 5 different countries\",\\n\"Samantha has learned about their history, customs and food\",\\n\"Samantha is planning to go on a trip to Japan next year\",\\n\"Samantha wants to explore the beautiful culture of Japan\",\\n\"Samantha wants to try new food in Japan\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Michael is a professional chef who enjoys cooking different dishes and experimenting with new ingredients. He has been working at a famous restaurant for 5 years and has won several awards for his exceptional culinary skills. He also loves teaching cooking classes and sharing his passion for food with others.\\n                OUTPUT : \"Michael is a professional chef\",\\n\"Michael enjoys cooking different dishes and experimenting with new ingredients\",\\n\"Michael has been working at a famous restaurant for 5 years\",\\n\"Michael has won several awards for his exceptional culinary skills\",\\n\"Michael loves teaching cooking classes\",\\n\"Michael loves sharing his passion for food with others\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Emily is an avid reader who loves to spend her weekends at the library and discovering new authors. She has read over 200 books and has a library in her room with all of her favorite books. She also enjoys writing book reviews and sharing her thoughts with others\\n                OUTPUT : \"Emily is an avid reader\",\\n\"Emily loves to spend her weekends at the library and discovering new authors\",\\n\"Emily has read over 200 books\",\\n\"Emily has a library in her room with all of her favorite books\",\\n\"Emily enjoys writing book reviews\",\\n\"Emily enjoys sharing her thoughts about books with others\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Today was a busy day for Sarah. She had to attend her math and science classes in the morning and then had a project presentation in her history class in the afternoon. After school, she went to the gym to work out and then spent the evening studying for her exams next week. She also made sure to call her grandmother before bed to catch up.\\n                OUTPUT : \"Today was a busy day for Sarah\",\\n\"Sarah had to attend her math and science classes in the morning\",\\n\"Sarah had a project presentation in her history class in the afternoon\",\\n\"After school, Sarah went to the gym to work out\",\\n\"Sarah spent the evening studying for her exams next week\",\\n\"Sarah made sure to call her grandmother before bed to catch up\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : John had a great day today. He started the day with a healthy breakfast and then went for a jog in the park. He attended his college classes and had a productive study session with his friends. After dinner, he played basketball with his team and then relaxed by reading a book before bed\\n                OUTPUT : \"John had a great day today\",\\n\"John started the day with a healthy breakfast\",\\n\"John went for a jog in the park\",\\n\"John attended his college classes\",\\n\"John had a productive study session with his friends\",\\n\"After dinner, John played basketball with his team\",\\n\"John relaxed by reading a book before bed\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Today I had a math test and a science quiz, I studied hard for both but only got a B in math and a C in science, my teacher said I need to work on my problem solving skills and practice more for my future exams\\n                OUTPUT : \"Today I had a math test\",\\n\"Today I had a science quiz\",\\n\"I studied hard for both math test and science quiz\",\\n\"I got a B in math test\",\\n\"I got a C in science quiz\",\\n\"My teacher said I need to work on my problem solving skills\",\\n\"My teacher said I need to practice more for my future exams\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I went to the library after school to study for my exams, I found a quiet corner and started studying, I studied for 2 hours and then I decided to take a break, I walked around the library and saw my friend John who was also studying, we talked for a while and then I went back to my seat and continued studying.\\n                OUTPUT : \"I went to the library after school to study for my exams\",\\n\"I found a quiet corner in the library and started studying\",\\n\"I studied for 2 hours\",\\n\"I decided to take a break from studying\",\\n\"I walked around the library\",\\n\"I saw my friend John who was also studying\",\\n\"We talked for a while\",\\n\"I went back to my seat and continued studying\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I had a great time playing basketball with my friends and my favorite team won the game, we also went to a nearby restaurant and tried new dishes, it was a fantastic day overall.\\n                OUTPUT : \"I had a great time playing basketball with my friends\",\\n\"my favorite team won the game\",\\n\"we also went to a nearby restaurant\",\\n\"we tried new dishes at the restaurant\",\\n\"it was a fantastic day overall\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I went to the library today and studied for my exams, I also attended a workshop on how to study effectively and learned some new techniques, I finished my day by going for a walk in the park and listening to music\\n                OUTPUT : \"I went to the library today\",\\n\"I studied for my exams at the library\",\\n\"I attended a workshop on how to study effectively\",\\n\"I learned some new techniques in the workshop\",\\n\"I finished my day by going for a walk in the park\",\\n\"I listened to music while walking in the park\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I had a meeting with my boss and the CEO of the company this morning and discussed the progress of our project and discussed the budget for the next quarter. Afterwards, I worked on the report for the project and sent it to my team and then went to the gym and had a great workout\\n                OUTPUT : \"I had a meeting with my boss and the CEO of the company this morning\",\\n\"In the meeting, we discussed the progress of our project\",\\n\"We also discussed the budget for the next quarter\",\\n\"Afterwards, I worked on the report for the project\",\\n\"I sent it to my team\",\\n\"I then went to the gym\",\\n\"I had a great workout at the gym\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Today I woke up early, went for a jog and did my daily chores including cleaning the house and cooking breakfast. After that, I attended my online yoga class and also finished my work for the day. In the evening, I met my best friend for a walk and we talked about our future plans and also had a small picnic. Overall, it was a productive day and I am feeling very content.\\n                OUTPUT : \"Today I woke up early\",\\n\"I went for a jog and did my daily chores\",\\n\"My daily chores included cleaning the house and cooking breakfast\",\\n\"After that, I attended my online yoga class\",\\n\"I finished my work for the day\",\\n\"In the evening, I met my best friend for a walk\",\\n\"We talked about our future plans and also had a small picnic\",\\n\"Overall, it was a productive day\",\\n\"I am feeling very content\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Today at work, I had a busy day as usual, finishing up projects and meeting with clients. I also attended a training session on time management skills and had a team meeting to discuss our current progress on a new project. I also had a one-on-one with my manager to go over my performance and received positive feedback, which made me feel good about my contributions to the company. After work, I went for a run and then had dinner with friends, discussing our plans for the weekend.\\n                OUTPUT : \"Today at work, I had a busy day finishing up projects and meeting with clients.\"\\n\"I attended a training session on time management skills.\"\\n\"I had a team meeting to discuss our current progress on a new project.\"\\n\"I had a one-on-one with my manager to go over my performance.\"\\n\"I received positive feedback from my manager, which made me feel good about my contributions to the company.\"\\n\"After work, I went for a run.\"\\n\"I had dinner with friends, discussing our plans for the weekend.\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Today, I woke up late and missed my morning workout. I was too lazy to make breakfast so I ordered pizza and watched TV all day. I also skipped my afternoon nap and didn\\'t do any work. I spent the entire day being lazy and not doing anything productive.\\n                OUTPUT : \"Today, I woke up late\",\\n\"I missed my morning workout\",\\n\"I was too lazy to make breakfast\",\\n\"I ordered pizza for breakfast\",\\n\"I watched TV all day\",\\n\"I skipped my afternoon nap\",\\n\"I didn\\'t do any work\",\\n\"I spent the entire day being lazy\",\\n\"I didn\\'t do anything productive\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Today I overslept and missed my morning meeting, which was a major project update and my boss was not happy about it. I tried to make excuses and explained that I had a long night and didn\\'t set an alarm, but my boss was uninterested in my excuses and told me to be more responsible in the future.\\n                OUTPUT : \"Today I overslept\",\\n\"I missed my morning meeting\",\\n\"The meeting was a major project update\",\\n\"My boss was not happy about me missing the meeting\",\\n\"I tried to make excuses for missing the meeting\",\\n\"I explained that I had a long night and didn\\'t set an alarm\",\\n\"My boss was uninterested in my excuses\",\\n\"My boss told me to be more responsible in the future\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I woke up this morning feeling lazy but I forced myself to go to the gym and exercise. I ran on the treadmill for 30 minutes and did some weightlifting. Afterwards, I went grocery shopping and bought ingredients for dinner tonight which is going to be grilled chicken and steamed vegetables. I then came back home and took a nap before starting my work.\\n                OUTPUT : \"I woke up this morning feeling lazy\",\\n\"I forced myself to go to the gym\",\\n\"I exercised at the gym\",\\n\"I ran on the treadmill for 30 minutes\",\\n\"I did some weightlifting at the gym\",\\n\"I went grocery shopping\",\\n\"I bought ingredients for dinner tonight\",\\n\"Dinner tonight is going to be grilled chicken and steamed vegetables\",\\n\"I came back home\",\\n\"I took a nap before starting my work\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : As the CEO of Facebook, I was busy handling company\\'s operations and meeting with potential investors yesterday. I also had a call with my team in the morning to discuss the progress of our latest project and it was a productive meeting. In the evening, I went for a walk and spent some time with my family, discussing our future plans and catching up on each other\\'s lives.\\n                OUTPUT : \"As the CEO of Facebook, I was busy handling company\\'s operations yesterday\",\\n\"I also had meetings with potential investors yesterday\",\\n\"I had a call with my team in the morning to discuss the progress of our latest project\",\\n\"The call was productive\",\\n\"In the evening, I went for a walk\",\\n\"I spent some time with my family\",\\n\"We discussed our future plans\",\\n\"We caught up on each other\\'s lives\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : As a singer, today I had a busy day. I started the day with a recording session for my upcoming album and had a meeting with my team to discuss the promotional plans for the album. After that, I went for a photoshoot for the album cover and had a press conference to announce the album release date. I ended the day with a live performance at a local club, where I got to interact with my fans and received positive feedback on my new songs.\\n                OUTPUT : \"As a singer, today I had a busy day\",\\n\"I started the day with a recording session for my upcoming album\",\\n\"I had a meeting with my team to discuss the promotional plans for the album\",\\n\"After that, I went for a photoshoot for the album cover\",\\n\"I had a press conference to announce the album release date\",\\n\"I ended the day with a live performance at a local club\",\\n\"I got to interact with my fans at the local club\",\\n\"I received positive feedback on my new songs at the local club\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I am the boyfriend of an overthinker and she always thinks a lot about everything and worries about small things. She also analyzes every situation and tries to find the best solution, but sometimes it leads to more stress for her. Yesterday she was thinking about our future and our plans for the next few years, and she started to worry about our finances and how we can save more money. I tried to calm her down and told her that we can work together and find a way to make it work\\n                OUTPUT : \"I am the boyfriend of an overthinker\",\\n\"She always thinks a lot about everything and worries about small things\",\\n\"She analyzes every situation and tries to find the best solution\",\\n\"However, sometimes it leads to more stress for her\",\\n\"Yesterday, she was thinking about our future and plans for the next few years\",\\n\"She started to worry about our finances and how we can save more money\",\\n\"I tried to calm her down\",\\n\"I told her that we can work together and find a way to make it work\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Today I went to a charity event for homeless people and it was a great experience, the event was organized by the local community and had a huge turnout with many volunteers and donations. The event included a food drive and a clothing drive and many people got to help out by donating food and clothes for the homeless community. I also had the opportunity to interact with some of the homeless people and heard their stories and it was an eye-opening experience\\n                OUTPUT : \"Today I went to a charity event for homeless people\",\\n\"The event was a great experience\",\\n\"The event was organized by the local community\",\\n\"The event had a huge turnout with many volunteers and donations\",\\n\"The event included a food drive and a clothing drive\",\\n\"Many people got to help out by donating food and clothes for the homeless community\",\\n\"I had the opportunity to interact with some of the homeless people\",\\n\"I heard their stories and it was an eye-opening experience\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Yesterday was a busy day as I had a breakfast meeting with my friends at a new café and later in the evening I went to a dinner party with them. We talked about our future plans and also discussed our favorite hobbies and interests. We also played some games and danced to the music till late night. Today, I am feeling a bit exhausted but happy with the time spent with my friends.\\n                OUTPUT : \"Yesterday, I had a breakfast meeting with my friends at a new café\",\\n\"Later in the evening, I went to a dinner party with them\",\\n\"We talked about our future plans and also discussed our favorite hobbies and interests\",\\n\"We also played some games and danced to the music till late night\",\\n\"Today, I am feeling a bit exhausted but happy with the time spent with my friends.\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Last night, I had a great time with my friends at the restaurant. We ordered pizza, wings, and soda and enjoyed chatting and laughing while eating. After that, we decided to go to the club and dance until the morning.\\n                OUTPUT : \"Last night I had a great time with my friends at the restaurant\",\\n\"We ordered pizza, wings, and soda\",\\n\"We enjoyed chatting and laughing while eating\",\\n\"After that, we decided to go to the club\",\\n\"We danced until the morning\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : I went to the park with my friends to play frisbee and have a picnic. We also played some soccer and had a race. Afterwards, we sat under the trees and enjoyed the scenery while having snacks and drinks.\"\\n                OUTPUT : \"I went to the park with my friends\",\\n\"We played frisbee and had a picnic\",\\n\"We also played some soccer and had a race\",\\n\"Afterwards, we sat under the trees\",\\n\"We enjoyed the scenery while having snacks and drinks\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Today was an amazing day filled with lots of fun activities with my friends. We started the day by going to the beach and playing beach volleyball followed by a delicious lunch at a local seafood restaurant, and then we went on a boat ride and saw some amazing dolphins and sea turtles. In the evening, we all got dressed up and went to a fancy restaurant where we danced the night away.\\n                OUTPUT : \"Today was an amazing day filled with lots of fun activities with my friends.\",\\n\"We started the day by going to the beach and playing beach volleyball.\",\\n\"We had a delicious lunch at a local seafood restaurant.\",\\n\"We went on a boat ride and saw some amazing dolphins and sea turtles.\",\\n\"In the evening, we all got dressed up.\",\\n\"We went to a fancy restaurant where we danced the night away.\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Sara is a doctor and runs her own clinic. She graduated from Harvard Medical School and has been practicing medicine for 10 years. Sara is also a volunteer at a local shelter and spends her weekends helping animals.\\n                OUTPUT : \"Sara is a doctor and runs her own clinic\",\\n\"Sara graduated from Harvard Medical School\",\\n\"Sara has been practicing medicine for 10 years\",\\n\"Sara is a volunteer at a local shelter\",\\n\"Sara spends her weekends helping animals\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Yesterday, Maria, Alex and Peter went to the park for a picnic. They had sandwiches, fruit, and lemonade. Maria and Alex played frisbee while Peter read a book. After their picnic, they went to the amusement park and rode the roller coasters, played arcade games and won some prizes. They had a great time and ended the day with ice cream at a nearby shop.\\n                OUTPUT : \"Yesterday, Maria, Alex and Peter went to the park for a picnic\",\\n\"They had sandwiches, fruit, and lemonade\",\\n\"Maria and Alex played frisbee\",\\n\"Peter read a book\",\\n\"After their picnic, they went to the amusement park\",\\n\"They rode the roller coasters, played arcade games and won some prizes\",\\n\"They had a great time\",\\n\"They ended the day with ice cream at a nearby shop\"\\n                <|endoftext|>\\n                ',\n",
              " 'Below is a given INPUT as text and OUTPUT is its  multiple non dividable  sentences such that each sentence contain only single knowledge meaning in it. \\n                \\n                INPUT : Sarah and her friends, Jack and Karen, went to the beach for a day trip. They went fishing, sunbathed, and played beach volleyball. In the evening, they had a bonfire and grilled marshmallows. Sarah and Jack sang songs while Karen played the guitar. They had a great time and vowed to make it an annual tradition.\\n                OUTPUT : \"Sarah and her friends, Jack and Karen, went to the beach for a day trip\",\\n\"They went fishing\",\\n\"They sunbathed\",\\n\"They played beach volleyball\",\\n\"In the evening, they had a bonfire\",\\n\"They grilled marshmallows\",\\n\"Sarah and Jack sang songs\",\\n\"Karen played the guitar\",\\n\"They had a great time\",\\n\"They vowed to make it an annual tradition\"\\n                <|endoftext|>\\n                ']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "EPOCHS = 5\n",
        "LEARNING_RATE = 0.001 #3e-5\n",
        "WARMUP_STEPS = 5000\n",
        "MAX_SEQ_LEN = 400\n",
        "from transformers import AdamW , get_linear_schedule_with_warmup\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'"
      ],
      "metadata": {
        "id": "FoyvrBxIHDAD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "model.train()\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps = -1)\n",
        "proc_seq_count = 0\n",
        "sum_loss = 0.0\n",
        "batch_count = 0\n",
        "\n",
        "tmp_jokes_tens = None\n",
        "models_folder = \"trained_models\"\n",
        "if not os.path.exists(models_folder):\n",
        "    os.mkdir(models_folder)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    print(f\"EPOCH {epoch} started\" + '=' * 30)\n",
        "    \n",
        "    for idx,joke in enumerate(joke_loader):\n",
        "        \n",
        "        #################### \"Fit as many joke sequences into MAX_SEQ_LEN sequence as possible\" logic start ####\n",
        "        joke_tens = torch.tensor(tokenizer.encode(joke[0])).unsqueeze(0).to(device)\n",
        "        #Skip sample from dataset if it is longer than MAX_SEQ_LEN\n",
        "        if joke_tens.size()[1] > MAX_SEQ_LEN:\n",
        "            continue\n",
        "        \n",
        "        #The first joke sequence in the sequence\n",
        "        if not torch.is_tensor(tmp_jokes_tens):\n",
        "            tmp_jokes_tens = joke_tens\n",
        "            continue\n",
        "        else:\n",
        "            #The next joke does not fit in so we process the sequence and leave the last joke \n",
        "            #as the start for next sequence \n",
        "            if tmp_jokes_tens.size()[1] + joke_tens.size()[1] > MAX_SEQ_LEN:\n",
        "                work_jokes_tens = tmp_jokes_tens\n",
        "                tmp_jokes_tens = joke_tens\n",
        "            else:\n",
        "                #Add the joke to sequence, continue and try to add more\n",
        "                tmp_jokes_tens = torch.cat([tmp_jokes_tens, joke_tens[:,1:]], dim=1)\n",
        "                continue\n",
        "        ################## Sequence ready, process it trough the model ##################\n",
        "        outputs = model(work_jokes_tens, labels=work_jokes_tens)\n",
        "        loss, logits = outputs[:2]                        \n",
        "        loss.backward()\n",
        "        sum_loss = sum_loss + loss.detach().data\n",
        "                       \n",
        "        proc_seq_count = proc_seq_count + 1\n",
        "        if proc_seq_count == BATCH_SIZE:\n",
        "            proc_seq_count = 0    \n",
        "            batch_count += 1\n",
        "            optimizer.step()\n",
        "            scheduler.step() \n",
        "            optimizer.zero_grad()\n",
        "            model.zero_grad()\n",
        "\n",
        "        if batch_count == 100:\n",
        "            print(f\"sum loss {sum_loss}\")\n",
        "            batch_count = 0\n",
        "            sum_loss = 0.0\n",
        "    \n",
        "    # Store the model after each epoch to compare the performance of them\n",
        "    torch.save(model.state_dict(), os.path.join(models_folder, f\"gpt2_medium_joker_{epoch}.pt\"))\n",
        "            \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FJS_79tHLRS",
        "outputId": "9ca168fb-962a-4aa8-d402-e1d433c05d72"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH 0 started==============================\n",
            "EPOCH 1 started==============================\n",
            "EPOCH 2 started==============================\n",
            "EPOCH 3 started==============================\n",
            "EPOCH 4 started==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_EPOCH = 4\n",
        "\n",
        "models_folder = \"trained_models\"\n",
        "\n",
        "model_path = os.path.join(models_folder, f\"gpt2_medium_joker_{MODEL_EPOCH}.pt\")\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "jokes_output_file_path = f'generated_{MODEL_EPOCH}.jokes'\n",
        "\n",
        "model.eval()\n",
        "if os.path.exists(jokes_output_file_path):\n",
        "    os.remove(jokes_output_file_path)\n",
        "    \n",
        "joke_num = 0\n",
        "with torch.no_grad():\n",
        "   \n",
        "        for joke_idx in range(1000):\n",
        "        \n",
        "            joke_finished = False\n",
        "\n",
        "            cur_ids = torch.tensor(tokenizer.encode(dataset[0].split('OUTPUT')[0] + \"\\n\\nSplitted:\")).unsqueeze(0).to(device)\n",
        "\n",
        "            for i in range(100):\n",
        "                outputs = model(cur_ids, labels=cur_ids)\n",
        "                loss, logits = outputs[:2]\n",
        "                softmax_logits = torch.softmax(logits[0,-1], dim=0) #Take the first(from only one in this case) batch and the last predicted embedding\n",
        "                if i < 3:\n",
        "                    n = 20\n",
        "                else:\n",
        "                    n = 3\n",
        "                next_token_id = choose_from_top(softmax_logits.to('cpu').numpy(), n=n) #Randomly(from the topN probability distribution) select the next word\n",
        "                cur_ids = torch.cat([cur_ids, torch.ones((1,1)).long().to(device) * next_token_id], dim = 1) # Add the last word to the running sequence\n",
        "\n",
        "                if next_token_id in tokenizer.encode('<|endoftext|>'):\n",
        "                    joke_finished = True\n",
        "                    break\n",
        "\n",
        "            \n",
        "            if joke_finished:\n",
        "                \n",
        "                joke_num = joke_num + 1\n",
        "                \n",
        "                output_list = list(cur_ids.squeeze().to('cpu').numpy())\n",
        "                output_text = tokenizer.decode(output_list)\n",
        "                print(output_text)\n",
        "                with open(jokes_output_file_path, 'a') as f:\n",
        "                    f.write(f\"{output_text} \\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SvIJtpSSHbFI",
        "outputId": "add55e9a-49b5-424d-df02-6c33645c0025"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is a given INPUT as text and \n",
            "\n",
            "Splitted:\n",
            "\n",
            "Input text:\n",
            "\n",
            "Input text split into two parts:\n",
            "\n",
            "Text:\n",
            "\n",
            "Input text split into three parts:\n",
            "\n",
            "Text:\n",
            "\n",
            "Input text split into four parts:\n",
            "\n",
            "Text:\n",
            "\n",
            "Input text split into five parts:\n",
            "\n",
            "Text:<|endoftext|>\n",
            "Below is a given INPUT as text and \n",
            "\n",
            "Splitted:\n",
            "\n",
            "\"I'm sorry I'm late\"\n",
            "\n",
            "Splitted:\n",
            "\n",
            "I'm sorry I'm late\"\n",
            "\n",
            "I'm sorry, I'm sorry I'm late\"\n",
            "\n",
            "I'm sorry, I'm sorry I am late\"\n",
            "\n",
            "I'm sorry, I'm sorry I am late\"\n",
            "\n",
            "I'm sorry, I'm sorry I am late\"<|endoftext|>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6ee148197559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0msoftmax_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Take the first(from only one in this case) batch and the last predicted embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1044\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    885\u001b[0m                 )\n\u001b[1;32m    886\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    888\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.044715\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}